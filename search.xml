<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[keepalived实例--双主]]></title>
      <url>%2F2017%2F06%2F25%2Fkeepalivedtest%2F</url>
      <content type="text"><![CDATA[keepalived实例–双主环境：RS：real_server 以下全部简称 两台RS配置IP 172.16.2.10/16 172.16.2.20/16 安装httpd，每台上面做一个不同的测试页，以便区分。实际中主备必须一样。 调度器：director 两台调度器 172.16.2.30/16 172.16.2.40/16 安装keepalived 安装ipvsadm（这里配置用不到，只做测试用） vip：virtual ip 客户端发送请求的IP vip组 172.16.2.88/16 172.16.2.99/16 以上主机全部同步时间 配置：RS配置两台RS使用脚本配置回环网卡IP(vip) 1234567891011121314151617181920212223242526272829#!/bin/bash#vip=&apos;172.16.2.99&apos; #dr模式下的必须操作，vip是什么，变量内vip就写什么。这里配置成88和99.netmask=&apos;255.255.255.255&apos;iface=&apos;lo:0&apos; #网卡别名。依次排序，不能重复case $1 instart) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ifconfig $iface $vip netmask $netmask broadcast $vip up route add -host $vip dev $iface ;;stop) ifconfig $iface down echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ;;*) echo &quot;Usage : $(basename $0) start|stop&quot; exit 1 ;;esac 两台RS安装httpd 安装 yum install httpd 提供测试页 echo RS1 &gt; /var/www/html/index.html RS2 同上 完成后启动服务，在调度器主机上能访问即可。 调度器配置安装好keepalived、ipvsadm、nginx后开始配置 配置keepalived修改配置文件。添加vrrp和virtual_server,配置如下。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node1 vrrp_mcast_group4 224.1.101.33&#125;vrrp_instance VI_1 &#123; state MASTER priority 100 interface eno16777736 virtual_router_id 33 advert_int 1 authentication &#123; auth_type PASS auth_pass RT3SKUI2 &#125; virtual_ipaddress &#123; 172.16.2.99/16 dev eno16777736 label eno16777736:0 &#125;# notify_master &quot;/etc/keepalived/notify.sh master&quot;# notify_backup &quot;/etc/keepalived/notify.sh backup&quot;# notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125;virtual_server 172.16.2.99 80 &#123; delay_loop 1 lb_algo wrr lb_kind DR protocol TCP sorry_server 127.0.0.1 80 real_server 172.16.2.10 80 &#123; weight 1 HTTP_GET &#123; url &#123; path /index.html status_code 200 &#125; nb_get_retry 3 delay_before_retry 2 connect_timeout 3 &#125; &#125; real_server 172.16.2.20 80 &#123; weight 1 HTTP_GET &#123; url &#123; path /index.html status_code 200 &#125; nb_get_retry 3 delay_before_retry 2 connect_timeout 3 &#125; &#125; &#125;&#125;vrrp_instance VI_2 &#123; state BACKUP priority 95 interface eno16777736 virtual_router_id 34 advert_int 1 authentication &#123; auth_type PASS auth_pass OT4SKOI2 &#125; virtual_ipaddress &#123; 172.16.2.88/16 dev eno16777736 label eno16777736:1 &#125;# notify_master &quot;/etc/keepalived/notify.sh master&quot;# notify_backup &quot;/etc/keepalived/notify.sh backup&quot;# notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125;virtual_server 172.16.2.88 80 &#123; delay_loop 1 lb_algo wrr lb_kind DR protocol TCP sorry_server 127.0.0.1 80 real_server 172.16.2.10 80 &#123; weight 1 HTTP_GET &#123; url &#123; path /index.html status_code 200 &#125; nb_get_retry 3 delay_before_retry 2 connect_timeout 3 &#125; &#125; real_server 172.16.2.20 80 &#123; weight 1 HTTP_GET &#123; url &#123; path /index.html status_code 200 &#125; nb_get_retry 3 delay_before_retry 2 connect_timeout 3 &#125; &#125;&#125; 附上代码中注释的邮件提醒服务脚本： 12345678910111213141516171819202122232425#!/bin/bash#contact=&apos;root@localhost&apos;notify() &#123; mailsubject=&quot;$(hostname) to be $1, vip floating&quot; mailbody=&quot;$(date +&apos;%F %T&apos;): vrrp transition, $(hostname) changed to be $1&quot; echo &quot;$mailbody&quot; | mail -s &quot;$mailsubject&quot; $contact&#125;case $1 inmaster) notify master ;;backup) notify backup ;;fault) notify fault ;;*) echo &quot;Usage: $(basename $0) &#123;master|backup|fault&#125;&quot; exit 1 ;;esac 启动keepalived 检查成功与否：ifconfig查IP 确保在主节点上可以看到设置的网卡别名，以及IP ipvsadm -ln 查规则 确保后端两台RS已经被加入到集群里。 注意：这里的规则不是使用ipvsadm添加。是keepalived根据配置文件从内核中直接生成的。 systemctl status keepalived 查看keepalived的状态 可以看到keepalived的详细状态信息。 确保以上三项全部没问题以后再使用一台客户端对vip进行访问就可以了。 还可以进行测试。停掉后端一台RS的http服务。查看访问结果。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[iptables]]></title>
      <url>%2F2017%2F06%2F15%2Fiptables%2F</url>
      <content type="text"><![CDATA[iptables1.介绍 iptables是与Linux最新3.5版本的内核集成的IP信息包过滤系统。如果Linux系统连接到因特网或LAN、服务器连接到因特网或LAN的代理服务器，则该系统有利于在Linux系统上更好的控制IP信息包过滤和防火墙设置。 防火墙在做信息包过滤决定时，有一套遵循和组成的规则，这些规则存储在专用的信息包过滤表中，而这些表集成在Linux内核中。在信息包过滤表中，规则被分组放在链中（chain）。而netfilter/iptables IP信息包 过滤系统是一款功能强大的工具，可对规则进行添加、编辑、和移除的操作。 netfilter组件也称为内核空间（Kernelspace），是内核的一部分，由一些信息包过滤表组成，这些表包含内核用来控制信息包过滤处理的规则表。 iptables组件是一种工具，也称为用户空间（userspace），它使插入、修改、和除去信息包过滤表中的规则变得容易。 2.历史版本与Linux内核各版本集成的防火墙历史版本： 1. 2.0.X内核：ipfwadm 2. 2.2.X内核：ipchains 3. 2.4.X内核：iptables 3.内容Iptables采用“表”和“链”的分层结构。在REHL4中是三张表五个链。现在REHL5成了四张表五个链了，不过多出来的那个表用的也不太多，所以基本还是和以前一样。 iptables在内核中一个定义了五个位置： 1.内核空间中：从一个网络接口进来，到另一个网络接口出去。 2.数据包从内核流入用户空间。 3.数据包从用户空间流出 4.进入/离开本机的外网接口 5.进入/离开本机的内网接口 链：这五个位置也被称为五个钩子函数（hook functions），也叫五个规则链： 1.PREROUTING（路由前） 2.INPUT（数据包流入） 3.FORWARD（路由转发） 4.OUTPUT（数据包流出） 5.POSTROUTING（路由后） 表：表提供特定的功能，iptables内置了4个表，即filter表、nat表、mangle表和raw表，分别用于实现包过滤，网络地址转换、包重构(修改)和数据跟踪处理。 功能表&lt;--&gt;链 1.Filter表--&gt;三个链：INPUT、FORWARD、OUTPUT 作用：过滤数据包 内核模块：iptables_filter. 2.Nat表--&gt;三个链：PREROUTING、POSTROUTING、OUTPUT 作用：用于网络地址转换（IP、端口） 内核模块：iptable_nat 3.Mangle表--&gt;五个链：PREROUTING、POSTROUTING、INPUT、OUTPUT、FORWARD 作用：修改数据包的服务类型、TTL、并且可以配置路由实现QOS内核模块：iptable_mangle 4.Raw表--&gt;两个链：OUTPUT、PREROUTING 作用：决定数据包是否被状态跟踪机制处理 内核模块：iptable_raw 优先级（由高而低）：raw -&gt; mangle -&gt; nat -&gt; filter iptables规则的组成部分：匹配条件： 网络层首部：SourceIP, DestinationIP, ... 传输层首部：SourtPort, DestinationPort, TCP Flags(SYN,ACK,FIN,URG,RST,PSH), ... 扩展模块引入的辅助检查机制： 跳转目标：-j target 内建的处理机制：ACCEPT, DROP, REJECT, SNAT, DNAT, MASQUERADE, MARK, LOG, ... 用户自定义链： 添加规则时需要考量的因素： (1) 实现的功能：用于判定将规则添加至哪个表； (2) 报文的流经位置：用于判断将规则添加至哪个链； (3) 报文的流向：判定规则中何为”源“，何为”目标“； (4) 匹配条件：用于编写正确的匹配规则； (a) 专用于某种应用的同类规则，匹配范围小的放前面； (b) 专用于某些应用的不同类规则，匹配到的可能性较多的放前面；同一类别的规则可使用自定义链单独存放； (c) 用于通用目的的规则放前面； filter表：过滤，”防火墙“意义的核心所在； INPUT，FORWARD，OUTPUT 语法结构iptables [-t 表名] 命令选项 ［链名］ ［条件匹配］ ［-j 目标动作或跳转］ 说明：表名、链名用于指定 iptables命令所操作的表和链，命令选项用于指定管理iptables规则的方式（比如：插入、增加、删除、查看等； 条件匹配用于指定对符合什么样条件的数据包进行处理；目标动作或跳转用于指定数据包的处理方式（比如允许通过、拒绝、丢弃、跳转（Jump）给其它链处理。 iptables [-t tables] COMMAND chain [-m matchname [per-match-options]] -j targetname [per-target-options] [-t tables] 指明是那个表 -t table： raw，mangle，nat，[filter] COMMAND 指明规则处理命令，使用大写字母，单个表示。 链管理： -N new 自定义一条新的规则链 -X 删除自定义链 -p 设置默认策略；对filter表中的链而言，其默认策略： ACCEPT:接受 DROP:丢弃 REJECT:拒绝 -E 重命名自定义链；应用技术不为0的自定义链，不能够被重命名，也不能被删除 规则管理: -I 插入一条规则 -A 追加一条规则 -D 删除一条规则 指明规则序号 指明规则本身 -R 替换指定链上的指定规则 -F 清空指定的规则链 -Z 置零 iptables的每条规则都有两个计数器 匹配到的报文个数 匹配到的所有报文的大小之和 查看： -L：列出指定链上的所有规则 -n 以数字格式显示地址和端口号 -v 详细信息 -vv -vvv -x 显示计数器结果的精确值 --line-numbers 显示规则序号 -S 显示指定链上的所有规则 chain 添加到哪个链 [-m matchname [per-match-options]] 扩展匹配条件 matchname匹配条件 [per-target-options] 扩展处理机制 target跳转目标 小写字母，做匹配条件定义 大写字母，做处理动作定义 格式： iptables [-t table] {-A|-C|-D} chain rule-specification iptables [-t table] -I chain [rulenum] rule-specification iptables [-t table] -R chain rulenum rule-specification iptables [-t table] -D chain rulenum iptables [-t table] -S [chain [rulenum]] iptables [-t table] {-F|-L|-Z} [chain [rulenum]] [options...] iptables [-t table] -N chain iptables [-t table] -X [chain] iptables [-t table] -P chain target iptables [-t table] -E old-chain-name new-chain-name rule-specification = [matches...] [target] match = -m matchname [per-match-options] target = -j targetname [per-target-options] 详细命令管理选项-A 在指定链的末尾添加（append）一条新的规则 -D 删除（delete）指定链中的某一条规则，可以按规则序号和内容删除 -I 在指定链中插入（insert）一条新的规则，默认在第一行添加 -R 修改、替换（replace）指定链中的某一条规则，可以按规则序号和内容替换 -L 列出（list）指定链中所有的规则进行查看 -E 重命名用户定义的链，不改变链本身 -F 清空（flush） -N 新建（new-chain）一条用户自己定义的规则链 -X 删除指定表中用户自定义的规则链（delete-chain） -P 设置指定链的默认策略（policy） -Z 将所有表的所有链的字节和数据包计数器清零 -n 使用数字形式（numeric）显示输出结果 -v 查看规则表详细信息（verbose）的信息 -V 查看版本(version) -h 获取帮助（help） 匹配条件：通用匹配（PARAMETERS）： [!] -s, --source address[/mask][,...]：检查报文的源IP地址是否符合此处指定的范围，或是否等于此处给定的地址； [!] -d, --destination address[/mask][,...]：检查报文的目标IP地址是否符合此处指定的范围，或是否等于此处给定的地址； 匹配所有地址写成0.0.0.0 [!] -p, --protocol protocol：匹配报文中的协议，可用值tcp, udp, udplite, icmp, icmpv6,esp, ah, sctp, mh 或者 &quot;all&quot;, 亦可以数字格式指明协议； -m, --match match：调用指定的扩展匹配模块来扩展匹配条件检查机制； [!] -i, --in-interface name：限定报文仅能够从指定的接口流入；only for packets entering the INPUT, FORWARD and PREROUTING chains. [!] -o, --out-interface name：限定报文仅能够从指定的接口流出；for packets entering the FORWARD, OUTPUT and POSTROUTING chains. 扩展匹配（MATCH EXTENSIONS） -m tcp --sport, --dport 隐式扩展：-p tcp：可直接使用tcp扩展模块的专用选项； [!] --source-port,--sport port[:port] 匹配报文源端口；可以给出多个端口，但只能是连续的端口范围 ； [!] --destination-port,--dport port[:port] 匹配报文目标端口；可以给出多个端口，但只能是连续的端口范围 ； [!] --tcp-flags mask comp 匹配报文中的tcp协议的标志位；Flags are: SYN ACK FIN RST URG PSH ALL NONE； mask：要检查的FLAGS list，以逗号分隔； comp：在mask给定的诸多的FLAGS中，其值必须为1的FLAGS列表，余下的其值必须为0； --tcp-flags SYN,ACK,FIN,RST SYN --tcp-flags ALL ALL --tcp-flags ALL NONE [!] --syn： --tcp-flags SYN,ACK,FIN,RST SYN -p udp：可直接使用udp协议扩展模块的专用选项： [!] --source-port,--sport port[:port] [!] --destination-port,--dport port[:port] [!] --icmp-type {type[/code]|typename} 0/0： echo reply 8/0：echo request 显式扩展：必须使用-m选项指明要调用的扩展模块的扩展机制； 1、multiport 以离散或连续的 方式定义多端口匹配条件，最多15个； [!] --source-ports,--sports port[,port|,port:port]...：指定多个源端口； [!] --destination-ports,--dports port[,port|,port:port]...：指定多个目标端口； # iptables -I INPUT -d 172.16.0.7 -p tcp -m multiport --dports 22,80,139,445,3306 -j ACCEPT 2、iprange 以连续地址块的方式来指明多IP地址匹配条件； [!] --src-range from[-to] [!] --dst-range from[-to] # iptables -I INPUT -d 172.16.0.7 -p tcp -m multiport --dports 22,80,139,445,3306 -m iprange --src-range 172.16.0.61-172.16.0.70 -j REJECT 3、time This matches if the packet arrival time/date is within a given range. --timestart hh:mm[:ss] --timestop hh:mm[:ss] [!] --weekdays day[,day...] [!] --monthdays day[,day...] --datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --kerneltz：使用内核配置的时区而非默认的UTC； 4、string This modules matches a given string by using some pattern matching strategy. --algo {bm|kmp} [!] --string pattern [!] --hex-string pattern --from offset --to offset ~]# iptables -I OUTPUT -m string --algo bm --string &quot;gay&quot; -j REJECT 5、connlimit Allows you to restrict the number of parallel connections to a server per client IP address (or client address block). --connlimit-upto n --connlimit-above n ~]# iptables -I INPUT -d 172.16.0.7 -p tcp --syn --dport 22 -m connlimit --connlimit-above 2 -j REJECT 6、limit This module matches at a limited rate using a token bucket filter. --limit rate[/second|/minute|/hour|/day] --limit-burst number ~]# iptables -I OUTPUT -s 172.16.0.7 -p icmp --icmp-type 0 -j ACCEPT 7、state The &quot;state&quot; extension is a subset of the &quot;conntrack&quot; module. &quot;state&quot; allows access to the connection tracking state for this packet. [!] --state state INVALID, ESTABLISHED, NEW, RELATED or UNTRACKED. NEW: 新连接请求； ESTABLISHED：已建立的连接； INVALID：无法识别的连接； RELATED：相关联的连接，当前连接是一个新请求，但附属于某个已存在的连接； UNTRACKED：未追踪的连接； state扩展： 内核模块装载： nf_conntrack nf_conntrack_ipv4 手动装载： nf_conntrack_ftp 追踪到的连接： /proc/net/nf_conntrack 调整可记录的连接数量最大值： /proc/sys/net/nf_conntrack_max 超时时长： /proc/sys/net/netfilter/*timeout* 处理动作（跳转目标）：-j targetname [per-target-options] 简单target： ACCEPT， DROP 扩展target： REJECT This is used to send back an error packet in response to the matched packet: otherwise it is equivalent to DROP so it is a terminating TARGET, ending rule traversal. --reject-with type The type given can be icmp-net-unreachable, icmp-host-unreachable, icmp-port-unreachable, icmp-proto-unreach‐ able, icmp-net-prohibited, icmp-host-prohibited, or icmp-admin-prohibited (*), which return the appropriate ICMP error message (icmp-port-unreachable is the default). LOG Turn on kernel logging of matching packets. --log-level --log-prefix 自定义链做为target： 保存和载入规则：保存：iptables-save &gt; /PATH/TO/SOME_RULE_FILE 重载：iptabls-restore &lt; /PATH/FROM/SOME_RULE_FILE -n, --noflush：不清除原有规则 -t, --test：仅分析生成规则集，但不提交 ================================================================================]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx配置指令（二）]]></title>
      <url>%2F2017%2F06%2F15%2Fnginx3%2F</url>
      <content type="text"><![CDATA[Nginx配置指令（二）客户端请求的相关配置： 1. keepalive_timeout 设定保持连接的超时时长，0表示禁止长连接；默认为75s；1234567891011Syntax: keepalive_timeout timeout [header_timeout];Default: keepalive_timeout 75s;Context: http, server, locationThe first parameter sets a timeout during which a keep-alive client connection will stay open on the server side. The zero value disables keep-alive client connections. The optional second parameter setsa value in the “Keep-Alive: timeout=time” response header field. Two parameters may differ.The “Keep-Alive: timeout=time” header field is recognized by Mozilla and Konqueror. MSIE closes keep-alive connections by itself in about 60 seconds. 2. keepalive_requests 在一次长连接上所允许请求的资源的最大数量，默认为100;12345678Syntax: keepalive_requests number;Default: keepalive_requests 100;Context: http, server, locationThis directive appeared in version 0.8.0.Sets the maximum number of requests that can be served through one keep-alive connection.After the maximum number of requests are made, the connection is closed. 3. keepalive_disable 对哪种浏览器禁用长连接；1234567891011Syntax: keepalive_disable none | browser ...;Default: keepalive_disable msie6;Context: http, server, locationDisables keep-alive connections with misbehaving browsers. The browser parameters specify which browsers will be affected. The value msie6 disables keep-alive connections with old versions of MSIE, once a POST request is received. The value safari disables keep-alive connections with Safari and Safari-like browsers on macOS and macOS-like operating systems. The value none enables keep-alive connections with all browsers. 4. send_timeout 向客户端发送响应报文的超时时长，此处，是指两次写操作之间的间隔时长；12345678Syntax: send_timeout time;Default: send_timeout 60s;Context: http, server, locationSets a timeout for transmitting a response to the client. The timeout is set only between two successive write operations, not for the transmission of the whole response. If the client does not receive anything within this time, the connection is closed. 5. client_body_buffer_size 用于接收客户端请求报文的body部分的缓冲区大小；默认为16k；超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置；上传数据量不大时，默认大小不必要修改。例如论坛等一次性上传较大数据时，需要调整默认大小。12345678Syntax: client_body_buffer_size size;Default: client_body_buffer_size 8k|16k;Context: http, server, locationSets buffer size for reading client request body. In case the request body is larger than the buffer, the whole body or only its part is written to a temporary file. By default, buffer size is equal to two memory pages. This is 8K on x86, other 32-bit platforms, and x86-64. It is usually 16K on other 64-bit platforms. 6. client_body_temp_path 设定用于存储客户端请求报文的body部分的临时存储路径及子目录结构和数量； 16进制的数字； client_body_temp_path /var/tmp/ [2 [1 [1]]] 1：表示用一位16进制数字表示一级子目录；0-f 2：表示用2位16进程数字表示二级子目录：00-ff 2：表示用2位16进程数字表示三级子目录：00-ff 12345678910111213Syntax: client_body_temp_path path [level1 [level2 [level3]]];Default: client_body_temp_path client_body_temp;Context: http, server, locationDefines a directory for storing temporary files holding client request bodies. Up to three-level subdirectory hierarchy can be used under the specified directory. For example, in the following configuration client_body_temp_path /spool/nginx/client_temp 1 2;a path to a temporary file might look like this: /spool/nginx/client_temp/7/45/00000123457 对客户端进行限制的相关配置：1. limit_rate; 限制响应给客户端的传输速率，单位是bytes/second，0表示无限制；12345678910111213141516171819202122232425Syntax: limit_rate rate;Default: limit_rate 0;Context: http, server, location, if in locationLimits the rate of response transmission to a client. The rate is specified in bytes per second.The zero value disables rate limiting. The limit is set per a request, and so if a client simultaneously opens two connections,the overall rate will be twice as much as the specified limit.Rate limit can also be set in the $limit_rate variable. It may be useful in cases where rate should be limited depending on a certain condition: server &#123; if ($slow) &#123; set $limit_rate 4k; &#125; ... &#125;Rate limit can also be set in the “X-Accel-Limit-Rate” header field of a proxied server response. This capability can be disabled using the proxy_ignore_headers, fastcgi_ignore_headers,uwsgi_ignore_headers, and scgi_ignore_headers directives. 2. limit_except method 限制对指定的请求方法之外的其它方法的使用客户端；12345678910111213141516Syntax: limit_except method ... &#123; ... &#125;Default: —Context: locationLimits allowed HTTP methods inside a location. The method parameter can be one of the following: GET, HEAD, POST, PUT, DELETE, MKCOL, COPY, MOVE, OPTIONS, PROPFIND, PROPPATCH, LOCK, UNLOCK, or PATCH. Allowing the GET method makes the HEAD method also allowed. Access to other methods canbe limited using the ngx_http_access_module and ngx_http_auth_basic_module modules directives: limit_except GET &#123; allow 192.168.1.0/32; deny all; &#125;Please note that this will limit access to all methods except GET and HEAD. 文件操作优化的配置:1. aio 详情：http://www.tuicool.com/articles/AvmUz2b123456789101112Syntax: aio on | off | threads[=pool];Default: aio off;Context: http, server, locationThis directive appeared in version 0.8.11.Enables or disables the use of asynchronous file I/O (AIO) on FreeBSD and Linux: location /video/ &#123; aio on; output_buffers 1 64k; &#125; 2. directio size 在Linux主机启用O_DIRECT标记，此处意味文件大于等于给定的大小时使用，例如directio 4m;1234567891011121314Syntax: directio size | off;Default: directio off;Context: http, server, locationThis directive appeared in version 0.7.7.Enables the use of the O_DIRECT flag (FreeBSD, Linux), the F_NOCACHE flag (macOS), or the directio() function (Solaris), when reading files that are larger than or equal to the specified size. The directive automatically disables (0.7.15) the use of sendfile for a given request. It can be useful for serving large files: directio 4m;or when using aio on Linux. 3. open_file_cache open_file_cache max=N [inactive=time]; nginx可以缓存以下三种信息： (1) 文件的描述符、文件大小和最近一次的修改时间； (2) 打开的目录结构； (3) 没有找到的或者没有权限访问的文件的相关信息； max=N：可缓存的缓存项上限；达到上限后会使用LRU算法实现缓存管理； inactive=time：缓存项的非活动时长，在此处指定的时长内未被命中的或命中的次数少于open_file_cache_min_uses指令所指定的次数的缓存项即为非活动项；12345678910111213141516171819202122232425262728Syntax: open_file_cache off;open_file_cache max=N [inactive=time];Default: open_file_cache off;Context: http, server, locationConfigures a cache that can store: open file descriptors, their sizes and modification times; information on existence of directories; file lookup errors, such as “file not found”, “no read permission”, and so on. Caching of errors should be enabled separately by the open_file_cache_errors directive. The directive has the following parameters:max sets the maximum number of elements in the cache; on cache overflow the least recently used (LRU) elements are removed; inactive defines a time after which an element is removed from the cache if it has not been accessed during this time; by default, it is 60 seconds; off disables the cache. Example: open_file_cache max=1000 inactive=20s; open_file_cache_valid 30s; open_file_cache_min_uses 2; open_file_cache_errors on; 4. open_file_cache_valid 缓存项有效性的检查频率；默认为60s;12345Syntax: open_file_cache_valid time;Default: open_file_cache_valid 60s;Context: http, server, locationSets a time after which open_file_cache elements should be validated. 5. open_file_cache_min_uses 在open_file_cache指令的inactive参数指定的时长内，至少应该被命中多少次方可被归类为活动项；123456Syntax: open_file_cache_min_uses number;Default: open_file_cache_min_uses 1;Context: http, server, locationSets the minimum number of file accesses during the period configured by the inactive parameter of the open_file_cache directive, required for a file descriptor to remain open in the cache. 6. open_file_cache_errors 是否缓存查找时发生错误的文件一类的信息；12345Syntax: open_file_cache_errors on | off;Default: open_file_cache_errors off;Context: http, server, locationEnables or disables caching of file lookup errors by open_file_cache.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx配置指令（一）]]></title>
      <url>%2F2017%2F06%2F14%2Fnginx2%2F</url>
      <content type="text"><![CDATA[Nginx配置指令（一）main配置段常见的配置指令：分类： 正常运行必备的配置 优化性能相关的配置 用于调试及定位问题相关的配置 事件驱动相关的配置 正常运行必备的配置： 1、user123456789Syntax: user user [group];Default: user nobody nobody;Context: mainDefines user and group credentials used by worker processes. If group is omitted, a group whose name equals that of user is used.``` ### 2、pid; 指定存储nginx主进程进程号码的文件路径； Syntax: pid file;Default: pid nginx.pid;Context: main Defines a file that will store the process ID of the main process.1234### 3、include file | mask;指明包含进来的其它配置文件片断； Syntax: include file | mask;Default: —Context: any Includes another file, or files matching the specified mask, into configuration.Included files should consist of syntactically correct directives and blocks.1234 ### 4、load_module file;指明要装载的动态模块； Syntax: load_module file;Default: —Context: main This directive appeared in version 1.9.11. Loads a dynamic module. Example: load_module modules/ngx_mail_module.so; 12345678## 性能优化相关的配置：**1、worker_processes number | auto;****worker**: 进程的数量；通常应该等于小于当前主机的cpu的物理核心数；**auto**：当前主机物理CPU核心数； Syntax: worker_processes number | auto;Default: worker_processes 1;Context: main Defines the number of worker processes. The optimal value depends on many factors including (but not limited to) the number of CPU cores,the number of hard disk drives that store data, and load pattern. When one is in doubt, setting it tothe number of available CPU cores would be a good start (the value “auto” will try to autodetect it). The auto parameter is supported starting from versions 1.3.8 and 1.2.5. 123**2、worker_cpu_affinity cpumask ...;**把进程与CPU绑定； Syntax: worker_cpu_affinity cpumask …;worker_cpu_affinity auto [cpumask];Default: —Context: main Binds worker processes to the sets of CPUs. Each CPU set is represented by a bitmask of allowed CPUs.There should be a separate set defined for each of the worker processes. By default, worker processesare not bound to any specific CPUs. For example, worker_processes 4; worker_cpu_affinity 0001 0010 0100 1000; binds each worker process to a separate CPU, while worker_processes 2; worker_cpu_affinity 0101 1010; binds the first worker process to CPU0/CPU2, and the second worker process to CPU1/CPU3.The second example is suitable for hyper-threading. The special value auto (1.9.10) allows binding worker processes automatically to available CPUs: worker_processes auto; worker_cpu_affinity auto; The optional mask parameter can be used to limit the CPUs available for automatic binding: worker_cpu_affinity auto 01010101; The directive is only available on FreeBSD and Linux. 12345**3、worker_priority number;**指定worker进程的nice值，设定worker进程优先级；[-20,20]默认都为0 Syntax: worker_priority number;Default: worker_priority 0;Context: main Defines the scheduling priority for worker processes like it is done by the nice command:a negative number means higher priority. Allowed range normally varies from -20 to 20. Example: worker_priority -10; 123**4、worker_rlimit_nofile number;**worker进程所能够打开的文件数量上限； Syntax: worker_rlimit_nofile number;Default: —Context: main Changes the limit on the maximum number of open files (RLIMIT_NOFILE) for workerprocesses. Used to increase the limit without restarting the main process.123456## 调试、定位问题：**1、daemon on|off;** 是否以守护进程方式运行Nignx； Syntax: daemon on | off;Default: daemon on;Context: main Determines whether nginx should become a daemon. Mainly used during development.123**2、master_process on|off;**是否以master/worker模型运行nginx；默认为on； Syntax: master_process on | off;Default: master_process on;Context: main Determines whether worker processes are started. This directive is intended fornginx developers.1234 **3、error_log file [level];**错误日志文件； Syntax: error_log file [level];Default: error_log logs/error.log error;Context: main, http, mail, stream, server, location Configures logging. Several logs can be specified on the same level (1.5.2). If on themain configuration level writing a log to a file is not explicitly defined, the defaultfile will be used. The first parameter defines a file that will store the log. The special value stderrselects the standard error file. Logging to syslog can be configured by specifying the“syslog:” prefix. Logging to a cyclic memory buffer can be configured by specifying the“memory:” prefix and buffer size, and is generally used for debugging (1.7.11). The second parameter determines the level of logging, and can be one of the following:debug, info, notice, warn, error, crit, alert, or emerg. Log levels above are listed inthe order of increasing severity. Setting a certain log level will cause all messages ofthe specified and more severe log levels to be logged. For example, the default levelerror will cause error, crit, alert, and emerg messages to be logged. If this parameteris omitted then error is used. For debug logging to work, nginx needs to be built with –with-debug, see “Adebugging log”. The directive can be specified on the stream level starting from version 1.7.11, andon the mail level starting from version 1.9.0.12345678910**ps：以上配置适用于开发测试环节**；## 事件驱动相关的配置:放在events配置块内；**1、worker_connections number;**每个worker进程所能够打开的最大并发连接数数量； Syntax: worker_connections number;Default: worker_connections 512;Context: events Sets the maximum number of simultaneous connections that can be opened by a worker process. It should be kept in mind that this number includes all connections (e.g. connections with proxiedservers, among others), not only connections with clients. Another consideration is that the actualnumber of simultaneous connections cannot exceed the current limit on the maximum number of open files,which can be changed by worker_rlimit_nofile.1234 **2、use method;**指明并发连接请求的处理方法； Syntax: use method;Default: —Context: events Specifies the connection processing method to use. There is normally no need to specify it explicitly,because nginx will by default use the most efficient method.1234567use epoll; **3、accept_mutex on | off;**处理新的连接请求的方法；on意味着由各worker轮流处理新请求;Off意味着每个新请求的到达都会通知所有的worker进程； Syntax: accept_mutex on | off;Default: accept_mutex off;Context: events If accept_mutex is enabled, worker processes will accept new connections by turn. Otherwise, all workerprocesses will be notified about new connections, and if volume of new connections is low, some of theworker processes may just waste system resources. There is no need to enable accept_mutex on systems that support the EPOLLEXCLUSIVE flag (1.11.3) orwhen using reuseport. Prior to version 1.11.3, the default value was on.1234567891011## http协议的相关配置：放在HTTP配置块内；配置在HTTP内server外，配置对所有server生效。### 与套接字相关的配置：**1. server**配置一个虚拟主机 Syntax: server { … }Default: —Context: http Sets configuration for a virtual server. There is no clear separation between IP-based(based on the IP address) and name-based (based on the “Host” request header field)virtual servers. Instead, the listen directives describe all addresses and ports thatshould accept connections for the server, and the server_name directive lists all server names.Example configurations are provided in the “How nginx processes a request” document.12345678**2. listen**监听的端口格式有三种，常用前两种；此处只介绍，格式用法，详细说明请查看：http://nginx.org/en/docs/http/ngx_http_core_module.html#listen Syntax: listen address[:port] [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off| [keepidle]:[keepintvl]:[keepcnt]]; listen port [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; listen unix:path [default_server] [ssl] [http2 | spdy] [proxy_protocol] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; Default: listen :80 | :8000;Context: server Sets the address and port for IP, or the path for a UNIX-domain socket on which theserver will accept requests. Both address and port, or only address or only port can be specified.An address may also be a hostname, for example: listen 127.0.0.1:8000; listen 127.0.0.1; listen 8000; listen *:8000; listen localhost:8000; 123456789101112131415161718192021222324252627**3. server_name**主机名指明虚拟主机的主机名称；后可跟多个由空白字符分隔的字符串；支持*通配任意长度的任意字符； server_name *.test.com 或 server_name www.test.*支持~起始的字符做正则表达式模式匹配； server_name ~^www\d+\.test\.com$匹配机制： (1) 首先是字符串精确匹配; (2) 左侧*通配符； (3) 右侧*通配符； (4) 正则表达式； 此处只介绍，格式用法，详细说明请查看：http://nginx.org/en/docs/http/ngx_http_core_module.html#server_name Syntax: server_name name …;Default: server_name “”;Context: server Sets names of a virtual server, for example: server { server_name example.com www.example.com; } The first name becomes the primary server name. Server names can include an asterisk (“*”) replacing the first or last part of a name: server { server_name example.com *.example.com www.example.*; } Such names are called wildcard names. The first two of the names mentioned above can be combined in one: server { server_name .example.com; 1234**4. sendfile on | off;**关于sendfile的具体介绍：http://www.oschina.net/question/54100_33185 Syntax: sendfile on | off;Default: sendfile off;Context: http, server, location, if in location Enables or disables the use of sendfile(). Starting from nginx 0.8.12 and FreeBSD 5.2.1, aio can be used to pre-load data for sendfile(): location /video/ { sendfile on; tcp_nopush on; aio on; } In this configuration, sendfile() is called with the SF_NODISKIO flag which causes it not to block ondisk I/O, but, instead, report back that the data are not in memory. nginx then initiates an asynchronousdata load by reading one byte. On the first read, the FreeBSD kernel loads the first 128K bytes of a fileinto memory, although next reads will only load data in 16K chunks. This can be changed using the read_ahead directive. Before version 1.7.11, pre-loading could be enabled with aio sendfile;. 1234**5. tcp_nodelay on | off;**开启或关闭nginx使用TCP_NODELAY选项的功能。 这个选项仅在将连接转变为长连接的时候才被启用。 Syntax: tcp_nodelay on | off;Default: tcp_nodelay on;Context: http, server, location Enables or disables the use of the TCP_NODELAY option.The option is enabled only when a connection is transitioned into the keep-alive state.1234**6. tcp_nopush on | off;**开启或者关闭nginx在FreeBSD上使用TCP_NOPUSH套接字选项， 在Linux上使用TCP_CORK套接字选项。选项仅在使用sendfile的时候才开启。 开启此选项允许在Linux和FreeBSD 4.*上将响应头和正文的开始部分一起发送；一次性发送整个文件。 Syntax: tcp_nopush on | off;Default: tcp_nopush off;Context: http, server, location Enables or disables the use of the TCP_NOPUSH socket option on FreeBSD or the TCP_CORK socket option on Linux. The options are enabled only when sendfile is used. Enabling the option allows sending the response header and the beginning of a file in one packet, on Linux and FreeBSD 4.*;sending a file in full packets.12345678详细介绍sendfile、tcp_nodelay、tcp_nopush之间的关系请参考：http://www.cnblogs.com/wajika/p/6573014.html### 定义路径的相关配置：**1. root**设置web资源路径映射；用于指明用户请求的url所对应的本地文件系统上的文档所在目录路径； Syntax: root path;Default: root html;Context: http, server, location, if in location Sets the root directory for requests. For example, with the following configuration location /i/ { root /data/w3; } The /data/w3/i/top.gif file will be sent in response to the “/i/top.gif” request. The path value can contain variables, except $document_root and $realpath_root. A path to the file is constructed by merely adding a URI to the value of the root directive.If a URI has to be modified, the alias directive should be used.12345**2. location** 在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请求的URI来检查定义的所有location，并找出一个最佳匹配，而后应用其配置； Syntax: location [ = | ~ | ~* | ^~ ] uri { … } location @name { … }Default: —Context: server, location =：对URI做精确匹配；~：对URI做正则表达式模式匹配，区分字符大小写；~：对URI做正则表达式模式匹配，不区分字符大小写；^~：对URI的左半部分做匹配检查，不区分字符大小写；不带符号：匹配起始于此uri的所有的url；匹配优先级：=, ^~, ～/～，不带符号； Let’s illustrate the above by an example: location = / { [ configuration A ]} location / { [ configuration B ]} location /documents/ { [ configuration C ]} location ^~ /images/ { [ configuration D ]} location ~* .(gif|jpg|jpeg)$ { [ configuration E ]} The “/” request will match configuration A,the “/index.html” request will match configuration B,the “/documents/document.html” request will match configuration C,the “/images/1.gif” request will match configuration D,the “/documents/1.jpg” request will match configuration E.123456789**3. alias**定义路径别名，文档映射的另一种机制；仅能用于location上下文； 注意：location中使用root指令和alias指令的意义不同； (a) root，给定的路径对应于location中的/uri/左侧的/； (b) alias，给定的路径对应于location中的/uri/右侧的/； Syntax: alias path;Default: —Context: location location ~* /images/ { root /data/pictures/; 在/data/pictures目录下找image/s目录下的文件}location ^~ /images/ { alias /data/pictures/; 别名，访问/images等于访问/date/pictures/} 12**4. index** Syntax: index file …;Default: index index.html;Context: http, server, location Defines files that will be used as an index. The file name can contain variables. Files are checked in the specified order. The last element of the list can be a file with an absolute path. Example: index index.$geo.html index.0.html /index.html; It should be noted that using an index file causes an internal redirect, and the request can be processed in a different location. For example, with the following configuration: location = / { index index.html; } location / { ... } a “/” request will actually be processed in the second location as “/index.html”.12**5. error_page** Syntax: error_page code … [=[response]] uri;Default: —Context: http, server, location, if in location Defines the URI that will be shown for the specified errors. A uri value can contain variables. Example: error_page 404 /404.html; error_page 500 502 503 504 /50x.html; error_page 404 =200 /notfound.html;location = /notfound.html { root /data/nginx/error_pages;} #自定义error页，并且也能更改返回状态码。``` 客户端请求的相关配置：1.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx安装以及配置文件]]></title>
      <url>%2F2017%2F06%2F13%2Fnginx1%2F</url>
      <content type="text"><![CDATA[Nginx安装以及配置文件Nginx功能概述：HTTP基础功能： 处理静态文件，索引文件以及自动索引； 反向代理加速（无缓存），简单的负载均衡和容错； FastCGI，简单的负载均衡和容错； 模块化的结构，包括gzipping，byte ranges，chunked responses，以及SSI-filter。在SSI过滤器中，到同一个proxy或者FastCGI的多个子请求并发处理； SSL和TLS SNI 支持； IMAP/POP3代理服务功能： 使用外部HTTP认证服务器重定向用户到IMPA/POP3后端； 使用外部HTTP认证服务器认证用户后连接重定向到内部的SMTP后端； 认证方法： POP3：POP3 USER/PASS，APOP，AUTH LOGIN PLAIN CRAM-MD5； IMAP：IMAP LOGIN； SMTP：AUTH LOGIN PLAIN CRAM-MD5； SSL支持； 在IMAP和POP3模式下的STARTTLS和STLS支持； 支持的操作系统： FreeBSD 3.x, 4.x, 5.x, 6.x i386; FreeBSD 5.x, 6.x amd64; Linux 2.2, 2.4, 2.6 i386; Linux 2.6 amd64; Solaris 8 i386; Solaris 9 i386 and sun4u; Solaris 10 i386; MacOS X (10.4) PPC; 结构与扩展： 一个主进程和多个工作进程。工作晋城市单线程的，且不需要特殊授权即可运行； kqueue (FreeBSD 4.1+), epoll (Linux 2.6+), rt signals (Linux 2.2.19+), /dev/poll (Solaris 7 11/99+), select, 以及 poll 支持； kqueue支持的不同功能包括 EV_CLEAR, EV_DISABLE （临时禁止事件）， NOTE_LOWAT, EV_EOF,有效数据的数目，错误代码； sendfile (FreeBSD 3.1+), sendfile (Linux 2.2+), sendfile64 (Linux 2.4.21+), 和 sendfilev (Solaris 87/01+) 支持； 输入过滤 (FreeBSD 4.1+) 以及 TCP_DEFER_ACCEPT (Linux 2.4+) 支持； 10,000 非活动的 HTTP keep-alive 连接仅需要 2.5M 内存。 最小化的数据拷贝操作； 其他HTTP功能： 基于IP和名称的虚拟主机服务； Memcached的GET接口； 支持keep-alive的管道连接； 灵活简单的配置； 重新配置和在线升级而无需中断客户的工作进程； 可定制的访问日志，日志写入缓存，以及快捷的日志回卷； 4xx-5xx错误代码重定向； 基于PCRE的rewrite重写模块； 基于客户端的IP地址和HTTP基本认证的访问控制； PUT，DELETE和MKCOL方法； 支持FLV（Flash视频）； 带宽限制； 实验特性： 内嵌的perl； 通过 aio_read()/aio_write()的套接字工作的实验模块，仅在FreeBSD下。 对线程的实验化支持，FreeBSD 4.x的实现基于rdork(); 为什么选择NginxNginx是一个高性能的Web和反向代理服务器，它具有很多非常优越的特性： 作为Web服务器： 相比Apache，Nginx使用更少的资源，支持更多的并发连接，体现更高的效率，这点使Nginx收到了虚拟主机提供商的欢迎，能够高达50,000个并发连接数请求的响应。Nginx使用epoll &amp; kqueue作为开发模型。 作为负载均衡器： Nginx既可以在内部支持Rails和PHP，也可以支持作为HTTP代理服务器对外进行服务。Nginx用C编写，不论是系统资源开销还是CPU使用效率都比Perlbal要好得多。 作为邮件代理服务器： Nginx勇士也是一个非常优秀的邮件代理服务器（最早开发这个产品的目的之一也是作为邮件代理服务器）， Nginx安装非常简单，配合文件非常简洁（还支持perl语法），Bugs非常少的服务器：：Nginx启动特别容易，并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。还能够在不间断服务的情况下进行软件版本的升级。 安装Nginx Nginx官网：http://nginx.org/ Nginx官网提供了三个类型的版本： Mainline version：Mainline 是 Nginx 目前主力在做的版本，可以说是开发版 Stable version：最新稳定版，生产环境上建议使用的版本 Legacy versions：遗留的老版本的稳定版 当前稳定版：nginx-1.12.0 安装方法： 编译安装 直接从yum仓库安装 官网给出的预编译包yum源配置文档：1234567891011121314Pre-Built Packages for Stable versionTo set up the yum repository for RHEL/CentOS, create the file named/etc/yum.repos.d/nginx.repo with the following contents: [nginx] name=nginx repo baseurl=http://nginx.org/packages/OS/OSRELEASE/$basearch/ gpgcheck=0 enabled=1Replace “OS” with “rhel” or “centos”, depending on the distribution used, and “OSRELEASE”with “6” or “7”, for 6.x or 7.x versions, respectively. 把&quot;OS&quot;替换为&quot;rhel&quot;或者&quot;centos&quot;。这取决于你所使用的。把&quot;OSRELEASE&quot;替换为&quot;6&quot;或者&quot;7&quot;分别为&quot;6.x&quot;和&quot;7.x&quot;的版本。 ps：在Centos7中。安装光盘中的yum仓库已经内置Nginx的安装包，直接yum安装即可。 编译安装： 准备编译环境 ~]# yum groupinstall “Development Tools” “Server Platform Development” ~]# yum install pcre-devel openssl-devel zlib-devel 创建Nginx执行用户 ~]# useradd -r nginx 安装Nginx ~]# tar -zxvf nginx-1.x.tar.gz ~]# cd nginx-1.x/ ~]# ./configure --prefix=/usr/local/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_dav_module --with-http_stub_status_module --with-threads --with-file-aio ~]# make ~]# make install 使用nginx -V来查看安装了那些模块。 ps:此处配置仅为本次实验有效，具体配置，视生产情况而定。使用./configure –help,可以查看Nginx支持那些选项。 自定义unit文件 路径：/usr/lib/systemd/system/nginx.service ps：此文件需手动配置可以设置开机自启。此操作仅编译安装时使用。 启动nginx ~]# systemctl start nginx 或 ~]# 绝对路径下/nginx/sbin/nginx -c 绝对路径下/nginx/conf/nginx.conf 使用ss -tnl查看80端口是否存在，存在则启动成功。 Nginx配置文件Nginx主配置文件是nginx.conf。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125# For more information on configuration, see:# * Official English Documentation: http://nginx.org/en/docs/# * Official Russian Documentation: http://nginx.org/ru/docs/#用户user nginx;#工作进程数worker_processes auto;#错误日志存放路径error_log /var/log/nginx/error.log;#定义进程pidpid /run/nginx.pid;#可动态装载的模块，怎么装载，装在哪些，都是/usr/share/nginx/modules/*.conf# Load dynamic modules. See /usr/share/nginx/README.dynamic.include /usr/share/nginx/modules/*.conf;#配置事件驱动模型=一个进程响应1024个请求。当前主机一共可响应请求数=worker_processes*worker_connectionsevents &#123; worker_connections 1024;&#125;#配置http服务，在server外，所有server共用，在server内，仅当前server启用http &#123;#访问日志的日志格式 #main 格式名称#$remote_addr 客户端地址#$remote_user 客户端远程用户#$time_local 本地时间#$request 请求，可以理解为URL，请求报文的起始行&lt;method&gt;&lt;URL&gt;&lt;VERSION&gt;#$status 状态响应码#$body_bytes_sent 报文主体字节数#$http_referer 引用，从哪来，怎么到当前地址的#$http_user_agent 客户端代理，用的是什么浏览器#$http_x_forwarded_for 代理服务器，代理转发地址 log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;#访问日志文件路径 调用文件格式 access_log /var/log/nginx/access.log main;#下面几个用来控制网络连接功能的#内核直接封装响应报文，不经过用户空间，可以提升性能 sendfile on;# tcp_nopush on; tcp_nodelay on;#保持连接。超时时长 keepalive_timeout 65; types_hash_max_size 2048;#包含那种mime类型 默认类型，把每个文件识别成8进制的数据流 include /etc/nginx/mime.types; default_type application/octet-stream; # Load modular configuration files from the /etc/nginx/conf.d directory. # See http://nginx.org/en/docs/ngx_core_module.html#include # for more information.#模块化配置，可以把自定义的虚拟主机放到此目录下 include /etc/nginx/conf.d/*.conf;#一个server代表一个虚拟主机 server &#123;#监听的端口，指令可以使用多次 listen 80 default_server; #默认虚拟主机 listen [::]:80 default_server;#主机名 server_name _;#默认网页/路径 root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf;#自定义配置 location / &#123; &#125;#自定义错误页 error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125;#https工作配置# Settings for a TLS enabled server.## server &#123;# listen 443 ssl http2 default_server;# listen [::]:443 ssl http2 default_server;# server_name _;# root /usr/share/nginx/html;## ssl_certificate &quot;/etc/pki/nginx/server.crt&quot;;# ssl_certificate_key &quot;/etc/pki/nginx/private/server.key&quot;;# ssl_session_cache shared:SSL:1m;# ssl_session_timeout 10m;# ssl_ciphers HIGH:!aNULL:!MD5;# ssl_prefer_server_ciphers on;## # Load configuration files for the default server block.# include /etc/nginx/default.d/*.conf;## location / &#123;# &#125;## error_page 404 /404.html;# location = /40x.html &#123;# &#125;## error_page 500 502 503 504 /50x.html;# location = /50x.html &#123;# &#125;# &#125;&#125; 配置文件：主配置文件的配置指令： directive value [value2 ...]; 注意： (1) 指令必须以分号结尾； (2) 支持使用配置变量； 内建变量：由Nginx模块引入，可直接引用； 自定义变量：由用户使用set命令定义； set variable_name value; 引用变量：$variable_name 主配置文件结构： main block：主配置段，也即全局配置段； event { ... }：事件驱动相关的配置； http { ... }：http/https 协议相关的配置段； mail { ... } stream { ... } http协议相关的配置结构： http { ... ...： 各server的公共配置 server { ... }： 每个server用于定义一个虚拟主机； server { ... listen server_name root alias location [OPERATOR] URL { ... if CONDITION { ... } } } }]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[lamp]]></title>
      <url>%2F2017%2F06%2F06%2Flamp%2F</url>
      <content type="text"><![CDATA[配置LAMP–fastcgi模式因为CentOS6上PHP-5.3.2默认不支持fpm机制，并且httpd-2.2默认不支持fcgi协议，所以此模式只在CentOS7上实验，CentOS6.想实现需要编译安装。 一、结构图 用三台虚拟机来模拟服务器： 172.16.2.10--http服务器 172.16.2.20--php-fpm服务器 172.16.2.30--mariadb服务器 二、配置1.配置mariadb 在2.30的主机上安装mariadb ~]# yum install mariadb-server 修改配置文件12345[root@localhost ~]# vim /etc/my.cnf.d/server.cnf# this is read by the standalone daemon and embedded servers[server] #在server下添加skip_name_resolve=ON #跳过名称解析innodb_file_per_table=ON #将共享表空间改为独立表空间 启动服务 ~]# systemctl start mariadb.service 创建数据库并重启服务12345678910111213141516[root@localhost ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 2Server version: 5.5.52-MariaDB MariaDB ServerCopyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.MariaDB [(none)]&gt; create database testdb; #创建数据库Query OK, 1 row affected (0.01 sec)MariaDB [(none)]&gt; exitBye[root@localhost ~]# systemctl restart mariadb.service [root@localhost ~]# 2.配置php-fpm在2.20主机上安装php-fpm以及php与mariadb的驱动php-mysql ~]# yum install -y php-fpm php-mysql 修改配置文件 需要修改： listen = 172.16.2.20:9000 #监听本机IP和端口，这里填本机IP listen.allowed_clients = 172.26.2.10 #允许那些客户端连接这里填httpd的IP 取消注释： pm.status_path = /status #查看状态信息 ping.path = /ping #查看网络信息 ping.response = pong chdir = /var/www #网页文件存放目录 php_value[session.save_path] = /var/lib/php/session #PHP的session的存放路径，默认没有，需要手动创建，并改属主属组，为apache 创建所需文件并改属主属组12345678910[root@localhost ~]# mkdir -pv /var/www/htmlmkdir: created directory ‘/var/www’mkdir: created directory ‘/var/www/html’[root@localhost ~]# chown -R apache.apache /var/www/[root@localhost ~]# [root@localhost ~]# mkdir -pv /var/lib/php/session mkdir: created directory ‘/var/lib/php/session’[root@localhost ~]# chown -R apache.apache /var/lib/php/session [root@localhost ~]# 启动服务 ~]# systemctl start php-fpm 3.配置httpd 在2.10主机上安装httpd ~]# yum install httpd 修改配置文件12345678910[root@localhost ~]# vim /etc/httpd/conf/httpd.conf## ServerName gives the name and port that the server uses to identify itself.# This can often be determined automatically, but we recommend you specify# it explicitly to prevent problems during startup.## If your host doesn&apos;t have a registered DNS name, enter its IP address here.#ServerName 172.16.2.10:80 #这里改为本机IP，因为httpd在本台主机上 创建虚拟主机1234567891011121314[root@localhost ~]# vim /etc/httpd/conf.d/virtual.confDirectoryIndex index.php&lt;VirtualHost *:80&gt; ServerName 172.16.2.10 #服务器名写httpd的IP DocumentRoot &quot;/var/www/html/&quot; ProxyRequests Off ProxyPassMatch ^/(.*\.php)$ fcgi://172.16.2.20:9000/var/www/html/$1 #这里写php-fpm主机的IP &lt;Directory &quot;/var/www/html/&quot;&gt; Options None AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt; 在php-fpm主机上创建php测试页并重启服务1234567[root@localhost ~]# cd /var/www/html/[root@localhost html]# vim index.php&lt;?php phpinfo();?&gt;[root@localhost html]# systemctl restart php-fpm 浏览器输入httpd的ip： 页面成功显示 表示httpd与php-fpm之间连接通信正常 三、配置PhpMyAdmin1.在php-fpm和httpd主机上，配置phpmyadmin。 123456789101112131415161718[root@localhost ~]# unzip phpMyAdmin-4.0.10.20-all-languages.zip[root@localhost ~]# lltotal 7292-rw-------. 1 root root 2642 Jun 6 2017 anaconda-ks.cfgdrwxr-xr-x 9 root root 4096 Mar 28 21:03 phpMyAdmin-4.0.10.20-all-languages-rw-r--r-- 1 root root 7457007 Jun 5 22:03 phpMyAdmin-4.0.10.20-all-languages.zip把解压后的文件改名后放到/var/www/html/目录下[root@localhost ~]# mv phpMyAdmin-4.0.10.20-all-languages pma[root@localhost ~]# lltotal 7292-rw-------. 1 root root 2642 Jun 6 2017 anaconda-ks.cfg-rw-r--r-- 1 root root 7457007 Jun 5 22:03 phpMyAdmin-4.0.10.20-all-languages.zipdrwxr-xr-x 9 root root 4096 Mar 28 21:03 pma[root@localhost ~]# mv pma /var/www/html/[root@localhost ~]# 修改pma的属主数组123456[root@localhost html]# chown -R apache.apache pma[root@localhost html]# lltotal 8-rw-r--r-- 1 root root 22 Jun 5 23:25 index.phpdrwxr-xr-x 9 apache apache 4096 Mar 28 21:03 pma[root@localhost html]# 修改配置文件12345678910[root@localhost pma]# mv config.sample.inc.php config.inc.php[root@localhost pma]# vim config.inc.php 修改cfg[&apos;Servers&apos;][$i][&apos;host&apos;] = &apos;172.16.2.30&apos;; #这里改为mariadb的IPcfg[&apos;blowfish_secret&apos;] = &apos;qweqweqwehh8b7c6d&apos;; /* YOU MUST FILL IN THIS FOR COOKIE AUTH! */ #在第一个选项后输入即为随机字符，不能输入&apos;/&apos;[root@localhost pma]# vim libraries/config.default.php修改cfg[&apos;Servers&apos;][$i][&apos;host&apos;] = &apos;172.16.2.30&apos;; #这里改为mariadb的IP 四、在mariadb上创建用户授权；123456789101112131415161718192021[root@localhost ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 2Server version: 5.5.52-MariaDB MariaDB ServerCopyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;172.16.2.10&apos; IDENTIFIED BY &apos;111111&apos;;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;172.16.2.20&apos; IDENTIFIED BY &apos;111111&apos;;Query OK, 0 rows affected (0.01 sec)MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;172.16.2.30&apos; IDENTIFIED BY &apos;111111&apos;;Query OK, 0 rows affected (0.01 sec)MariaDB [(none)]&gt; exitBye[root@localhost ~]# 五、重启所有主机服务并测试；httpd主机 [root@localhost ~]# systemctl restart httpd [root@localhost ~]# php-fpm主机 [root@localhost ~]# systemctl restart php-fpm [root@localhost ~]# mariadb主机 [root@localhost ~]# systemctl restart mariadb [root@localhost ~]# 打开网页输入172.16.2.10/pma/index.php 成功。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[配置DNS解析练习]]></title>
      <url>%2F2017%2F06%2F01%2Fdnstest%2F</url>
      <content type="text"><![CDATA[DNS操作一、配置一个正向解析区（输入域名解析出IP）1.在主配置文件中（/etc/named.conf）或主配置文件辅助配置文件（/etc/named.rfc1912.zones）中实现； 格式： zone &quot;ZONE_NAME&quot; IN { type {master|slave|hint|forward}; file &quot;ZONE_NAME.zone&quot;; }; 1234567#末尾添加一个区域#并把文件指向lee.com.zonezone &quot;lee.com&quot; IN &#123; type master; file &quot;lee.com.zone&quot;;&#125;; 2.创建区域文件 在/var/named目录下创建lee.com.zone文件 12345678910111213[root@localhost named]# cat lee.com.zone $TTL 3600lee.com. IN SOA lee.com. admin.lee.com. ( 2017053001 1H 5M 1W 6H ) IN NS dns1.lee.com.dns1.lee.com. IN A 172.16.250.14www.lee.com. IN A 172.16.250.14web IN CNAME www 3.修改bind配置文件 在/etc目录下的named.conf文件 1234567891011options &#123; listen-on port 53 &#123; 172.16.250.14; &#125;; #花括号内改为本机IP,括号前后必须加空格 directory &quot;/var/named&quot;; dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; allow-query &#123; any; &#125;; #花括号内改为any，允许所有人来查询 recursion yes; dnssec-enable no; #不做安全性校验 dnssec-validation no; #不做安全性校验 4.检查配置文件12[root@localhost named]# named-checkconf[root@localhost named]# 5.检查区域配置文件语法错误1234[root@localhost named]# named-checkzone lee.com. /var/named/lee.com.zone zone lee.com/IN: loaded serial 2017053001OK#只能检查语法错误，不能检查逻辑错误 6.权限及属组修改123456789101112[root@localhost named]# chgrp named /var/named/lee.com.zone[root@localhost named]# chmod o= /var/named/lee.com.zone[root@localhost named]# lltotal 36drwxrwx--- 2 named named 4096 May 23 13:18 datadrwxrwx--- 2 named named 4096 May 24 2017 dynamic-rw-r----- 1 root named 202 May 24 13:28 lee.com.zone-rw-r----- 1 root named 3171 Jan 11 2016 named.ca-rw-r----- 1 root named 152 Dec 15 2009 named.empty-rw-r----- 1 root named 152 Jun 21 2007 named.localhost-rw-r----- 1 root named 168 Dec 15 2009 named.loopbackdrwxrwx--- 2 named named 4096 May 11 2016 slaves 7.启动服务重新加载（生产实际只重载不重启）12345[root@localhost named]# service named startStarting named: [ OK ][root@localhost named]# rndc reloadserver reload successful[root@localhost named]# 8.测试123456[root@localhost named]# host -t A www.lee.comwww.lee.com has address 172.16.250.14[root@localhost named]# host -t SOA lee.comlee.com has SOA record lee.com. admin.lee.com. 2017053001 3600 300 604800 21600 二、配置一个反向解析区(输入ip解析出域名)1.在主配置文件中（/etc/named.conf）或主配置文件辅助配置文件（/etc/named.rfc1912.zones）中实现； 格式： zone &quot;ZONE_NAME&quot; IN { type {master|slave|hint|forward}; file &quot;ZONE_NAME.zone&quot;; }; 12345678#末尾添加一个区域#并把文件指向172.16.zone#反向区域名是倒过来写的网络IP+.in-addr.arpazone &quot;16.172.in-addr.arpa&quot; IN &#123; type master; file &quot;172.16.zone&quot;;&#125;; 2.创建区域文件 在/var/named目录下创建172.16.zone文件 1234567891011[root@localhost named]# cat 172.16.zone $TTL 1200@ IN SOA @ nsadmin.lee.com. ( 2017060101 3H 20M 1W 1D )@ IN NS dns1.lee.com.98.254.16.172.in-addr.arpa. IN PTR dns1.lee.com.98.254.16.172.in-addr.arpa. IN PTR www.lee.com. 3.修改bind配置文件 因为做正向解析区域时已经对配置文件做了修改，所以以后的操作不用再对配置文件进行配置。 4.检查配置文件12[root@localhost named]# named-checkconf[root@localhost named]# 5.检查区域配置文件语法错误12345[root@localhost named]# named-checkzone 16.172.in-addr.arpa /var/named/172.16.zonezone 16.172.in-addr.arpa/IN: loaded serial 2017060101OK[root@localhost named]# #只能检查语法错误，不能检查逻辑错误 6.权限及属组修改12345678910111213[root@localhost named]# chgrp named /var/named/172.16.zone [root@localhost named]# chmod o= /var/named/172.16.zone [root@localhost named]# lltotal 24-rw-r----- 1 root named 199 Jun 1 11:18 172.16.zonedrwxrwx--- 2 named named 47 May 29 16:34 datadrwxrwx--- 2 named named 58 Jun 1 11:08 dynamic-rw-r--r-- 1 root root 277 May 23 17:19 lyz.zone-rw-r----- 1 root named 2076 Jan 28 2013 named.ca-rw-r----- 1 root named 152 Dec 15 2009 named.empty-rw-r----- 1 root named 152 Jun 21 2007 named.localhost-rw-r----- 1 root named 168 Dec 15 2009 named.loopbackdrwxrwx--- 2 named named 6 Nov 12 2016 slaves 7.重新加载服务123[root@localhost named]# rndc reloadserver reload successful[root@localhost named]# 8.测试1234567891011121314151617181920212223[root@localhost named]# dig -x 172.16.254.98 @172.16.254.98; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-37.el7 &lt;&lt;&gt;&gt; -x 172.16.254.98 @172.16.254.98;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 9854;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;98.254.16.172.in-addr.arpa. IN PTR;; ANSWER SECTION:98.254.16.172.in-addr.arpa. 1200 IN PTR www.lee.com.;; AUTHORITY SECTION:16.172.in-addr.arpa. 1200 IN NS dns1.lee.com.;; Query time: 1 msec;; SERVER: 172.16.254.98#53(172.16.254.98);; WHEN: Thu Jun 01 11:28:20 CST 2017;; MSG SIZE rcvd: 99 12345678910111213[root@localhost named]# dig -t axfr 16.172.in-addr.arpa @172.16.254.98; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-37.el7 &lt;&lt;&gt;&gt; -t axfr 16.172.in-addr.arpa @172.16.254.98;; global options: +cmd16.172.in-addr.arpa. 1200 IN SOA 16.172.in-addr.arpa. nsadmin.lee.com. 2017060101 10800 1200 604800 8640016.172.in-addr.arpa. 1200 IN NS dns1.lee.com.67.0.16.172.in-addr.arpa. 1200 IN PTR dns1.lee.com.98.254.16.172.in-addr.arpa. 1200 IN PTR www.lee.com.16.172.in-addr.arpa. 1200 IN SOA 16.172.in-addr.arpa. nsadmin.lee.com. 2017060101 10800 1200 604800 86400;; Query time: 2 msec;; SERVER: 172.16.254.98#53(172.16.254.98);; WHEN: Thu Jun 01 11:30:41 CST 2017;; XFR size: 5 records (messages 1, bytes 187) 三、配置主从域名解析服务器主从正向解析1.在从服务器上配置/etc/named.rfc1912.zones文件。在最后添加一个域 12345zone &quot;lee.com&quot; IN &#123; type slave; #类型选择从服务器 file &quot;slaves/lee.com.zone&quot;; #文件指向/var/named/slaves/的lee.com.zone从服务器上这个文件不用手动创建， masters &#123; 172.16.250.14;&#125;; #指明主服务器的IP&#125;; 2.检查配置文件是否有错 12[root@localhost slaves]# named-checkconf [root@localhost slaves]# 3.与时间服务器同步时间，主从服务器都需要做 12[root@localhost ~]# ntpdate 172.16.0.1 1 Jun 14:12:14 ntpdate[2712]: step time server 172.16.0.1 offset 527048.206825 sec 4.在从服务器上重载服务12[root@localhost ~]# rndc reloadserver reload successful 5.查看一下日志文件/var/log/messages 显示文件已经传输成功 1234567891011[root@localhost slaves]# tail /var/log/messagesJun 1 14:12:40 localhost named[2257]: using default UDP/IPv6 port range: [1024, 65535]Jun 1 14:12:40 localhost named[2257]: sizing zone task pool based on 7 zonesJun 1 14:12:40 localhost named[2257]: Warning: &apos;empty-zones-enable/disable-empty-zone&apos; not set: disabling RFC 1918 empty zonesJun 1 14:12:40 localhost named[2257]: reloading configuration succeededJun 1 14:12:40 localhost named[2257]: reloading zones succeededJun 1 14:12:40 localhost named[2257]: zone lee.com/IN: Transfer started.Jun 1 14:12:40 localhost named[2257]: transfer of &apos;lee.com/IN&apos; from 172.16.250.14#53: connected using 172.16.250.196#33700Jun 1 14:12:40 localhost named[2257]: zone lee.com/IN: transferred serial 2017053001Jun 1 14:12:40 localhost named[2257]: transfer of &apos;lee.com/IN&apos; from 172.16.250.14#53: Transfer completed: 1 messages, 6 records, 176 bytes, 0.003 secs (58666 bytes/sec)Jun 1 14:12:40 localhost named[2257]: zone lee.com/IN: sending notifies (serial 2017053001) 此时在/var/named/slaves目录下就有了从主服务器同步过来的区域配置文件lee.com.zone 123456[root@localhost slaves]# cd ~[root@localhost ~]# cd /var/named/slaves/[root@localhost slaves]# lltotal 4-rw-r--r-- 1 named named 337 Jun 1 14:12 lee.com.zone[root@localhost slaves]# 6.测试1234567891011121314151617181920212223242526[root@localhost slaves]# dig -t A www.lee.com @172.16.250.196; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6 &lt;&lt;&gt;&gt; -t A www.lee.com @172.16.250.196;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 56624;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 1;; QUESTION SECTION:;www.lee.com. IN A;; ANSWER SECTION:www.lee.com. 3600 IN A 172.16.250.14;; AUTHORITY SECTION:lee.com. 3600 IN NS dns1.lee.com.;; ADDITIONAL SECTION:dns1.lee.com. 3600 IN A 172.16.250.14;; Query time: 2 msec;; SERVER: 172.16.250.196#53(172.16.250.196);; WHEN: Thu Jun 1 14:42:03 2017;; MSG SIZE rcvd: 80[root@localhost slaves]# 主从反向解析1.在从服务器上配置/etc/named.rfc1912.zones文件。在最后添加一个域 12345zone &quot;16.172.in-addr.arpa&quot; &#123; type slave; #选择从服务器类型 file &quot;slaves/lee.com.backzone&quot;; #文件指向/var/named/slaves/的lee.com.zone从服务器上这个文件不用手动创建， masters &#123; 172.16.250.14; &#125;; #指明主服务器的IP&#125;; 2.检查配置文件是否有错 12[root@localhost slaves]# named-checkconf [root@localhost slaves]# 3.与时间服务器同步时间，主从服务器都需要做 12[root@localhost ~]# ntpdate 172.16.0.1 1 Jun 14:12:14 ntpdate[2712]: step time server 172.16.0.1 offset 527048.206825 sec 4.在从服务器上重载服务12[root@localhost ~]# rndc reloadserver reload successful 5.查看一下日志文件/var/log/messages 显示文件已经传输成功 1234567891011[root@localhost slaves]# tail /var/log/messagesJun 1 15:01:11 localhost named[2257]: using default UDP/IPv6 port range: [1024, 65535]Jun 1 15:01:11 localhost named[2257]: sizing zone task pool based on 8 zonesJun 1 15:01:11 localhost named[2257]: Warning: &apos;empty-zones-enable/disable-empty-zone&apos; not set: disabling RFC 1918 empty zonesJun 1 15:01:11 localhost named[2257]: reloading configuration succeededJun 1 15:01:11 localhost named[2257]: reloading zones succeededJun 1 15:01:11 localhost named[2257]: zone 16.172.in-addr.arpa/IN: Transfer started.Jun 1 15:01:11 localhost named[2257]: transfer of &apos;16.172.in-addr.arpa/IN&apos; from 172.16.250.14#53: connected using 172.16.250.196#42173Jun 1 15:01:11 localhost named[2257]: zone 16.172.in-addr.arpa/IN: transferred serial 2017060101Jun 1 15:01:11 localhost named[2257]: transfer of &apos;16.172.in-addr.arpa/IN&apos; from 172.16.250.14#53: Transfer completed: 1 messages, 5 records, 182 bytes, 0.001 secs (182000 bytes/sec)Jun 1 15:01:11 localhost named[2257]: zone 16.172.in-addr.arpa/IN: sending notifies (serial 2017060101) 此时在/var/named/slaves目录下就有了从主服务器同步过来的区域配置文件lee.com.backzone 123456[root@localhost slaves]# cd ~[root@localhost ~]# cd /var/named/slaves/[root@localhost slaves]# lltotal 8-rw-r--r-- 1 named named 363 Jun 1 15:01 lee.com.backzone-rw-r--r-- 1 named named 358 Jun 1 14:41 lee.com.zone 6.测试123456789101112131415161718[root@localhost slaves]# dig -t A 16.172.in-addr.arpa @172.16.250.196; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6 &lt;&lt;&gt;&gt; -t A 16.172.in-addr.arpa @172.16.250.196;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 59949;; flags: qr aa rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 0;; QUESTION SECTION:;16.172.in-addr.arpa. IN A;; AUTHORITY SECTION:16.172.in-addr.arpa. 1200 IN SOA 16.172.in-addr.arpa. nsadmin.lee.com. 2017060101 10800 1200 604800 86400;; Query time: 0 msec;; SERVER: 172.16.250.196#53(172.16.250.196);; WHEN: Thu Jun 1 15:06:08 2017;; MSG SIZE rcvd: 88 12345678910111213141516171819202122232425[root@localhost slaves]# dig -x 172.16.250.14 @172.16.250.196; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6 &lt;&lt;&gt;&gt; -x 172.16.250.14 @172.16.250.196;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 1037;; flags: qr aa rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 1, ADDITIONAL: 1;; QUESTION SECTION:;14.250.16.172.in-addr.arpa. IN PTR;; ANSWER SECTION:14.250.16.172.in-addr.arpa. 1200 IN PTR www.lee.com.14.250.16.172.in-addr.arpa. 1200 IN PTR dns1.lee.com.;; AUTHORITY SECTION:16.172.in-addr.arpa. 1200 IN NS dns1.lee.com.;; ADDITIONAL SECTION:dns1.lee.com. 3600 IN A 172.16.250.14;; Query time: 3 msec;; SERVER: 172.16.250.196#53(172.16.250.196);; WHEN: Thu Jun 1 15:07:32 2017;; MSG SIZE rcvd: 118 四、配置子域域名解析1.在主服务器上添加子域信息12345678910111213141516171819[root@localhost named]# cat /var/named/lee.com.zone $TTL 3600lee.com. IN SOA lee.com. admin.lee.com. ( 2017053002 1H 5M 1W 6H ) IN NS dns1.lee.com.dns1.lee.com. IN A 172.16.250.14www.lee.com. IN A 172.16.250.14web IN CNAME wwwops.lee.com IN NS dns1.ops.lee.comdev.lee.com IN NS dns1.dev.lee.com.dns1.ops IN A 172.16.250.196dns1.dev IN A 172.16.254.98 2.在子域服务器上添加子域1234zone &quot;ops.lee.com&quot; &#123; type master; file &quot;ops.lee.com.zone&quot;;&#125;; 3.创建域配置文件12345678910111213$TTL 3600@ IN SOA ops.lee.com nsadmin.ops.lee.com ( 2717060101 1H 5M 3D 2H )@ IN NS dns1.ops.lee.com.dns1 IN A 172.16.250.196www IN A 172.16.250.196~ 4.测试123456789101112131415161718192021222324[root@localhost slaves]# dig -t A dns1.ops.lee.com @172.16.250.14; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6 &lt;&lt;&gt;&gt; -t A dns1.ops.lee.com @172.16.250.14;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 9662;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 1;; QUESTION SECTION:;dns1.ops.lee.com. IN A;; ANSWER SECTION:dns1.ops.lee.com. 3600 IN A 172.16.250.196;; AUTHORITY SECTION:lee.com. 3600 IN NS dns1.lee.com.;; ADDITIONAL SECTION:dns1.lee.com. 3600 IN A 172.16.250.14;; Query time: 2 msec;; SERVER: 172.16.250.14#53(172.16.250.14);; WHEN: Thu Jun 1 15:34:43 2017;; MSG SIZE rcvd: 85 123456789101112131415161718192021[root@localhost named]# dig -t A dns1.ops.lee.com @172.16.250.196; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.47.rc1.el6 &lt;&lt;&gt;&gt; -t A dns1.ops.lee.com @172.16.250.196;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63239;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 1, ADDITIONAL: 0;; QUESTION SECTION:;dns1.ops.lee.com. IN A;; ANSWER SECTION:dns1.ops.lee.com. 3600 IN A 172.16.250.196;; AUTHORITY SECTION:ops.lee.com. 3600 IN NS dns1.ops.lee.com.;; Query time: 2 msec;; SERVER: 172.16.250.196#53(172.16.250.196);; WHEN: Thu Jun 1 15:33:49 2017;; MSG SIZE rcvd: 64]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[openssl--CA]]></title>
      <url>%2F2017%2F05%2F30%2Fopenssl-CA%2F</url>
      <content type="text"><![CDATA[openssl–CA证书CA的配置文件是/etc/pki/tls目录下的openssl.cnf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768####################################################################[ ca ]default_ca = CA_default # The default ca section#默认CA将从CA_default这一段中加载配置####################################################################[ CA_default ]dir = /etc/pki/CA # 把那个目录当做为CA的工作路径certs = $dir/certs # 已经签署过的证书存放路径crl_dir = $dir/crl # 吊销列表存放路径database = $dir/index.txt # 索引文件数据库#unique_subject = no # Set to &apos;no&apos; to allow creation of # several ctificates with same subject.new_certs_dir = $dir/newcerts # 默认存放新证书的路径certificate = $dir/cacert.pem # The CA certificateserial = $dir/serial # 签署过证书的序列号crlnumber = $dir/crlnumber # the current crl number # must be commented out to leave a V1 CRLcrl = $dir/crl.pem # The current CRLprivate_key = $dir/private/cakey.pem# The private keyRANDFILE = $dir/private/.rand # private random number filex509_extensions = usr_cert # The extentions to add to the cert# Comment out the following two lines for the &quot;traditional&quot;# (and highly broken) format.name_opt = ca_default # Subject Name optionscert_opt = ca_default # Certificate field options# Extension copying option: use with caution.# copy_extensions = copy# Extensions to add to a CRL. Note: Netscape communicator chokes on V2 CRLs# so this is commented out by default to leave a V1 CRL.# crlnumber must also be commented out to leave a V1 CRL.# crl_extensions = crl_extdefault_days = 365 # how long to certify fordefault_crl_days= 30 # how long before next CRLdefault_md = sha256 # use SHA-256 by defaultpreserve = no # keep passed DN ordering# A few difference way of specifying how similar the request should look# For type CA, the listed attributes must be the same, and the optional# and supplied fields are just that :-)policy = policy_match# For the CA policy[ policy_match ]countryName = matchstateOrProvinceName = matchorganizationName = matchorganizationalUnitName = optionalcommonName = suppliedemailAddress = optional# For the &apos;anything&apos; policy# At this point in time, you must list all acceptable &apos;object&apos;# types.[ policy_anything ]countryName = 国家stateOrProvinceName = 省localityName = 市organizationName = 公司organizationalUnitName = 部门commonName = 持有证书的人名，或者拥有证书的主机名emailAddress = 邮件地址 构建私有CA： 一、首先创建私钥： 在/etc/pki/CA/private目录下创建私钥确保权限600： 12345678[root@station51 private]# (umask 0077;openssl genrsa -out cakey.pem 2048)Generating RSA private key, 2048 bit long modulus.....................................+++....................+++e is 65537 (0x10001)[root@station51 private]# lltotal 4-rw------- 1 root root 1675 May 29 17:08 cakey.pem 二、生成自签证书： 1234567891011121314151617181920212223[root@station51 private]# openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3655You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &apos;.&apos;, the field will be left blank.-----Country Name (2 letter code) [XX]:CN State or Province Name (full name) []:BeijingLocality Name (eg, city) [Default City]:BeijingOrganization Name (eg, company) [Default Company Ltd]:testOrganizational Unit Name (eg, section) []:OpsCommon Name (eg, your name or your server&apos;s hostname) []:ca.testserver Email Address []:test@test.com[root@station51 private]# cd ..[root@station51 CA]# lltotal 20-rw-r--r-- 1 root root 1399 May 29 17:16 cacert.pemdrwxr-xr-x. 2 root root 4096 Jun 29 2015 certsdrwxr-xr-x. 2 root root 4096 Jun 29 2015 crldrwxr-xr-x. 2 root root 4096 Jun 29 2015 newcertsdrwx------. 2 root root 4096 May 29 17:08 private 说明： openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cecert.pem -days 3655 -new：生成新证书签署请求； -x509：生成自签格式证书，专用于创建私有CA时； -key：生成请求时用到的私有文件路径； -out：生成的请求文件路径；如果自签操作将直接生成签署过的证书； -days：证书的有效时长，单位是day； 三、为CA提供所需的目录及文件（这步操作在CentOS6中需要手动创建，CentOS7中自动生成）； ~]# mkdir -pv /etc/pki/CA/{certs,crl,newcerts} ~]# touch /etc/pki/CA/{serial,index.txt} ~]# echo 01 &gt; /etc/pki/CA/serial 以上步骤完成后私有CA就已经完成了。 实验： 要用到证书进行安全通信的服务器，需要向CA请求签署证书： 一、安装所需要的软件包 yum -y install httpd mod_ssl 二、生成自签证书 步骤： touch /etc/pki/CA/index.txt echo 01 &gt; /etc/pki/CA/serial cd /etc/pki/CA (umask 0077;openssl genrsa -out /etc/pki/CA/private/cakey.pem 1024) cd /etc/pki/CA/private openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566[root@localhost ~]# yum -y install httpd mod_sslLoaded plugins: fastestmirror, refresh-packagekit, securityRepository &apos;centos&apos; is missing name in configuration, using idRepository &apos;epel&apos; is missing name in configuration, using idSetting up Install ProcessLoading mirror speeds from cached hostfilecentos | 4.0 kB 00:00 epel | 4.3 kB 00:00 Package httpd-2.2.15-53.el6.centos.x86_64 already installed and latest versionResolving Dependencies--&gt; Running transaction check---&gt; Package mod_ssl.x86_64 1:2.2.15-53.el6.centos will be installed--&gt; Finished Dependency ResolutionDependencies Resolved======================================================================================== Package Arch Version Repository Size========================================================================================Installing: mod_ssl x86_64 1:2.2.15-53.el6.centos centos 97 kTransaction Summary========================================================================================Install 1 Package(s)Total download size: 97 kInstalled size: 187 kDownloading Packages:mod_ssl-2.2.15-53.el6.centos.x86_64.rpm | 97 kB 00:00 Running rpm_check_debugRunning Transaction TestTransaction Test SucceededRunning Transaction Installing : 1:mod_ssl-2.2.15-53.el6.centos.x86_64 1/1 Verifying : 1:mod_ssl-2.2.15-53.el6.centos.x86_64 1/1 Installed: mod_ssl.x86_64 1:2.2.15-53.el6.centos Complete![root@localhost ~]# touch /etc/pki/CA/index.txt[root@localhost ~]# echo 01 &gt; /etc/pki/CA/serial[root@localhost ~]# cd /etc/pki/CA[root@localhost CA]# (umask 0077;openssl genrsa -out /etc/pki/CA/private/cakey.pem 1024)Generating RSA private key, 1024 bit long modulus...........++++++.++++++e is 65537 (0x10001)[root@localhost CA]# cd /etc/pki/CA/private[root@localhost private]# openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pemYou are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &apos;.&apos;, the field will be left blank.-----Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:BJLocality Name (eg, city) [Default City]:BJOrganization Name (eg, company) [Default Company Ltd]:www.test.comOrganizational Unit Name (eg, section) []:www.test.comCommon Name (eg, your name or your server&apos;s hostname) []:www.test.comEmail Address []:[root@localhost private]# 三、生成证书请求 步骤： mkdir /web/ssl -pv cd /web/ssl (umask 0077; openssl genrsa -out http.key 1024) openssl req -new -key http.key -out httpd.csr 1234567891011121314151617181920212223242526272829303132[root@localhost ~]# mkdir /web/sslmkdir: cannot create directory `/web/ssl&apos;: No such file or directory[root@localhost ~]# mkdir /web/ssl -pvmkdir: created directory `/web&apos;mkdir: created directory `/web/ssl&apos;[root@localhost ~]# cd /web/ssl/[root@localhost ssl]# (umask 0077;openssl genrsa -out http.key 1024)Generating RSA private key, 1024 bit long modulus.................................................................++++++......++++++e is 65537 (0x10001)[root@localhost ssl]# openssl req -new -key http.key -out httpd.csrYou are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &apos;.&apos;, the field will be left blank.-----Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:BJLocality Name (eg, city) [Default City]:BJOrganization Name (eg, company) [Default Company Ltd]:www.test.comOrganizational Unit Name (eg, section) []:www.test.comCommon Name (eg, your name or your server&apos;s hostname) []:www.test.comEmail Address []:Please enter the following &apos;extra&apos; attributesto be sent with your certificate requestA challenge password []:An optional company name []:[root@localhost ssl]# 四、签名请求文件 步骤：openssl ca -in /web/ssl/httpd.csr -out /etc/pki/CA/newcerts/httpd.crt 12345678910111213141516171819202122232425262728293031Using configuration from /etc/pki/tls/openssl.cnfCheck that the request matches the signatureSignature okCertificate Details: Serial Number: 1 (0x1) Validity Not Before: May 29 19:14:32 2017 GMT Not After : May 29 19:14:32 2018 GMT Subject: countryName = CN stateOrProvinceName = BJ organizationName = www.test.com organizationalUnitName = www.test.com commonName = www.test.com X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: 3C:45:24:8C:7A:9C:DC:07:EF:91:37:88:55:E8:BF:0C:5C:53:F1:7F X509v3 Authority Key Identifier: keyid:3A:6A:75:4F:6D:E9:F1:F6:48:81:64:BD:FD:B8:4E:BA:30:6E:3A:75Certificate is to be certified until May 29 19:14:32 2018 GMT (365 days)Sign the certificate? [y/n]:y1 out of 1 certificate requests certified, commit? [y/n]yWrite out database with 1 new entriesData Base Updated 五、配置 ssl.conf,实现 https 修改配置文件vim /etc/httpd/conf.d/ssl.conf SSLCertificateFile /etc/pki/CA/newcerts/httpd.crt SSLCertificateKeyFile /web/ssl/http.key DocumentRoot &quot;/var/www/html&quot; ServerName www.test.com:443 systemctl restart httpd ss -ntl | grep 443 六、添加证书到本地PC即可]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[OPENSSL]]></title>
      <url>%2F2017%2F05%2F30%2FOPENSSL%2F</url>
      <content type="text"><![CDATA[OPENSSL常见用法输入openssl后面随意跟一个错误选项即可调出选项列表 12345678910111213141516171819202122232425262728293031323334353637383940[root@station51 ~]# openssl -openssl:Error: &apos;-&apos; is an invalid command.#标准命令Standard commandsasn1parse ca（常用） ciphers cms crl crl2pkcs7 dgst dh dhparam dsa dsaparam ec ecparam enc（常用） engine errstr gendh gendsa（常用） genpkey genrsa nseq ocsp passwd pkcs12 pkcs7 pkcs8 pkey pkeyparam pkeyutl prime rand req（常用） rsa rsautl s_client s_server s_time sess_id smime speed spkac ts verify version x509 #消息摘要类命令Message Digest commands (see the `dgst&apos; command for more details)md2 md4 md5 rmd160 sha sha1 #加解密命令Cipher commands (see the `enc&apos; command for more details)aes-128-cbc aes-128-ecb aes-192-cbc aes-192-ecb aes-256-cbc aes-256-ecb base64 bf bf-cbc bf-cfb bf-ecb bf-ofb camellia-128-cbc camellia-128-ecb camellia-192-cbc camellia-192-ecb camellia-256-cbc camellia-256-ecb cast cast-cbc cast5-cbc cast5-cfb cast5-ecb cast5-ofb des des-cbc des-cfb des-ecb des-ede des-ede-cbc des-ede-cfb des-ede-ofb des-ede3 des-ede3-cbc des-ede3-cfb des-ede3-ofb des-ofb des3 desx idea idea-cbc idea-cfb idea-ecb idea-ofb rc2 rc2-40-cbc rc2-64-cbc rc2-cbc rc2-cfb rc2-ecb rc2-ofb rc4 rc4-40 seed seed-cbc seed-cfb seed-ecb seed-ofb zlib 对称加密： 工具：openssl enc, gpg 支持的算法：3des, aes, blowfish, towfish 加密：123456789101112131415161718192021#以/etc/fstab文件举例[root@station51 ~]# cd /etc[root@station51 etc]# openssl enc -e -des3 -a -salt -in fstab -out fstab.ciphertextenter des-ede3-cbc encryption password:Verifying - enter des-ede3-cbc encryption password: [root@station51 etc]# cat fstab.ciphertext U2FsdGVkX1/C0Rj1Zt+/RbCihTNFSlIW/JQ0fds493+tVA1E972inpvhi7/Oi50v9vjYfse07fyZgBf2hQALx57j+Bl/8gZoQofs8tTj2uMYqpAiePeDYzKAoXFG+XSf7bkDnlw3akbD6FGnbF0UblcD90Dz6+OSDQ01/xkIJZFfymwvW0YesKBWzK38dbp7IW3Hi8LRSs17ND4UHhLP24TQfbEDqure21Zuo3GqOnHa5IhKOtfm1vYePd5fHN/omiYvjpayk8tsLdBTO8pL/Z5Fi07DR9FywhxQ7pdpKQD3wiMm79pIqBm2ZktuQ2cwuK4BwSv0wqeAQiBgAWSAUSijcQ+mC4lh9SI8GwYxyyDRHH06J2mzqnyN7vXesaj6R3gqbwIK9wDQmXE+j/kahMlzP80WIPvPlJdpJMMPMriv7dW55b3AvZ4AJ+D1jmSFNxctZ+sng18h4nd/f2Ko3bHMdSnDEQzwmUfYKiIEygUlwg8c8HRySp7Q30gDyzy+k5Q5kjOgSRZEvvCutIxDTwPiZ0Ssapw1Y3UMAc7TdlOuzZxU/3JSU7R31r6jAc4wLQTLzflfEe1bGH5FLkWUg+9B8jZozHp/7EmnMgxi888r3z3JF+qO8K8XdkQSrN2pxbjkdYPCmwhun19XViHMeyFctItbqL8KGzOyGSBbhzq+uE4Qeruu+ogf8EQRzcyGutfE+Rzcvc71WKk2uinIcMG6DsUmKtmvd5gJtVBVhWq4s2JVJ8t/CbHS+8ZUs35aF7eNfUnSae1P2jN/Cad8FwtRClCGTIxGR+g9un76wbscFYR3OLO51w==[root@station51 etc]# 说明： openssl enc -e -des3 -a -salt -in fstab -out fstab.ciphertext openssl enc -d -des3 -a -salt -in fstab.ciphertext -out fstab -e encrypt加密 &lt;--&gt; -d decrypt解密 -des3 使用des3加密算法 -a 基于文本格式输出加密后文件内容 -salt 在加密过程中添加一段随机数 -in 对哪个文件加密 -out 加密后的文件输出到哪里 单向加密： 工具：openssl dgst, md5sum, sha1sum, sha224sum, ... 支持算法：md2、md4、md5、rmd160、sha、sha1 加密：123456789[root@station51 etc]# openssl dgst -md5 /etc/fstabMD5(/etc/fstab)= ec48e5270ea9c035c72aa1519432af8c[root@station51 etc]# md5sum /etc/fstabec48e5270ea9c035c72aa1519432af8c /etc/fstab···································································[root@station51 etc]# openssl dgst -sha1 /etc/fstabSHA1(/etc/fstab)= 43133334e56e2a58245cd0a9e5174f6bebe325a1[root@station51 etc]# sha1sum /etc/fstab43133334e56e2a58245cd0a9e5174f6bebe325a1 /etc/fstab 说明： dgst命令： ~]# openssl dgst -md5 /PATH/TO/SOMEFILE 生成用户密码： 工具：passwd, openssl passwd 123456789[root@station51 etc]# openssl passwd -1 -salt 123456 hello$1$123456$HQ125.2GLsY4GcwH9Mm1P/[root@station51 etc]# openssl passwd -1 -salt 123456 hello$1$123456$HQ125.2GLsY4GcwH9Mm1P/[root@station51 etc]# openssl passwd -1 -salt 123456 helloworld$1$123456$jBay/ZlxBUiEX3gCH5Pba.[root@station51 etc]# openssl passwd -1 -salt 12345678 hello$1$12345678$SWwdAXyU/e6YSg8pQlz4D/[root@station51 etc]# 说明： 语法格式：openssl passwd -1 -salt SALT 文件 salt自己指定，salt相同字符串相同，多次加密后生成密码相同 salt自己指定，salt相同字符串不相同，加密后生成密码不同 salt自己指定，salt不同字符串相同，多次加密后生成密码不同 生成随机数： 工具：openssl rand 类型 字符串长度 1234[root@station51 etc]# openssl rand -hex 42f1e3fb3[root@station51 etc]# openssl rand -base64 4HLmG0w== 说明： 语法格式：openssl rand 类型 字符串长度 结合：生成用户密码+生成随机数12[root@station51 etc]# openssl passwd -1 -salt $(openssl rand -hex 4) hello$1$874b43cc$yVoAMU.vR5/KJS5VXNDxG. 公钥加密： 加密解密： 算法：RSA，ELGamal 工具：openssl rsautl, gpg 数字签名： 算法：RSA， DSA， ELGamal 工具： 密钥交换： 算法：DH 生成私钥： 12345678910111213141516171819202122[root@station51 /]# openssl genrsa -out mykey.key 1024Generating RSA private key, 1024 bit long modulus........++++++........++++++........++++++e is 65537 (0x10001)[root@station51 /]# cat mykey.key -----BEGIN RSA PRIVATE KEY-----MIICXQIBAAKBgQDB2PBAFQGSVrHFnWBn1iAbwdZRRSIK9usxh3Tq0czeWraJCcqTYpHL9+I6U//fMUaNb57t/JphnnAsJ29ToTPtrf4y5y9xsbZpo7vnSSeBw1cUVsd0KIxnk9KT1dFW5X3lwo3DkNmgLIWGOB2R/nl5LYC4bnvHI7l+JIsU/8OHiwIDAQABAoGAbWU5SGDSbzx/vK8w7ciYfDGq+lhSeu+YEW6JW8+kl0OISdP9v6lb8EjnIdWvy8xqLX11qobotPiOA00J9Z8+xwElSrvCK24HKdK85uWjU7RZhbGO2IzmAQFjYhhkcy2PK2J+9DQxbJ6pBofL1/bX6k/QRfFt8avZi1IMo9jM/dkCQQD7goyrng5gRuYsFsR66zScQSY/o5+upE5msRFQ6DWNXdlZ/xxOF6Pp/b9WVnbse13I9quSMlsJUocrWMOyEcC/AkEAxU7cFVcECEMOa/MCBUTFbUNybudY4jaT2OldSCeoPBjCoc+4O1jflSTEZ7s3Q78uNvu7/TbX+soIwhYHevFgNQJBAIY0IQ+qJQ2mh0dbVrgoLUh7Uwd+LcSok9UkApNjdL/cJhBpmhbpcmN3LNPLC2YgZejIBsDZ8c3Fpa6xjKrF4k0CQQCdVG6Fzab3d5DuXw2Daf0LTTbYXD0x1Fc8JYkuWgD6OrwoDtxW5l0SLgk2tcAxkyakzUJvfOXnomYtbSd1zzbpAkBmGmzPrntM5O11x1dwMYg4XzHQoxdNaNmuJaq/jBVq0vy+wvkDn88goH7Wq99kcrUYz1zo7UcL8GA6aOjK1Y9Y-----END RSA PRIVATE KEY----- 说明： 生成私钥： ~]# openssl genrsa -out mykey.key 1024 提出公钥： ~]# openssl rsa -in mykey.key -pubout 提取公钥： 只输出公钥不输入私钥 123456789101112131415161718192021222324[root@station51 /]# openssl rsa -in mykey.key -puboutwriting RSA key-----BEGIN PUBLIC KEY-----MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDB2PBAFQGSVrHFnWBn1iAbwdZRRSIK9usxh3Tq0czeWraJCcqTYpHL9+I6U//fMUaNb57t/JphnnAsJ29ToTPtrf4y5y9xsbZpo7vnSSeBw1cUVsd0KIxnk9KT1dFW5X3lwo3DkNmgLIWGOB2R/nl5LYC4bnvHI7l+JIsU/8OHiwIDAQAB-----END PUBLIC KEY-----[root@station51 /]# cat mykey.key -----BEGIN RSA PRIVATE KEY-----MIICXQIBAAKBgQDB2PBAFQGSVrHFnWBn1iAbwdZRRSIK9usxh3Tq0czeWraJCcqTYpHL9+I6U//fMUaNb57t/JphnnAsJ29ToTPtrf4y5y9xsbZpo7vnSSeBw1cUVsd0KIxnk9KT1dFW5X3lwo3DkNmgLIWGOB2R/nl5LYC4bnvHI7l+JIsU/8OHiwIDAQABAoGAbWU5SGDSbzx/vK8w7ciYfDGq+lhSeu+YEW6JW8+kl0OISdP9v6lb8EjnIdWvy8xqLX11qobotPiOA00J9Z8+xwElSrvCK24HKdK85uWjU7RZhbGO2IzmAQFjYhhkcy2PK2J+9DQxbJ6pBofL1/bX6k/QRfFt8avZi1IMo9jM/dkCQQD7goyrng5gRuYsFsR66zScQSY/o5+upE5msRFQ6DWNXdlZ/xxOF6Pp/b9WVnbse13I9quSMlsJUocrWMOyEcC/AkEAxU7cFVcECEMOa/MCBUTFbUNybudY4jaT2OldSCeoPBjCoc+4O1jflSTEZ7s3Q78uNvu7/TbX+soIwhYHevFgNQJBAIY0IQ+qJQ2mh0dbVrgoLUh7Uwd+LcSok9UkApNjdL/cJhBpmhbpcmN3LNPLC2YgZejIBsDZ8c3Fpa6xjKrF4k0CQQCdVG6Fzab3d5DuXw2Daf0LTTbYXD0x1Fc8JYkuWgD6OrwoDtxW5l0SLgk2tcAxkyakzUJvfOXnomYtbSd1zzbpAkBmGmzPrntM5O11x1dwMYg4XzHQoxdNaNmuJaq/jBVq0vy+wvkDn88goH7Wq99kcrUYz1zo7UcL8GA6aOjK1Y9Y-----END RSA PRIVATE KEY----- 为了避免私钥被其他用户窃取，建议加密时顺便修改文件权限： ~]#(umask 077; openssl genrsa -out test.key 1024) 12345678[root@station51 /]# (umask 077; openssl genrsa -out test.key 1024)Generating RSA private key, 1024 bit long modulus...................++++++.................................................++++++e is 65537 (0x10001)[root@station51 /]# ll-rw-r--r-- 1 root root 887 May 29 16:07 mykey.key-rw------- 1 root root 887 May 29 16:13 test.key]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[SSL与SSH]]></title>
      <url>%2F2017%2F05%2F30%2Fssl-ssh%2F</url>
      <content type="text"><![CDATA[# openssl与openssh 笔记 OpenSSL 传输层协议：TCP，UDP，SCTP port：进程地址，进程向内核注册使用某端口（独占） 同一主机上的进程间通信：IPC， message queue, shm, semerphor 不同主上的进程间通信：socket cip:port &lt;-- --&gt; sip:port cip:55673 &lt;-- --&gt; sip:80 监听模式：LISTEN （ip:port） SSL: Secure Sockets Layer http --&gt; ssl --&gt; https TLS: transport layer Security 安全的目标： 保密性：confidentiality 完整性：integrity 可用性：availability 攻击类型： 威胁保密性的攻击：窃听、通信量分析； 威胁完整性的攻击：更改、伪装、重放、否认 威胁可用性的攻击：拒绝服务（DoS） 解决方案： 技术（加密和解密）、服务（用于抵御攻击的服务，也即是为了上述安全目标而特地设计的安全服务） 加密和解密： 传统加密方法：替代加密方法、置换加密方法 现代加密方法：现代块加密方法 服务： 认证机制 访问控制机制 密钥算法和协议 对称加密 公钥加密 单向加密 认证协议 Linux系统：OpenSSL(ssl)， GPG(pgp) OpenSSL由三部分组成： libencrypto库 libssl库 openssl多用途命令行工具 加密算法和协议： 对称加密：加密和解密使用同一个密钥； DES：Data Encryption Standard; 3DES：Triple DES; AES：Advanced Encryption Standard; (128bits, 192bits, 256bits, 384bits) Blowfish Twofish IDEA RC6 CAST5 特性： 1、加密、解密使用同一个密钥； 2、将原始数据分割成为固定大小的块，逐个进行加密； 缺陷： 1、密钥过多； 2、密钥分发困难； 公钥加密：密钥分为公钥与私钥 公钥：从私钥中提取产生；可公开给所有人；public key 私钥：通过工具创建，使用者自己留存，必须保证其私密性；secret key； 特点：用公钥加密的数据，只能使用与之配对儿的私钥解密；反之亦然； 用途： 数字签名：主要在于让接收方确认发送方的身份； 密钥交换：发送方用对方公钥加密一个对称密钥，并发送给对方； 数据加密 算法：RSA， DSA， ELGamal DSS: Digital Signature Standard DSA：Digital Signature Algorithm 单向加密：即提出数据指纹；只能加密，不能解密； 特性：定长输出、雪崩效应； 功能：完整性； 算法： md5：Message Digest 5, 128bits sha1：Secure Hash Algorithm 1, 160bits sha224, sha256, sha384, sha512 密钥交换： IKE（Internet Key Exchange） 公钥加密 DH（Deffie-Hellman） A：p, g B：p, g A: x --&gt; p^x%g ==&gt; B A: (p^y%g)^x=p^yx%g B: y --&gt; p^y%g ==&gt; A =&gt; (p^y%g)^x=p^xy%g B: (p^x%g)^y=p^xy%g PKI：Public Key Infrastructure 公钥基础设施： 注册机构：RA 证书吊销列表：CRL 证书存取库： X.509v3：定义了证书的结构以及认证协议标准 版本号 序列号 签名算法ID 发行者名称 有效期限 主体名称 主体公钥 发行者的惟一标识 主体的惟一标识 扩展 发行者的签名 SSL：Secure sockets Layer Netscape: 1994 V1.0, V2.0, V3.0 TLS: Transport Layer Security IETF: 1999 V1.0, V1.1, V1.2, V1.3 分层设计： 1、最底层：基础算法原语的实现，aes, rsa, md5 2、向上一层：各种算法的实现； 3、再向上一层：组合算法实现的半成品； 4、用各种组件拼装而成的各种成品密码学协议软件； 协议的开源实现：OpenSSL 加密算法和协议： 对称加密：数据加密（保密性），（3DES，AES） 公钥加密：身份认证、密钥交换、数据加密（不常用，比对称加密要慢3个数量级），（RSA，DSA） 单向加密：数据完整性，（MD5, SHA1, ...） 密钥交换：RSA，DH（迪菲-赫尔曼），ECDH（椭圆曲线DH），ECDHE（临时椭圆曲线DH） SSL/TLS SSL: 安全套接字层（ssl 1.0, ssl 2.0, ssl 3.0） TLS：传输层安全 （tls 1.0, tls 1.1, tls 1.2, tls 1.3） OpenSSL libcrypto libssl openssl SSL会话主要三步： 客户端向服务器端索要并验正证书； 双方协商生成“会话密钥”； 双方采用“会话密钥”进行加密通信； SSL Handshake Protocol： 第一阶段：ClientHello： 支持的协议版本，比如tls 1.2； 客户端生成一个随机数，稍后用户生成“会话密钥” 支持的加密算法，比如AES、3DES、RSA； 支持的压缩算法； 第二阶段：ServerHello 确认使用的加密通信协议版本，比如tls 1.2； 服务器端生成一个随机数，稍后用于生成“会话密钥” 确认使用的加密方法； 服务器证书； 第三阶段： 验正服务器证书，在确认无误后取出其公钥；（发证机构、证书完整性、证书持有者、证书有效期、吊销列表） 发送以下信息给服务器端： 一个随机数； 编码变更通知，表示随后的信息都将用双方商定的加密方法和密钥发送； 客户端握手结束通知； 第四阶段： 收到客户端发来的第三个随机数pre-master-key后，计算生成本次会话所有到的“会话密钥”； 向客户端发送如下信息： 编码变更通知，表示随后的信息都将用双方商定的加密方法和密钥发送； 服务端握手结束通知； PKI：公钥基础设施 签证机构：CA 注册机构：RA 证书吊销列表：CRL 证书存取库 OpenSSL(2) 组件： libcrypto, libssl主要由开发者使用； openssl：多用途命令行工具； openssl: 许多子命令，分为三类： 标准命令 消息摘要命令（dgst子命令） 加密命令（enc子命令） 标准命令： enc, ca, req, genrsa, ... 对称加密： 工具：openssl enc, gpg 支持的算法：3des, aes, blowfish, towfish enc命令： 加密：~]# openssl enc -e -des3 -a -salt -in fstab -out fstab.ciphertext 解密：~]# openssl enc -d -des3 -a -salt -out fstab -in fstab.ciphertext 单向加密： 工具：openssl dgst, md5sum, sha1sum, sha224sum, ... dgst命令： ~]# openssl dgst -md5 /PATH/TO/SOMEFILE 生成用户密码： 工具：passwd, openssl passwd openssl passwd -1 -salt SALT 生成随机数： 工具：openssl rand ~]# openssl rand -hex NUM ~]# openssl rand -base NUM 公钥加密： 加密解密： 算法：RSA，ELGamal 工具：openssl rsautl, gpg 数字签名： 算法：RSA， DSA， ELGamal 工具： 密钥交换： 算法：DH 生成密钥： 生成私钥： ~]# (umask 077; openssl genrsa -out /PATH/TO/PRIVATE_KEY_FILE NUM_BITS) 提出公钥： ~]# openssl rsa -in /PATH/FROM/PRIVATE_KEY_FILE -pubout Linux系统上的随机数生成器： /dev/random：仅从熵池返回随机数；随机数用尽，阻塞； /dev/urandom：从熵池返回随机数；随机数用尽，会利用软件生成伪随机数，非阻塞； 伪随机数不安全； 熵池中随机数的来源： 硬盘IO中断时间间隔； 键盘IO中断时间间隔； CA： 公共信任的CA，私有CA； 建立私有CA： openssl OpenCA openssl命令： 配置文件：/etc/pki/tls/openssl.cnf 构建私有CA: 在确定配置为CA的服务上生成一个自签证书，并为CA提供所需要的目录及文件即可； 步骤： (1) 生成私钥； ~]# (umask 077; openssl genrsa -out /etc/pki/CA/private/cakey.pem 4096) (2) 生成自签证书； ~]# openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3655 -new：生成新证书签署请求； -x509：生成自签格式证书，专用于创建私有CA时； -key：生成请求时用到的私有文件路径； -out：生成的请求文件路径；如果自签操作将直接生成签署过的证书； -days：证书的有效时长，单位是day； (3) 为CA提供所需的目录及文件； ~]# mkdir -pv /etc/pki/CA/{certs,crl,newcerts} ~]# touch /etc/pki/CA/{serial,index.txt} ~]# echo 01 &gt; /etc/pki/CA/serial 要用到证书进行安全通信的服务器，需要向CA请求签署证书： 步骤：（以httpd为例） (1) 用到证书的主机生成私钥； ~]# mkdir /etc/httpd/ssl ~]# cd /etc/httpd/ssl ~]# (umask 077; openssl genrsa -out /etc/httpd/ssl/httpd.key 2048) (2) 生成证书签署请求 ~]# openssl req -new -key /etc/httpd/ssl/httpd.key -out /etc/httpd/ssl/httpd.csr -days 365 (3) 将请求通过可靠方式发送给CA主机； (4) 在CA主机上签署证书； ~]# openssl ca -in /tmp/httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 365 查看证书中的信息： ~]# openssl x509 -in /etc/pki/CA/certs/httpd.crt -noout -serial -subject 吊销证书： 步骤： (1) 客户端获取要吊销的证书的serial（在使用证书的主机执行）： ~]# openssl x509 -in /etc/pki/CA/certs/httpd.crt -noout -serial -subject (2) CA主机吊销证书 先根据客户提交的serial和subject信息，对比其与本机数据库index.txt中存储的是否一致； 吊销： # openssl ca -revoke /etc/pki/CA/newcerts/SERIAL.pem 其中的SERIAL要换成证书真正的序列号； (3) 生成吊销证书的吊销编号（第一次吊销证书时执行） # echo 01 &gt; /etc/pki/CA/crlnumber (4) 更新证书吊销列表 # openssl ca -gencrl -out thisca.crl 查看crl文件： # openssl crl -in /PATH/FROM/CRL_FILE.crl -noout -text 博客作业：加密解密技术基础、PKI及创建私有私有CA； OpenSSH： telnet：C/S，23/tcp CentOS 6： Server: telnet-server Client: telnet 服务进程有两种类型： 独立守护进程：自我管理； 超级守护进程：xinetd，服务器托管者，用于托管其它瞬时守护进程；自己是独立守护进程； 瞬时守护进程：非自我管理，而是由“超级守护进程”代为管理； xinetd： 配置文件：/etc/xinetd.conf, /etc/xinetd.d/(*) CentOS 7： Server: telnet-server Client: telnet ssh：Secure SHell， C/S： 22/tcp，安全地远程登录 Server：OpenSSH(sshd) Client：OpenSSH(ssh, scp), Windows： xshell, securecrt, sshsecureshellclient, putty； ssh protocol version: V1：不安全, man-in-middle V2： 主机认证：需要用到主机认证密钥；由服务器端维护和提供； 用户登录： 用户认证： 基于口令的认证； 基于密钥的认证； 用户提供一对儿密钥，私钥保留在客户端，公钥保留于远程服务器端的用户家目录下； OpenSSH： sshd：配置文件 /etc/ssh/sshd_config ssh: 配置文件 /etc/ssh/ssh_config 客户端程序： ssh [options] [user@]host [COMMAND] ssh [-l user] [options] host [COMMAND] 省略用户名： 使用本地用户名作为远程登录的用户名； 常用选项： -l user：以指定的用户登录远程主机； -p port：用于指明远程服务器的端口； -X：支持X11转发； -Y：支持信任的X11转发； X：协议； x-window, C/S X11转发的作用：在本地显示远程主机上的图形窗口； 前提：本地是X图形界面，或者提供了x service； -o StrictHostKeyChecking=no 接收的所有认可的服务器列表： ~/.ssh/known_hosts ssh远程连接服务器时的配置选项，定义在/etc/ssh/ssh_config配置文件中； HOST patttern OPTION1 VALUE OPTION2 VALUE ... ssh支持的用户认证方式： 基于口令的认证； 基于密钥的认证； (1) 在本地主机生成一对儿密钥： ssh-keygen [-q] [-b bits] [-t type] [-f output_keyfile] [-P passphrase] -t {rsa|ecdsa|dsa}：公钥加密算法类型； -b bits：指明密钥长度； -P passphrase：私钥加密密码； -f output_keyfile：生成密钥的保存位置； (2) 在本地主机上，将公钥复制到要登录的远程主机的某用户的家目录下的特定文件中(~/.ssh/authorized_keys) ssh-copy-id [-i [identity_file]] [-p port] [-o ssh_option] [user@]hostname (3) 测试 ssh user@host scp命令： 基于ssh连接完成复制 scp [options] SRC... DEST/ scp [options] SRC DEST 存在两种使用情形： PULL： scp [options] [user@]host:/PATH/TO/SOMEFILE /PATH/TO/SOMEFILE PUSH: scp [options] /PATH/TO/SOMEFILE [user@]host:/PATH/TO/SOMEFILE 常用选项： -r：递归复制； -p：保持原文件的权限信息； -q：静默模式； -P PORT：指明远程主机ssh协议监听的端口； sftp命令： ftp：file transfer protocol，明文； 安全的文件传输机制： ftps: ftp over ssl sftp: ftp over ssh sftp： C/S架构 S：由sshd服务进程管理，是sshd的一个子系统，在centos系统上的openssh上，默认为启动状态； /usr/libexec/openssh/sftp-server C：即sftp; 连接至远程主机： sftp user@host sftp&gt; help sshd（服务器端）： 配置文件：/etc/ssh/sshd_config 格式：配置指令 值 常用指令： Port 22 ListenAddress 0.0.0.0 Protocol 2 PermitRootLogin yes UseDNS no 手册页： man sshd_config man sshd man ssh_config man ssh 限制可登录的用户（配置文件）： AllowUsers user1 user2 user3 ... AllowGroups grp1 grp2 ... DenyUsers user1 user2 ... DenyGroups grp1 grp2 ... CentOS 6： 服务脚本：/etc/rc.d/init.d/sshd CentOS 7： Systemd Unit File：/usr/lib/systemd/system/sshd.service 并行的客户端工具： pssh: epel pssh pscp ssh服务的最佳实践： 1、不要使用默认端口； 2、禁止使用protocol version 1； 3、限制可登录的用户； 4、设定空闲会话超时时长； 5、利用防火墙设置ssh访问策略； 6、仅监听特定的IP地址； 7、基于口令认证时，使用强密码策略； # tr -dc A-Za-z0-9_ &lt; /dev/urandom | head -c 30 | xargs 8、使用基于密钥的认证； 9、禁止使用空密码； 10、禁止root用户直接登录； 11、限制ssh的访问频度和并发在线数； 12、做好日志，经常分析； /var/log/secure ssh协议的另一个实现：dropbear 轻量化的实现方案，多用于嵌入式环境中； 常用工具： dbclient：ssh协议客户端程序 dbclient [options] [user@]host[/port][,[user@]host/port],...] [command] dropbearkey：主机密钥生成工具 dropbearkey -t &lt;type&gt; -f &lt;filename&gt; [-s bits] /etc/dropbear/ 服务端程序： dropbear -p [IP:]PORT -F: 前台 -E：将日志发往错误输出]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[shell脚本练习]]></title>
      <url>%2F2017%2F05%2F21%2Fxiti1%2F</url>
      <content type="text"><![CDATA[常见shel题型第一题：99乘法表12345678910111213#!/bin/bash#for ((i=1;i&lt;=10;i++));do for ((j=1;j&lt;=i;j++));do echo -e &quot;$j*$i=$(($j*$i))\t\c&quot; done echodone 第二题：写一个脚本1、创建目录/tmp/dir-当前日期时间；例如/tmp/dir-20150707-155503。 2、在此目录中创建10个空文件，分别为file1-file10；1234567891011121314151617#!/bin/bash##设置一个变量，作为创建命令时的路径和目录名basedir=/root/test/tmp/dir`date +%Y%m%d-%H%M%S`#创建目录mkdir -p $basedir#进入到这个目录cd $basedir#使用for循环创建这个目录下的文件for i in &#123;1..10&#125;;do touch $basedir/$file$idone 第三题：写一个脚本1、创建用户tuser1-tuser9; 2、创建目录/tmp/dir-当前日期； 3、在/tmp/dir-当前日期 目录中创建9个空文件file101-file109 4、将file101的属主改为tuser1，依次类推，一直将file109的属主改为tuser9;1234567891011121314151617181920212223#!/bin/bash##定义一个变量，创建以当前日期为名称的目录basedir=/root/test/tmp/dir-`date +%Y%m%d`#创建目录mkdir -p $basedir#进入目录内cd $bashdir#使用for循环在当前目录下创建空文件file101-file109#并将file101的属主改为tuser1，以此类推，一直将file109的属主改为tuser9#因为系统中没有tuser的用户所有在循环中创建tuser用户#使用chown 用户 文件 来更改文件的属主for i in &#123;1..9&#125;;do filename=$basedir/file10$i touch $filename useradd tuser$i chown tuser$i $filename done 第四题：写一个脚本，完成以下任务。1、添加5个用户，user1-user5，每个用户的密码同用户名 2、添加密码完成后不显示passwd执行结果 3、显示添加成功信息123456789101112131415#!/bin/bash##使用for循环创建5个用户#每个用户的密码与用户名相同#密码设置完成后不显示执行结果#所有命令执行成功后显示成功信息for i in &#123;1..5&#125;;do username=user$i useradd $username echo $username | passwd --stdin $username &amp;&gt; /dev/null echo &quot;$username created successfully&quot;done 第五题：写一个脚本1、脚本可以接受一个以上的文件路径作为参数； 2、显示每个文件所拥的行数；1234567891011#!/bin/bash##使用for循环接收文件参数for file in $*;do#设置一个变量为wc -l的执行结果，切出来的就是行数 lines=`wc -l $file | cut -d&apos; &apos; -f1`#打印行数 echo &quot;$file has $lines lines.&quot;done 第六题：写一个脚本，不使用awk1、显示/etc/passwd文件中位于文件的第偶数行的用户名；并显示共有多少个这样的用户12345678910111213141516171819#!/bin/bash##首先定义一个变量，统计/etc/passwd/中共有多少行totalUSERs=`wc -l /etc/passwd | cut -d&quot; &quot; -f1`#使用for循环，从2开始，每隔2循环一次，到/etc/passwd,中的最后一行for i in `seq 2 2 $totalUSERs`;do #定义一个变量提取出偶数行的用户名 userName=`head -n $i /etc/passwd | tail -1 | cut -d: -f1` echo $userName#把提取出来的用户名输出到一个文本中去 echo $userName &gt;&gt; /root/test/tmp/count.tmpdone#对文本进行操作，输出到文本中的都是偶数行的用户，统计行数echo &quot;Total users:`wc -l /root/test/tmp/count.tmp | cut -d&quot; &quot; -f1` &quot; 第七题：写一个脚本指定一个用户名,判断此用户的用户名和它的基本组的组名是否相同12345678910111213141516171819202122232425#!/bin/bash##首先判断是否输入了参数if [ $# -ne 1 ];then echo &quot;请输入一个用户&quot; exit 3fi#判断输入的用户是否存在if ! id $1 &amp;&gt; /dev/null ;then echo &quot;$1 Not Exsits&quot; exit 4fi#定义输入的参数变量和查询后的组名变量username=$1groupname=`id $username -gn`#做字符串比较，如果查询到的输出等于输入的参数就相同，否则不同if [ &quot;$username&quot; == &quot;$groupname&quot; ];then echo &quot;same&quot;else echo &quot;Not same&quot;fi 第八题：写一个脚本1、判断当前主机的CPU生产商，（其信息保存在/proc/cpuinfo文件中） 如果是：AuthemticAMD,就显示其为AMD公司 GenuineIntel,就显示其为 Intel公司 否则，就显示其为其他公司。12345678910111213#!/bin/bash##定义变量为查询CPU的结果CPU=`egrep &quot;^vendor_id&quot; /proc/cpuinfo | tail -1 | cut -d: -f2`#做字符串比较if [ $CPU == &apos;GenuineIntel&apos; ] ;then echo &quot;Intel&quot;elif [ $CPU == &apos;AuthemticAMD&apos; ] ;then echo &quot;AMD&quot;else echo &quot;Other&quot;fi 第九题：写一个脚本1、给定三个用户名，将这些用户的帐号信息从/etc/passwd提取出来，然后放入/tmp/test.txt文件中，并在行首给定行号123456789101112131415#!/bin/bash##判断输入参数个数if [ $# -ne 3 ];then echo &quot;请输入三个用户名&quot; exit 3fi#定义一个变量，从0开始，作为行号，grep搜索以用户名开头的行提取出相关信息i=0for user in $*;do let i++ echo -e &quot;$i\t `grep &quot;^$user&quot; /etc/passwd`&quot; &gt;&gt; /root/test/tmp/test.txtdone 第十题：写一个脚本：计算100以内所有能被3整除的整数的和12345678#!/bin/bash#SUM=0for i in `seq 3 3 100`;do let SUM+=$idoneecho &quot;sum:$SUM&quot;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[编程函数（二）]]></title>
      <url>%2F2017%2F05%2F13%2Fbianchenghanshu2%2F</url>
      <content type="text"><![CDATA[函数返回值：函数的执行结果返回值： 显示使用echo或print命令输出； 函数体中调用的命令的执行结果； 函数的退出状态码： 默认取决与函数体中执行的最后一条命令的退出状态码 自定义：return 函数可以接受参数： 传递参数给函数： 在函数体当中，可以使用$1 $2 ...引用传递给函数的参数 在调用函数时，在函数名后面以空白符分隔给定参数列表即可，例如testfunc arg1 arg2 arg3 示例：添加十个用户， 添加用户的功能使用函数实现，用户名作为参数传输给函数123456789101112131415161718192021222324#!/bin/bash## 5 user existsadduser()&#123; if id $1 &amp;&gt; /dev/null;then return 5 else useradd $1 retval=$? return $retval fi&#125;for i in &#123;1..10&#125;;do adduser $&#123;1&#125;$&#123;i&#125; retval=$? if [ $retval -eq 0 ];then echo &quot;Add user $&#123;1&#125;$&#123;i&#125; finished&quot; elif [ $retval -eq 5];then echo &quot;user $&#123;1&#125;$&#123;i&#125; exists&quot; else echo &quot;Unkown Error&quot; fidone 变量作用域：局部变量：作用范围是函数的生命周期；在函数结束时被自动销毁 定义局部变量的方法：local VARIABLE=VALUE 本地变量：作用域是运行脚本的shell进程的生命周期；因此，其作用范围为当前shell脚本程序文件 示例 12345678910#！/bin/bash#name=tomsetname&#123; local name=jerry echo &quot;Function:$name&quot;&#125;setnameecho &quot;shell:$name&quot; 函数递归：函数直接或间接调用自身 阶乘示例 123456789fact()&#123; if [ $1 -eq 0 -o $1 -eq 1 ];then echo 1 else echo $[ $1*$(fact $[$1-1])] fi&#125;fact $1 斐波那契数列示例 123456789101112131415#!/bin/bash# fab() &#123; if [ $1 -eq 1 ];then echo 1 elif [ $2 -eq 2 ];then echo 1 else echo $[$(fab $[$1-1])+$(fab $[$1-2])] fi &#125; for i in $&#123;seq 1 $1&#125;;do fab $i done]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[编程函数（一）]]></title>
      <url>%2F2017%2F05%2F12%2Fbianchenghanshu%2F</url>
      <content type="text"><![CDATA[编程函数case 语句多分支if语句 if CONDITION1；then 分支1 elif CONDITION2 ；then 分支2 else CONDITION ；then 分支n fi 示例1：显示一个菜单给用户 cpu）display cpu information disk）display disk information quit）quit *） 要求： 提示用户给出自己的选择 正确的选择则给出相应的信息；否则提示重新选择正确的选项 123456789101112131415161718192021222324#!/bin/bash#cat&lt;&lt;EOFcpu）display cpu informationdisk）display disk informationquit）quit===============================EOFread -p &quot;请输入你的选项&quot; optionwhile [&quot;$option&quot; != &quot;cpu&quot; -a &quot;$option&quot; != &quot;disk&quot; -a &quot;$option&quot; != &quot;quit&quot;] echo &quot;请输入：cpu、disk、quit&quot; read -p &quot;请重新输入一次选项：&quot; optiondoneif [ &quot;$option&quot; == &quot;cpu&quot; ];then lscpuelif [ &quot;$option&quot; == &quot;disk&quot; ];then fdisk -l /dev/[hs]d[a-z]else echo &quot;quit&quot; exit 0fi case语句的语法格式： case $VARAIBLE in PART1) 分支1 ;; PART2) 分支2 ;; *) 分支n ;; esac case示例：1234567891011121314#!/bin/bash#case $option incpu) lscpu ;;disk) fdisk -l /dev/[hs]d[a-z];;*) echo &quot;quit&quot; exit 0 ;;case case支持glob风格的通配符 *任意长度的任意赐福 ？任意单个字符 []范围内任意单个字符 a|b或 示例：写一个服务框架脚本 此脚本可接收start、stop、restart、status、四个参数之一 如果参数非此四者，则提示使用帮助后退出 satrt，则创建lockfile，并显示启动； stop，则删除lockfile，并显示停止； restart，则先删除此文件再创建此文件，此后显示重启完成， status，如果lockfile存在，则显示running，否则显示为stoping 123456789101112131415161718192021222324252627282930313233343536#!/bin/bash#chkconfig: - 50 50#description：test service scriptprog=$&#123;basename $0&#125;lockfile=/var/lock/subsys/$progcase $1 instart) if [ -f $lockfile ];then echo &quot;$prog is running yet&quot; else touch $lockfile [ $? -eq 0 ] &amp;&amp; echo &quot;start $prog finshed&quot; fi ;;stop) if [ -f $lockfile ];then rm -f $lockfile [ $? -eq 0 ] &amp;&amp; echo &quot;stop $prog finshed&quot;esle touch -f $lockfile echo &quot;start $prog finshed&quot;fi;;statu) if [ -f $locakfile ];then echo &quot;$prog is running&quot; else echo &quot;$prog is stopped&quot; fi ;;*) echo &quot;usage :$prog &#123;start|stop|restart|status&#125;&quot; exit 1 ;;esac 函数：function 过程式编程：代码重用 模块化编程 结构化编程 把一段独立功能的代码当做一个整体并为之去一个名字；命名的代码段，此即为函数； 注意：定义函数的代码段不会自动执行，在调用时执行；所谓调用函数，在代码中给定函数名即可； 函数名出现的任意位置，在代码执行时，都会被自动替换为函数代码； 语法一： function f_name { 函数体 } 语法二： f_name() { 函数体 } 函数的生命周期：每次被调用时创建，返回时终止； 其状态返回结果为函数体中运行的最后一条命令的状态结果 自定义状态返回值，需要使用return return [0-255] 0:成功 1-255：失败 示例1：给定一个用户名，取得用户的ID号和默认shell123456789101112#!/bin/bash#username=$1userinfo() &#123; if id &quot;$username&quot; &amp;&gt; /dev/null ;then grep &quot;^$\&gt;&quot; | cut -d: -f3,7 else echo &quot;No such user&quot; fi&#125;userinfo 示例2：服务脚本框架 #!/bin/bash #chkconfig: - 50 50 #description：test service script prog=${basename $0} lockfile=/var/lock/subsys/$prog start(){ if [ -f $lockfile ];then echo &quot;$prog is running yet&quot; else touch $lockfile [ $? -eq 0 ] &amp;&amp; echo &quot;start $prog finshed&quot; fi } stop() { if [ -f $lockfile ];then rm -f $lockfile [ $? -eq 0 ] &amp;&amp; echo &quot;stop $prog finshed&quot; esle touch -f $lockfile echo &quot;start $prog finshed&quot; fi } statu() { if [ -f $locakfile ];then echo &quot;$prog is running&quot; else echo &quot;$prog is stopped&quot; fi } usage() { echo &quot;Usage:$prog {start|stop|restart|status}&quot; } case $1 in start) start ;; stop) stop ;; status) status ;; *) usage exit ;; esac]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[grub.conf格式]]></title>
      <url>%2F2017%2F05%2F11%2Fgrub-conf%2F</url>
      <content type="text"><![CDATA[grub.conf格式生成时间是安装系统的时间 default=0 timeout=3 password --md5 密码 进入单用户时需要输入口令，保护所有内核版本系统grub-md5-crypt生成md5加密密码 --encrypted grub-crypt生成sha512加密密码 title leessangzs OS root （hd0,0）根目录的路径，但是操作系统启动一开始是找boot的，所以此处写boot的路径hd表示硬盘，0表示第一个硬盘，0表示第一个分区 kernel /vmlinuz initrd /initramfs password 密码 进入此系统时需要的输入口令，只对当前内核版本有效 实验：删除grub.conf，恢复 进入命令行界面写两行 kernel行和initrd行 kernel /vmlinuz root=/dev/sda initrd /initrams 实验：删除grub，恢复 救援模式 切根 grub-install /dev/sda sync vim grub.conf default=0 timeout=3 title leessangz OS kernel /vmlinuz root=/dev/sda initrd /initramfs 实验：删除boot，恢复 boot里有 vmlinuz initramfs.img grub.conf 选用：rpm -ivh /mnt/cdrom/Packages/Kernel.XXXrpm 解决vmlinuz 救援模式去安装盘里拷一份vmlinuz放到boot下 解决initramfs.img mkinitrd /boot/initrdramfs.img `uname -r` sync同步一下 解决grub文件夹 grub-install /dev/sda 解决grub.conf vim grub.conf default=0 timeout=3 title leessangz OS kernel /vmlinuz root=/dev/sdax initrd /initramfs]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[实验：解决启动等级为6时无限重启]]></title>
      <url>%2F2017%2F05%2F03%2Fchange-open-level%2F</url>
      <content type="text"><![CDATA[实验：解决启动等级为6时无限重启 首先把/etc/inittab文件中最后一行启动等级改为6。 保存后重启发现系统无限重启。 解决：首先进入系统启动倒数界面。摁任意键。 进入列表界面后摁a键。 在命令行最后输入数字3.设置为当前启动等级为多用户模式。 进入系统以后再重新修改/etc/inittab文件。将启动等级恢复为3。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[实验：忘记登录密码，单用户模式下修改密码]]></title>
      <url>%2F2017%2F05%2F03%2Fchangepasswd%2F</url>
      <content type="text"><![CDATA[实验：忘记登录密码，单用户模式下修改密码进入系统启动倒数界面摁任意键。 进入列表界面摁a键。 在命令行末尾输入single或者数字1 回车后进入单用户模式，修改密码。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--locate]]></title>
      <url>%2F2017%2F04%2F25%2Fevery-day-linux-command18-locate%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–locate文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 locate 让使用者可以很快速的搜寻档案系统内是否有指定的档案。其方法是先建立一个包括系统内所有档案名称及路径的数据库，之后当寻找时就只需查询这个数据库，而不必实际深入档案系统之中了。在一般的 distribution 之中，数据库的建立都被放在 crontab 中自动执行。 1．命令格式： Locate [选择参数] [样式] 2．命令功能： locate命令可以在搜寻数据库时快速找到档案，数据库由updatedb程序来更新，updatedb是由cron daemon周期性建立的， locate命令在搜寻数据库时比由整个由硬盘资料来搜寻资料来得快，但较差劲的是locate所找到的档案若是最近才建立或 刚更名的，可能会找不到，在内定值中，updatedb每天会跑一次，可以由修改crontab来更新设定值。(etc/crontab) locate指定用在搜寻符合条件的档案，它会去储存档案与目录名称的数据库内，寻找合乎范本样式条件的档案或目录录， 可以使用特殊字元（如”*” 或”?”等）来指定范本样式，如指定范本为kcpa*ner, locate会找出所有起始字串为kcpa且 结尾为ner的档案或目录，如名称为kcpartner若目录录名称为kcpa_ner则会列出该目录下包括 子目录在内的所有档案。 locate指令和find找寻档案的功能类似，但locate是透过update程序将硬盘中的所有档案和目录资料先建立一个索引数据库， 在 执行loacte时直接找该索引，查询速度会较快，索引数据库一般是由操作系统管理，但也可以直接下达update强迫系统立 即修改索引数据库。 3．命令参数： -e 将排除在寻找的范围之外。 -1 如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到的档案。这会始速度减慢，因为 locate 必须至实际的档案系统中取得档案的权限资料。 -f 将特定的档案系统排除在外，例如我们没有到理要把 proc 档案系统中的档案放在资料库中。 -q 安静模式，不会显示任何错误讯息。 -n 至多显示 n个输出。 -r 使用正规运算式 做寻找的条件。 -o 指定资料库存的名称。 -d 指定资料库的路径 -h 显示辅助讯息 -V 显示程式的版本讯息 4．使用实例： 实例1:查找和pwd相关的所有文件 命令： locate pwd 输出：12345678910111213141516171819202122232425262728293031peida-VirtualBox ~ # locate pwd/bin/pwd/etc/.pwd.lock/sbin/unix_chkpwd/usr/bin/pwdx/usr/include/pwd.h/usr/lib/python2.7/dist-packages/twisted/python/fakepwd.py/usr/lib/python2.7/dist-packages/twisted/python/fakepwd.pyc/usr/lib/python2.7/dist-packages/twisted/python/test/test_fakepwd.py/usr/lib/python2.7/dist-packages/twisted/python/test/test_fakepwd.pyc/usr/lib/syslinux/pwd.c32/usr/share/help/C/empathy/irc-join-pwd.page/usr/share/help/ca/empathy/irc-join-pwd.page/usr/share/help/cs/empathy/irc-join-pwd.page/usr/share/help/de/empathy/irc-join-pwd.page/usr/share/help/el/empathy/irc-join-pwd.page 实例2： 搜索etc目录下所有以sh开头的文件 命令： locate /etc/sh 输出：123456789peida-VirtualBox ~ # locate /etc/sh/etc/shadow/etc/shadow-/etc/shellspeida-VirtualBox ~ # 实例3：搜索etc目录下，所有以m开头的文件 命令： locate /etc/m 输出：12345678910111213peida-VirtualBox ~ # locate /etc/m/etc/magic/etc/magic.mime/etc/mailcap/etc/mailcap.order/etc/manpath.config/etc/mate-settings-daemon]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--whereis]]></title>
      <url>%2F2017%2F04%2F24%2Fevery-day-linux-command17-whereis%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–whereis文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。 和find相比，whereis查找的速度非常快，这是因为linux系统会将 系统内的所有文件都记录在一个数据库文件中，当使用whereis和下面即将介绍的locate时，会从数据库中查找数据，而不是像find命令那样，通 过遍历硬盘来查找，效率自然会很高。 但是该数据库文件并不是实时更新，默认情况下时一星期更新一次，因此，我们在用whereis和locate 查找文件时，有时会找到已经被删除的数据，或者刚刚建立文件，却无法查找到，原因就是因为数据库文件没有被更新。 1．命令格式： whereis [-bmsu] [BMS 目录名 -f ] 文件名 2．命令功能： whereis命令是定位可执行文件、源代码文件、帮助文件在文件系统中的位置。这些文件的属性应属于原始代码，二进制文件， 或是帮助文件。whereis 程序还具有搜索源代码、指定备用搜索路径和搜索不寻常项的能力。 3．命令参数： -b 定位可执行文件。 -m 定位帮助文件。 -s 定位源代码文件。 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件。 -B 指定搜索可执行文件的路径。 -M 指定搜索帮助文件的路径。 -S 指定搜索源代码文件的路径。 4．使用实例： 实例1：将和**文件相关的文件都查找出来 命令： whereis svn 输出：1234567[root@localhost ~]# whereis tomcattomcat:[root@localhost ~]# whereis svnsvn: /usr/bin/svn /usr/local/svn /usr/share/man/man1/svn.1.gz 说明： tomcat没安装，找不出来，svn安装找出了很多相关文件 实例2：只将二进制文件 查找出来 命令： whereis -b svn 输出：12345678910111213[root@localhost ~]# whereis -b svnsvn: /usr/bin/svn /usr/local/svn[root@localhost ~]# whereis -m svnsvn: /usr/share/man/man1/svn.1.gz[root@localhost ~]# whereis -s svnsvn:[root@localhost ~]# 说明： whereis -m svn 查出说明文档路径，whereis -s svn 找source源文件。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Home目录迁移]]></title>
      <url>%2F2017%2F04%2F24%2Fmove-home%2F</url>
      <content type="text"><![CDATA[迁移Home目录到新分区1.备份Home目录12[root@localhost ~]# mkdir /bak[root@localhost ~]# cp -a /home /bak/ 2.创建Home所需要迁移到的新分区1234567891011121314151617181920212223242526272829[root@localhost /]# fdisk /dev/sdbDevice contains neither a valid DOS partition table, nor Sun, SGI or OSF disklabelBuilding a new DOS disklabel with disk identifier 0xc32bdfe3.Changes will remain in memory only, until you decide to write them.After that, of course, the previous content won&apos;t be recoverable.Warning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite)WARNING: DOS-compatible mode is deprecated. It&apos;s strongly recommended to switch off the mode (command &apos;c&apos;) and change display units to sectors (command &apos;u&apos;).Command (m for help): 输入：nCommand action e extended p primary partition (1-4) 输入：pPartition number (1-4): 1 输入：1First cylinder (1-2610, default 1): Using default value 1Last cylinder, +cylinders or +size&#123;K,M,G&#125; (1-2610, default 2610): +5GCommand (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks. 实验环境为Home分配一个5G新分区sdb1。 3.格式化新分区1234567891011121314151617181920212223[root@localhost /]# mkfs.ext4 /dev/sdb1mke2fs 1.41.12 (17-May-2010)Filesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks328656 inodes, 1313305 blocks65665 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=134637158441 block groups32768 blocks per group, 32768 fragments per group8016 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736Writing inode tables: done Creating journal (32768 blocks): doneWriting superblocks and filesystem accounting information: doneThis filesystem will be automatically checked every 31 mounts or180 days, whichever comes first. Use tune2fs -c or -i to override. 这里选择ext4的文件系统 4.将新分区临时挂载并在分区上新建Home目录12[root@localhost /]# mkdir /mnt/home[root@localhost /]# mount /dev/sdb1 /mnt/home 5.将系统改为单用户模式1[root@localhost /]# init 1 为了防止其他用户在迁移过程中对Home目录进行修改。 6.把Hmoe目录下的所有文件，拷贝到新建的Home目录中123456789[root@localhost home]# cp -av /home/* /mnt/home/`/home/user1&apos; -&gt; `/mnt/home/user1&apos;`/home/user1/.bash_logout&apos; -&gt; `/mnt/home/user1/.bash_logout&apos;`/home/user1/.bashrc&apos; -&gt; `/mnt/home/user1/.bashrc&apos;`/home/user1/.mozilla&apos; -&gt; `/mnt/home/user1/.mozilla&apos;`/home/user1/.mozilla/extensions&apos; -&gt; `/mnt/home/user1/.mozilla/extensions&apos;`/home/user1/.mozilla/plugins&apos; -&gt; `/mnt/home/user1/.mozilla/plugins&apos;`/home/user1/.bash_profile&apos; -&gt; `/mnt/home/user1/.bash_profile&apos;`/home/user1/.gnome2&apos; -&gt; `/mnt/home/user1/.gnome2&apos; 做这步操作之前要确保系统中已经创件过新用户，不然Home为空。 7.将原有Home目录删除12[root@localhost home]# rm -rf /home/*[root@localhost home]# 8.修改配置文件。使Home目录开机自动挂载到新分区首先用blkid命令查询需要挂载的分区的UUID12345678[root@localhost home]# blkid/dev/sda1: UUID=&quot;1b111728-c1d4-4814-bc8d-68376790c00e&quot; TYPE=&quot;ext4&quot; /dev/sda2: UUID=&quot;ufu0Lv-xfQQ-zs4y-dhsz-4tae-btjc-kBrhoM&quot; TYPE=&quot;LVM2_member&quot; /dev/sdb1: UUID=&quot;9220e3b8-ac6f-4da5-883d-e7b20a8d1400&quot; TYPE=&quot;ext4&quot; /dev/mapper/vg0-root: UUID=&quot;12e97ef4-2c8a-4604-a3e4-d831c47117ef&quot; TYPE=&quot;ext4&quot; /dev/mapper/vg0-swap: UUID=&quot;425afff3-9081-4cfd-97f4-d7f4ba3438b1&quot; TYPE=&quot;swap&quot; /dev/mapper/vg0-usr: UUID=&quot;a2310e89-94ab-417b-aa07-2758157ad154&quot; TYPE=&quot;ext4&quot; /dev/mapper/vg0-var: UUID=&quot;3ddb530b-4aed-44f5-8937-83bb3158dce2&quot; TYPE=&quot;ext4&quot; 然后修改配置文件fstab，在最后一行添加。1234567891011121314151617## /etc/fstab# Created by anaconda on Wed May 3 08:41:37 2017## Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos;# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/vg0-root / ext4 defaults 1 1UUID=1b111728-c1d4-4814-bc8d-68376790c00e /boot ext4 defaults 1 2/dev/mapper/vg0-usr /usr ext4 defaults 1 2/dev/mapper/vg0-var /var ext4 defaults 1 2/dev/mapper/vg0-swap swap swap defaults 0 0tmpfs /dev/shm tmpfs defaults 0 0devpts /dev/pts devpts gid=5,mode=620 0 0sysfs /sys sysfs defaults 0 0proc /proc proc defaults 0 0UUID=9220e3b8-ac6f-4da5-883d-e7b20a8d1400 /home ext4 defaults 0 0 最后一行UUID是home挂载到的新分区的UUID。/dev/sdb1 9.生效mount -a 10.退出单用户模式init 5 11.卸载临时目录并删除123456789101112131415161718[root@localhost home]# umount /mnt/home[root@localhost home]# rmdir /mnt/home[root@localhost home]# [root@localhost home]# [root@localhost home]# [root@localhost home]# [root@localhost home]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsr0 11:0 1 1024M 0 rom sda 8:0 0 100G 0 disk ├─sda1 8:1 0 200M 0 part /boot└─sda2 8:2 0 60G 0 part ├─vg0-root (dm-0) 253:0 0 20G 0 lvm / ├─vg0-swap (dm-1) 253:1 0 2G 0 lvm [SWAP] ├─vg0-usr (dm-2) 253:2 0 10G 0 lvm /usr └─vg0-var (dm-3) 253:3 0 20G 0 lvm /varsdb 8:16 0 20G 0 disk └─sdb1 8:17 0 5G 0 part /home 使用lsblk命令查询分区信息后发现。/home目录已经迁移到了sdb1上。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--which]]></title>
      <url>%2F2017%2F04%2F23%2Fevery-day-linux-command16-which%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–which文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 我们经常在linux要查找某个文件，但不知道放在哪里了，可以使用下面的一些命令来搜索： which 查看可执行文件的位置。 whereis 查看文件的位置。 locate 配合数据库查看文件位置。 find 实际搜寻硬盘查询文件名称。 which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 1．命令格式： which 可执行文件名称 2．命令功能： which指令会在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。 3．命令参数： -n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。 -p 与-n参数相同，但此处的包括了文件的路径。 -w 指定输出时栏位的宽度。 -V 显示版本信息 4．使用实例： 实例1：查找文件、显示命令路径 命令： which lsmod 输出：123456789[root@localhost ~]# which pwd/bin/pwd[root@localhost ~]# which adduser/usr/sbin/adduser[root@localhost ~]# 说明： which 是根据使用者所配置的 PATH 变量内的目录去搜寻可运行档的！所以，不同的 PATH 配置内容所找到的命令当然不一样的！ 实例2：用 which 去找出 which 命令： which which 输出：1234567[root@localhost ~]# which whichalias which=&apos;alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde&apos; /usr/bin/which[root@localhost ~]# 说明： 竟然会有两个 which ，其中一个是 alias 这就是所谓的『命令别名』，意思是输入 which 会等于后面接的那串命令！ cd 这个常用的命令竟然找不到啊！为什么呢？这是因为 cd 是bash 内建的命令！ 但是 which 默认是找 PATH 内所规范的目录，所以当然一定找不到的！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--tail]]></title>
      <url>%2F2017%2F04%2F22%2Fevery-day-linux-command15-tail%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–tail文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 tail 命令从指定点开始将文件写到标准输出.使用tail命令的-f选项可以方便的查阅正在改变的日志文件,tail -f filename会把filename里最尾部的内容显示在屏幕上,并且不但刷新,使你看到最新的文件内容. 1．命令格式; tail[必要参数][选择参数][文件] 2．命令功能： 用于显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。 3．命令参数： -f 循环读取 -q 不显示处理信息 -v 显示详细的处理信息 -c&lt;数目&gt; 显示的字节数 -n&lt;行数&gt; 显示行数 --pid=PID 与-f合用,表示在进程ID,PID死掉之后结束. -q, --quiet, --silent 从不输出给出文件名的首部 -s, --sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒 4．使用实例： 实例1：显示文件末尾内容 命令： tail -n 5 log2014.log 输出：1234567891011[root@localhost test]# tail -n 5 log2014.log 2014-092014-102014-112014-12[root@localhost test]# 说明： 显示文件最后5行内容 实例2：循环查看文件内容 命令： tail -f test.log 输出：1234567891011121314151617181920212223242526272829[root@localhost ~]# ping 192.168.120.204 &gt; test.log &amp;[1] 11891[root@localhost ~]# tail -f test.log PING 192.168.120.204 (192.168.120.204) 56(84) bytes of data.64 bytes from 192.168.120.204: icmp_seq=1 ttl=64 time=0.038 ms64 bytes from 192.168.120.204: icmp_seq=2 ttl=64 time=0.036 ms64 bytes from 192.168.120.204: icmp_seq=3 ttl=64 time=0.033 ms64 bytes from 192.168.120.204: icmp_seq=4 ttl=64 time=0.027 ms64 bytes from 192.168.120.204: icmp_seq=5 ttl=64 time=0.032 ms64 bytes from 192.168.120.204: icmp_seq=6 ttl=64 time=0.026 ms64 bytes from 192.168.120.204: icmp_seq=7 ttl=64 time=0.030 ms64 bytes from 192.168.120.204: icmp_seq=8 ttl=64 time=0.029 ms64 bytes from 192.168.120.204: icmp_seq=9 ttl=64 time=0.044 ms64 bytes from 192.168.120.204: icmp_seq=10 ttl=64 time=0.033 ms64 bytes from 192.168.120.204: icmp_seq=11 ttl=64 time=0.027 ms[root@localhost ~]# 说明： ping 192.168.120.204 &gt; test.log 在后台ping远程主机。并输出文件到test.log；这种做法也使用于一个以上 的档案监视。用Ctrl＋c来终止。 实例3：从第5行开始显示文件 命令： tail -n +5 log2014.log 输出：123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@localhost test]# cat log2014.log 2014-012014-022014-032014-042014-052014-062014-072014-082014-092014-102014-112014-12==============================[root@localhost test]# tail -n +5 log2014.log2014-052014-062014-072014-082014-092014-102014-112014-12]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--head]]></title>
      <url>%2F2017%2F04%2F21%2Fevery-day-linux-command14-head%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–head文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 head 与 tail 就像它的名字一样的浅显易懂，它是用来显示开头或结尾某个数量的文字区块，head 用来显示档案的开头至标准输出中，而 tail 想当然尔就是看档案的结尾。 1．命令格式： head [参数]... [文件]... 2．命令功能： head 用来显示档案的开头至标准输出中，默认head命令打印其相应文件的开头10行。 3．命令参数： -q 隐藏文件名 -v 显示文件名 -c&lt;字节&gt; 显示字节数 -n&lt;行数&gt; 显示的行数 4．使用实例： 实例1：显示文件的前n行 命令： head -n 5 log2014.log 输出：123456789101112131415161718192021222324252627282930313233343536373839[root@localhost test]# cat log2014.log 2014-012014-022014-032014-042014-052014-062014-072014-082014-092014-102014-112014-12==============================[root@localhost test]# head -n 5 log2014.log 2014-012014-022014-032014-042014-05[root@localhost test]# 实例2：显示文件前n个字节 命令： head -c 20 log2014.log 输出：123456789[root@localhost test]# head -c 20 log2014.log2014-012014-022014[root@localhost test]# 实例3：文件的除了最后n个字节以外的内容 命令： head -c -32 log2014.log 输出：12345678910111213141516171819202122232425[root@localhost test]# head -c -32 log2014.log2014-012014-022014-032014-042014-052014-062014-072014-082014-092014-102014-112014-12[root@localhost test]# 实例4：输出文件除了最后n行的全部内容 命令： head -n -6 log2014.log 输出：123456789101112131415[root@localhost test]# head -n -6 log2014.log2014-012014-022014-032014-042014-052014-062014-07[root@localhost test]#]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--less]]></title>
      <url>%2F2017%2F04%2F20%2Fevery-day-linux-command13-less%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–less文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 每天一个linux命令–less less 工具也是对文件或其它输出进行分页显示的工具，应该说是linux正统查看文件内容的工具，功能极其强大。less 的用法比起 more 更加的有弹性。在 more 的时候，我们并没有办法向前面翻， 只能往后面看，但若使用了 less 时，就可以使用 [pageup] [pagedown] 等按键的功能来往前往后翻看文件，更容易用来查看一个文件的内容！除此之外，在 less 里头可以拥有更多的搜索功能，不止可以向下搜，也可以向上搜。 1．命令格式： less [参数] 文件 2．命令功能： less与more类似，但使用less 可以随意浏览文件，而more仅能向前移动，却不能向后移动， 而且less在查看之前不会加载整个文件。 3．命令参数： -b &lt;缓冲区大小&gt; 设置缓冲区的大小 -e 当文件显示结束后，自动离开 -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -g 只标志最后搜索的关键词 -i 忽略搜索时的大小写 -m 显示类似more命令的百分比 -N 显示每行的行号 -o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来 -Q 不使用警告音 -s 显示连续空行为一行 -S 行过长时间将超出部分舍弃 -x &lt;数字&gt; 将“tab”键显示为规定的数字空格 /字符串：向下搜索“字符串”的功能 ?字符串：向上搜索“字符串”的功能 n：重复前一个搜索（与 / 或 ? 有关） N：反向重复前一个搜索（与 / 或 ? 有关） b 向后翻一页 d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一行 回车键 滚动一页 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--more]]></title>
      <url>%2F2017%2F04%2F19%2Fevery-day-linux-command12-more%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–more文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 more命令，功能类似 cat ，cat命令是整个文件的内容从上到下显示在屏幕上。 more会以一页一页的显示方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示，而且还有搜寻字串的功能 。more命令从前向后读取文件，因此在启动时就加载整个文件。 1．命令格式： more [-dlfpcsu ] [-num ] [+/ pattern] [+ linenum] [file ... ] 2．命令功能： more命令和cat的功能一样都是查看文件里的内容，但有所不同的是more可以按页来查看文件的内容，还支持直接跳转行等功能。 3．命令参数： +n 从笫n行开始显示 -n 定义屏幕大小为n行 +/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 -c 从顶部清屏，然后显示 -d 提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能 -l 忽略Ctrl+l（换页）字符 -p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似 -s 把连续的多个空行显示为一行 -u 把文件内容中的下画线去掉 4．常用操作命令： Enter 向下n行，需要定义。默认为1行 Ctrl+F 向下滚动一屏 空格键 向下滚动一屏 Ctrl+B 返回上一屏 = 输出当前行的行号 ：f 输出文件名和当前行的行号 V 调用vi编辑器 !命令 调用Shell，并执行命令 q 退出more 5．命令实例： 实例1：显示文件中从第3行起的内容 命令： more +3 log2012.log 输出：1234567891011121314151617181920212223242526272829303132333435[root@localhost test]# cat log2012.log 2012-012012-022012-032012-04-day12012-04-day22012-04-day3======[root@localhost test]# more +3 log2012.log 2012-032012-04-day12012-04-day22012-04-day3======[root@localhost test]#``` 实例2：从文件中查找第一个出现&quot;day3&quot;字符串的行，并从该处前两行开始显示输出 命令： more +/day3 log2012.log输出： [root@localhost test]# more +/day3 log2012.log …skipping 2012-04-day1 2012-04-day2 2012-04-day3 2012-05 2012-05-day1 ======[root@localhost test]#1234567实例3：设定每屏显示行数 命令： more -5 log2012.log输出： [root@localhost test]# more -5 log2012.log 2012-01 2012-02 2012-03 2012-04-day1 2012-04-day2123456789101112说明： 如下图所示，最下面显示了该屏展示的内容占文件总行数的比例，按 Ctrl+F 或者空格键 将会显示下一屏5条内容， 百分比也会跟着变化。实例4：列一个目录下的文件，由于内容太多，我们应该学会用more来分页显示。这得和管道 | 结合起来 命令： ls -l | more -5输出： [root@localhost test]# ls -l | more -5 总计 36 -rw-r–r– 1 root root 308 11-01 16:49 log2012.log -rw-r–r– 1 root root 33 10-28 16:54 log2013.log -rw-r–r– 1 root root 127 10-28 16:51 log2014.log lrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.log -rw-r–r– 1 root root 25 10-28 17:02 log.log -rw-r–r– 1 root root 37 10-28 17:07 log.txt drwxr-xr-x 6 root root 4096 10-27 01:58 scf drwxrwxrwx 2 root root 4096 10-28 14:47 test3 drwxrwxrwx 2 root root 4096 10-28 14:47 test4```说明： 每页显示5个文件信息，按 Ctrl+F 或者 空格键 将会显示下5条文件信息。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--nl]]></title>
      <url>%2F2017%2F04%2F18%2Fevery-day-linux-command11-nl%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–nl文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 nl命令在linux系统中用来计算文件中行号。nl 可以将输出的文件内容自动的加上行号！其默认的结果与 cat -n 有点不太一样， nl 可以将行号做比较多的显示设计，包括位数与是否自动补齐 0 等等的功能。 1．命令格式：nl [选项]... [文件]... 2．命令参数：-b ：指定行号指定的方式，主要有两种： -b a ：表示不论是否为空行，也同样列出行号(类似 cat -n)； -b t ：如果有空行，空的那一行不要列出行号(默认值)； -n ：列出行号表示的方法，主要有三种： -n ln ：行号在萤幕的最左方显示； -n rn ：行号在自己栏位的最右方显示，且不加 0 ； -n rz ：行号在自己栏位的最右方显示，且加 0 ； -w ：行号栏位的占用的位数。 -p 在逻辑定界符处不重新开始计算。 3．命令功能：nl 命令读取 File 参数（缺省情况下标准输入），计算输入中的行号，将计算过的行号写入标准输出。 在输出中，nl 命令根据您在命令行中指定的标志来计算左边的行。输入文本必须写在逻辑页中。每个 逻辑页有头、主体和页脚节（可以有空节）。 除非使用 -p 标志，nl 命令在每个逻辑页开始的地方重新 设置行号。 可以单独为头、主体和页脚节设置行计算标志（例如，头和页脚行可以被计算然而文本行不能）。 4．使用实例：实例一：用 nl 列出 log2012.log 的内容 命令： nl log2012.log 输出：1234567891011[root@localhost test]# nl log2012.log 1 2012-01 2 2012-02 3 ======[root@localhost test]# 说明： 文件中的空白行，nl 不会加上行号 实例二：用 nl 列出 log2012.log 的内容，空本行也加上行号 命令： nl -b a log2012.log 输出：1234567891011[root@localhost test]# nl -b a log2012.log 1 2012-01 2 2012-02 3 4 5 ======[root@localhost test]# 实例3：让行号前面自动补上0,统一输出格式 命令： 输出：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@localhost test]# nl -b a -n rz log2014.log 000001 2014-01000002 2014-02000003 2014-03000004 2014-04000005 2014-05000006 2014-06000007 2014-07000008 2014-08000009 2014-09000010 2014-10000011 2014-11000012 2014-12000013 =======[root@localhost test]# nl -b a -n rz -w 3 log2014.log 001 2014-01002 2014-02003 2014-03004 2014-04005 2014-05006 2014-06007 2014-07008 2014-08009 2014-09010 2014-10011 2014-11012 2014-12013 ======= 说明： nl -b a -n rz 命令行号默认为六位，要调整位数可以加上参数 -w 3 调整为3位。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--cat]]></title>
      <url>%2F2017%2F04%2F17%2Fevery-day-linux-command10-cat%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–cat文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 cat命令的用途是连接文件或标准输入并打印。这个命令常用来显示文件内容，或者将几个文件连接起来显示，或者从标准输入读取内容并显示，它常与重定向符号配合使用。 1．命令格式：cat [选项] [文件]... 2．命令功能：cat主要有三大功能： 1.一次显示整个文件:cat filename 2.从键盘创建一个文件:cat &gt; filename 只能创建新文件,不能编辑已有文件. 3.将几个文件合并为一个文件:cat file1 file2 &gt; file 3．命令参数：-A, --show-all 等价于 -vET -b, --number-nonblank 对非空输出行编号 -e 等价于 -vE -E, --show-ends 在每行结束处显示 $ -n, --number 对输出的所有行编号,由1开始对所有输出的行数编号 -s, --squeeze-blank 有连续两行以上的空白行，就代换为一行的空白行 -t 与 -vT 等价 -T, --show-tabs 将跳格字符显示为 ^I -u (被忽略) -v, --show-nonprinting 使用 ^ 和 M- 引用，除了 LFD 和 TAB 之外 4．使用实例：实例一：把 log2012.log 的文件内容加上行号后输入 log2013.log 这个文件里 命令： cat -n log2012.log log2013.log 输出：12345678910111213141516171819202122232425262728293031323334353637[root@localhost test]# cat log2012.log 2012-012012-02======[root@localhost test]# cat log2013.log 2013-012013-022013-03======[root@localhost test]# cat -n log2012.log log2013.log 1 2012-01 2 2012-02 3 4 5 ====== 6 2013-01 7 2013-02 8 9 10 2013-03 11 ======[root@localhost test]# 实例二：把 log2012.log 和 log2013.log 的文件内容加上行号（空白行不加）之后将内容附加到 log.log 里。 命令： cat -b log2012.log log2013.log log.log 输出：123456789101112131415[root@localhost test]# cat -b log2012.log log2013.log log.log 1 2012-01 2 2012-02 3 ====== 4 2013-01 5 2013-02 6 2013-03 7 ======[root@localhost test]# 实例三：把 log2012.log 的文件内容加上行号后输入 log.log 这个文件里 命令： 输出：1234567891011121314151617[root@localhost test]# cat log.log [root@localhost test]# cat -n log2012.log &gt; log.log[root@localhost test]# cat -n log.log 1 2012-01 2 2012-02 3 4 5 ======[root@localhost test]# 实例四：使用here doc来生成文件 输出：123456789101112131415161718192021222324252627[root@localhost test]# cat &gt;log.txt &lt;&lt;EOF&gt; Hello&gt; World&gt; Linux&gt; PWD=$(pwd)&gt; EOF[root@localhost test]# ls -l log.txt -rw-r--r-- 1 root root 37 10-28 17:07 log.txt[root@localhost test]# cat log.txt HelloWorldLinuxPWD=/opt/soft/test[root@localhost test]# 说明： 注意粗体部分，here doc可以进行字符串替换。 备注： tac (反向列示) 命令： tac log.txt 输出：123456789[root@localhost test]# tac log.txt PWD=/opt/soft/testLinuxWorldHello 说明： tac 是将 cat 反写过来，所以他的功能就跟 cat 相反， cat是由第一行到最后一行连续显示在萤幕上， 而 tac 则是由最后一行到第一行反向在萤幕上显示出来！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--touch]]></title>
      <url>%2F2017%2F04%2F16%2Fevery-day-linux-command9-touch%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–touch文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 Linux的touch命令不常用，一般在使用make的时候可能会用到，用来修改文件时间戳，或者新建一个不存在的文件。 1．命令格式：touch [选项]... 文件... 2．命令参数：-a 或--time=atime或--time=access或--time=use 只更改存取时间。 -c 或--no-create 不建立任何文档。 -d 使用指定的日期时间，而非现在的时间。 -f 此参数将忽略不予处理，仅负责解决BSD版本touch指令的兼容性问题。 -m 或--time=mtime或--time=modify 只更改变动时间。 -r 把指定文档或目录的日期时间，统统设成和参考文档或目录的日期时间相同。 -t 使用指定的日期时间，而非现在的时间。 3．命令功能：touch命令参数可更改文档或目录的日期时间，包括存取时间和更改时间。 4．使用范例：实例一：创建不存在的文件 命令： touch log2012.log log2013.log 输出：1234567891011121314151617[root@localhost test]# touch log2012.log log2013.log[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 16:01 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log如果log2014.log不存在，则不创建文件[root@localhost test]# touch -c log2014.log[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 16:01 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log 实例二：更新log.log的时间和log2012.log时间戳相同 命令： touch -r log.log log2012.log 输出：1234567891011121314151617[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 16:01 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log[root@localhost test]# touch -r log.log log2012.log [root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log 实例三：设定文件的时间戳 命令： touch -t 201211142234.50 log.log 输出：1234567891011121314151617[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log[root@localhost test]# touch -t 201211142234.50 log.log[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log2012.log-rw-r--r-- 1 root root 0 10-28 16:01 log2013.log-rw-r--r-- 1 root root 0 2012-11-14 log.log 说明： -t time 使用指定的时间值 time 作为指定文件相应时间戳记的新值．此处的 time规定为如下形式的十进制数: [[CC]YY]MMDDhhmm[.SS] 这里，CC为年数中的前两位，即”世纪数”；YY为年数的后两位，即某世纪中的年数．如果不给出CC的值，则touch 将把年数CCYY限定在1969--2068之内．MM为月数，DD为天将把年数CCYY限定在1969--2068之内．MM为月数，DD 为天数hh 为小时数(几点)，mm为分钟数，SS为秒数。此处秒的设定范围是0--61，这样可以处理闰秒．这些数字组 成的时间是环境变量TZ指定的时区中的一个时间．由于系统的限制，早于1970年1月1日的时间是错误的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--cp]]></title>
      <url>%2F2017%2F04%2F15%2Fevery-day-linux-command8-cp%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–cp文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 cp命令用来复制文件或者目录，是Linux系统中最常用的命令之一。一般情况下，shell会设置一个别名，在命令行下复制文件时，如果目标文件已经存在，就会询问是否覆盖，不管你是否使用-i参数。但是如果是在shell脚本中执行cp时，没有-i参数时不会询问是否覆盖。这说明命令行和shell脚本的执行方式有些不同。 1．命令格式：cp [选项]... [-T] 源 目的 或：cp [选项]... 源... 目录 或：cp [选项]... -t 目录 源... 2．命令功能：将源文件复制至目标文件，或将多个源文件复制至目标目录。 3．命令参数：-a, --archive 等于-dR --preserve=all --backup[=CONTROL 为每个已存在的目标文件创建备份 -b 类似--backup 但不接受参数 --copy-contents 在递归处理是复制特殊文件内容 -d 等于--no-dereference --preserve=links -f, --force 如果目标文件无法打开则将其移除并重试(当 -n 选项存在时则不需再选此项) -i, --interactive 覆盖前询问(使前面的 -n 选项失效) -H 跟随源文件中的命令行符号链接 -l, --link 链接文件而不复制 -L, --dereference 总是跟随符号链接 -n, --no-clobber 不要覆盖已存在的文件(使前面的 -i 选项失效) -P, --no-dereference 不跟随源文件中的符号链接 -p 等于--preserve=模式,所有权,时间戳 --preserve[=属性列表 保持指定的属性(默认：模式,所有权,时间戳)，如果可能保持附加属性： 环境、链接、xattr 等 -R, -r, --recursive 复制目录及目录内的所有项目 4．命令实例：实例一：复制单个文件到目标目录，文件在目标文件中不存在 命令： cp log.log test5 输出：1234567891011121314151617181920212223[root@localhost test]# cp log.log test5[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxr-xr-x 2 root root 4096 10-28 14:53 test5[root@localhost test]# cd test5[root@localhost test5]# ll-rw-r--r-- 1 root root 0 10-28 14:46 log5-1.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-2.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-3.log-rw-r--r-- 1 root root 0 10-28 14:53 log.log 说明： 在没有带-a参数时，两个文件的时间是不一样的。在带了-a参数时，两个文件的时间是一致的。 实例二：目标文件存在时，会询问是否覆盖 命令： cp log.log test5 输出：12345678910111213141516171819[root@localhost test]# cp log.log test5cp：是否覆盖“test5/log.log”? n[root@localhost test]# cp -a log.log test5cp：是否覆盖“test5/log.log”? y[root@localhost test]# cd test5/[root@localhost test5]# ll-rw-r--r-- 1 root root 0 10-28 14:46 log5-1.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-2.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-3.log-rw-r--r-- 1 root root 0 10-28 14:48 log.log 说明： 目标文件存在时，会询问是否覆盖。这是因为cp是cp -i 的别名。目标文件存在时，即使加了-f标志，也还会询问是否覆盖。 实例三：复制整个目录 命令： 输出：123456789101112131415161718192021222324252627282930313233343536373839404142434445目标目录存在时：[root@localhost test]# cp -a test3 test5 [root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxr-xr-x 3 root root 4096 10-28 15:11 test5[root@localhost test]# cd test5/[root@localhost test5]# ll-rw-r--r-- 1 root root 0 10-28 14:46 log5-1.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-2.log-rw-r--r-- 1 root root 0 10-28 14:46 log5-3.log-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxrwxrwx 2 root root 4096 10-28 14:47 test3目标目录不存在是：[root@localhost test]# cp -a test3 test4[root@localhost test]# ll-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4drwxr-xr-x 3 root root 4096 10-28 15:11 test5[root@localhost test]# 说明： 注意目标目录存在与否结果是不一样的。目标目录存在时，整个源目录被复制到目标目录里面。 实例四：复制的 log.log 建立一个连结档 log_link.log 命令： cp -s log.log log_link.log 输出：123456789101112131415[root@localhost test]# cp -s log.log log_link.log[root@localhost test]# lllrwxrwxrwx 1 root root 7 10-28 15:18 log_link.log -&gt; log.log-rw-r--r-- 1 root root 0 10-28 14:48 log.logdrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 14:47 test3drwxrwxrwx 2 root root 4096 10-28 14:47 test4drwxr-xr-x 3 root root 4096 10-28 15:11 test5 说明： 那个 log_link.log 是由 -s 的参数造成的，建立的是一个『快捷方式』， 所以您会看到在文件的最右边，会显示这个文件是『连结』到哪里去的！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux运维脚本编写规范]]></title>
      <url>%2F2017%2F04%2F14%2Fshell-guifan%2F</url>
      <content type="text"><![CDATA[Linux运维脚本编写规范1.脚本名以.sh结尾，名称尽量见名知意，比如，ClearLog.sh、 Clear_Log.sh、clearlog.sh、SerRestart.sh、Ser_Restart.sh; 2.尽量使用UTF-8编码，注释及输出尽量使用英文。 3.一般情况下都赋予执行权限，但一些关于变量的配置文件不用加执行权限。 4.脚本执行的时候可以使用bash执行，或者使用bash -x执行，可以直观的显示具体的执行过程。 5.脚本首行使用#!/bin/bash,没有空格，不带任何选项。 6.第二行为空格，或者是添加一行注释。 7.第三行开始注释内容：文件名、功能描述、作者、最后修改日期、版本号、以及一些说明、还加上邮箱等联系方式、如果可以，需要加上版权声明。1234567891011脚本示例 #!/bin/bash #调用语言 # # Filename: test.sh # Description: this is Description # Author： leessangz # Email: leessangz@gmail.com # Revision: 0.1 # Date: 2017-07-01 # Note: test # 8.注释内容之后空一行开始定义shell脚本中的变量。 9.脚本内的变量定义，尽量使用大写，或者每个单词的首字母大写的驼峰原则，或者使用下划线连接的方式，变量名要见名知意，避免a，b，c，类似的定义，变量定义前后不要用空格。1234脚本示例 YUM_CMD=&quot;/usr/bin/yum&quot; YUMCMD=&quot;/usr/bin/yum&quot; Yum_Cmd=&quot;/usr/bin/yum&quot; 如果是整形，需要使用declare -i来声明。 如果是数组，则需要使用declare -a来声明。 如果是只读变量，则需要使用declare -r来声明。 变量值尽量使用双引号引起来，如果要使用强引用，如变量值中包含$符号，则使用&apos;&apos;单引号引起来。 ShiLi=&apos;shili$shili&apos; 如果要将命令的执行结果赋值给变量，则使用反引号，或者$() ScriptDir=$(cd $(dirname $0) &amp;&amp; pwd) ScriptDir=`pwd` 变量的引用使用以下方法： ${ShiLi} $ShiLi 推荐使用第一种，如：tar zcf ${ShiLi}.tar.gz /apps/data/ 11.单引号和双引号混合使用的场景： echo ‘Welcome to “my school”‘ 12.在某些特殊的环境下，shell脚本里引用的命令，有可能是自己定义的bin路径，在执行的时候会报出command not found， 解决的方式是在执行的时候命令跟全路径，或者在脚本的开始，先设置一下PATH变量 如： export PATH=”/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/apps/bin/“ 13.建议在脚本执行的开始重读下/etc/profile 或者是自己定义的关于环境变量的配置文件，推荐使用source， 如： source /etc/profile source /opt/sh/appenv.sh 14.使用here document； 如果脚本在执行的时候需要大段输出提示信息，可以使用以下方式： cat &lt;&lt; EOF This scripts used for XXX Usage:$0 [option] Pls be careful. Enjoy Yourself. EOF 如果只是单行提示信息，可以使用echo的方式添加颜色： echo &quot;Welcome to use my script&quot; 15.如果需要在脚本里生成配置文件的模板，也可以使用here document的方式，示例如下：12345678910111213141516示例脚本： cat&gt;&gt;/etc/rsyncd.conf&lt;&lt;EOF log file = /usr/local/logs/rsyncd.log transfer logging = yes log format = %t %a %m %f %b syslog facility = local3 timeout = 300 [data1] path=/home/username list=yes ignore errors auth users = data1user secrets file=/etc/rsyncd/rsyncd.secrets comment = some description about this moudle exclude = test1/ test2/ EOF 16.如果需要创建历史文件，可以使用以下方法： mktemp -d /tmp/file$$ 17.条件测试时尽量使用[[]],而不用[]或者test，因为[[]]功能会更强大。 [[ -d /tmp/logs ]] 不在使用[ “x$NAME” == “x” ]这种方式； 18.算数运算使用(())或者是中括号，但是记得括号里面的变量不要在加$ ((12+i)) 而非((12+$i)) 19.使用高级变量的方法，比如使用 ${ShiLi:?”Error Message”}确保关键变量已经定义 ${ShiLi:=”S1”} 或者设置默认值 否则： rm -rf ${ShiLi}/* 后果不堪设想 20.可以使用&amp;&amp; ||来替代简单的if-then-else-fi语句。 21.尽量给每条语句或者代码段的执行给一个执行结果状态，如果某条命令执行失败，则exit N.尽可能使用$?来检查前面一条命令的执行状态。 22.流程控制语句尽量使用一下方式：1234567891011for I in &#123;1..10&#125;;do ...donewhile true;do ...doneif [];then ...fi 23.如果命令过长，可以分成多行来写，比如：12345678./configure \--prefix=/usr \--sbin-path=/usr/sbin/nginx \--conf-path=/etc/nginx/nginx.conf \--error-log-path=/var/log/nginx/error.log \--http-log-path=/var/log/nginx/access.log \--pid-path=/var/run/nginx/nginx.pid \--lock-path=/var/lock/nginx.lock \ 24.shell脚本并不要求强制缩进，但是要养成缩进的好习惯，可以使用两个空格，建议使用tab键。如： if [];then …24. fi 25.尽可能多的注释信息。 26.想要获取当前脚本所在目录，可以使用 ScriptDir=$(cd $(dirname $0) &amp;&amp; pwd) 27.尽可能使用函数的功能，将不同的功能定义为函数，直接引用函数； 28.如果自定义环境变量，可以专门写到一个文件中，避免在/etc/profile中添加； 29.禁止使用SUID和SGID以及ACL用户访问控制列表的功能，如果需要较高权限，可以使用sudo。 30.关键的操作须有日志输出，专门记录操作的成功或者失败以及执行的时间点。 31.脚本内可能包含敏感信息，比如服务器密码或者数据库密码，如果公开之前请先确认敏感信息是否已经被删除。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--mv]]></title>
      <url>%2F2017%2F04%2F14%2Fevery-day-linux-command7-mv%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–mv文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 mv命令是move的缩写，可以用来移动文件或者将文件改名（move (rename) files），是Linux系统下常用的命令，经常用来备份文件或者目录。 1．命令格式：mv [选项] 源文件或目录 目标文件或目录 2．命令功能：视mv命令中第二个参数类型的不同（是目标文件还是目标目录），mv命令将文件重命名或 将其移至一个新的目录中。当第二个参数类型是文件时，mv命令完成文件重命名，此时， 源文件只能有一个（也可以是源目录名），它将所给的源文件或目录重命名为给定的目标 文件名。当第二个参数是已存在的目录名称时，源文件或目录参数可以有多个，mv命令将 各参数指定的源文件均移至目标目录中。在跨文件系统移动文件时，mv先拷贝，再将原有 文件删除，而链至该文件的链接也将丢失。 3．命令参数：-b ：若需覆盖文件，则覆盖前先行备份。 -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖； -i ：若目标文件 (destination) 已经存在时，就会询问是否覆盖！ -u ：若目标文件已经存在，且 source 比较新，才会更新(update) -t ： --target-directory=DIRECTORY move all SOURCE arguments into DIRECTORY， 即指定mv的目标目录，该选项适用于移动多个源文件到一个目录的情k况，此时目标目录在前，源文件在后。 4．命令实例：实例一：文件改名 命令： mv test.log test1.txt 输出：12345678910111213141516171819202122232425[root@localhost test]# ll总计 20drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5-rw-r--r-- 1 root root 16 10-28 06:04 test.log[root@localhost test]# mv test.log test1.txt[root@localhost test]# ll总计 20drwxr-xr-x 6 root root 4096 10-27 01:58 scf-rw-r--r-- 1 root root 16 10-28 06:04 test1.txtdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5 说明： 将文件test.log重命名为test1.txt 实例二：移动文件 命令： mv test1.txt test3 输出：123456789101112131415161718192021222324252627282930313233[root@localhost test]# ll总计 20drwxr-xr-x 6 root root 4096 10-27 01:58 scf-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# mv test1.txt test3[root@localhost test]# ll总计 16drwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 2 root root 4096 10-28 06:09 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# cd test3[root@localhost test3]# ll总计 4-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt[root@localhost test3]# 说明： 将test1.txt文件移到目录test3中 实例三：将文件log1.txt,log2.txt,log3.txt移动到目录test3中。 命令： mv log1.txt log2.txt log3.txt test3 mv -t /opt/soft/test/test4/ log1.txt log2.txt log3.txt 输出：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465[root@localhost test]# ll总计 28-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txtdrwxrwxrwx 2 root root 4096 10-28 06:09 test3[root@localhost test]# mv log1.txt log2.txt log3.txt test3[root@localhost test]# ll总计 16drwxrwxrwx 2 root root 4096 10-28 06:18 test3[root@localhost test]# cd test3/[root@localhost test3]# ll总计 16-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt[root@localhost test3]#[root@localhost test3]# ll总计 20-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txtdrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt[root@localhost test3]# mv -t /opt/soft/test/test4/ log1.txt log2.txt log3.txt [root@localhost test3]# cd ..[root@localhost test]# cd test4/[root@localhost test4]# ll总计 12-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt[root@localhost test4]# 说明： mv log1.txt log2.txt log3.txt test3 命令将log1.txt ，log2.txt， log3.txt 三个文件移到 test3目录中去，mv -t /opt/soft/test/test4/ log1.txt log2.txt log3.txt 命令又将三个文件移动到test4目录中去 实例四：将文件file1改名为file2，如果file2已经存在，则询问是否覆盖 命令： mv -i log1.txt log2.txt 输出：123456789101112131415161718192021222324252627[root@localhost test4]# ll总计 12-rw-r--r-- 1 root root 8 10-28 06:15 log1.txt-rw-r--r-- 1 root root 12 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt[root@localhost test4]# cat log1.txt odfdfs[root@localhost test4]# cat log2.txt ererwerwer[root@localhost test4]# mv -i log1.txt log2.txt mv：是否覆盖“log2.txt”? y[root@localhost test4]# cat log2.txt odfdfs[root@localhost test4]# 实例五：将文件file1改名为file2，即使file2存在，也是直接覆盖掉。 命令： mv -f log3.txt log2.txt 输出：123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@localhost test4]# ll总计 8-rw-r--r-- 1 root root 8 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt[root@localhost test4]# cat log2.txt odfdfs[root@localhost test4]# cat log3cat: log3: 没有那个文件或目录[root@localhost test4]# ll总计 8-rw-r--r-- 1 root root 8 10-28 06:15 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log3.txt[root@localhost test4]# cat log2.txt odfdfs[root@localhost test4]# cat log3.txt dfosdfsdfdss[root@localhost test4]# mv -f log3.txt log2.txt [root@localhost test4]# cat log2.txt dfosdfsdfdss[root@localhost test4]# ll总计 4-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt[root@localhost test4]# 说明： log3.txt的内容直接覆盖了log2.txt内容，-f 这是个危险的选项，使用的时候一定要保持头脑清晰，一般情况下最好不用加上它。 实例六：目录的移动 命令： mv dir1 dir2 输出：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051[root@localhost test4]# ll-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt[root@localhost test4]# ll-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt[root@localhost test4]# cd ..[root@localhost test]# lldrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 3 root root 4096 10-28 06:24 test3drwxr-xr-x 2 root root 4096 10-28 06:48 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# cd test3[root@localhost test3]# lldrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txt[root@localhost test3]# cd ..[root@localhost test]# mv test4 test3[root@localhost test]# lldrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 4 root root 4096 10-28 06:54 test3drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# cd test3/[root@localhost test3]# lldrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-28 06:48 test4[root@localhost test3]# 说明： 如果目录dir2不存在，将目录dir1改名为dir2；否则，将dir1移动到dir2中。 实例7：移动当前文件夹下的所有文件到上一级目录 命令： mv * ../ 输出：1234567891011121314151617181920212223[root@localhost test4]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt[root@localhost test4]# mv * ../[root@localhost test4]# ll[root@localhost test4]# cd ..[root@localhost test3]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txtdrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-28 07:02 test4 实例八：把当前目录的一个子目录里的文件移动到另一个子目录里 命令： mv test3/*.txt test5 输出：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@localhost test]# lldrwxr-xr-x 6 root root 4096 10-27 01:58 scfdrwxrwxrwx 4 root root 4096 10-28 07:02 test3drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# cd test3[root@localhost test3]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txtdrwxr-xr-x 2 root root 4096 10-28 06:21 logs-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-28 07:02 test4[root@localhost test3]# cd ..[root@localhost test]# mv test3/*.txt test5[root@localhost test]# cd test5[root@localhost test5]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-25 17:56 test5-1[root@localhost test5]# cd ..[root@localhost test]# cd test3/[root@localhost test3]# lldrwxr-xr-x 2 root root 4096 10-28 06:21 logsdrwxr-xr-x 2 root root 4096 10-28 07:02 test4[root@localhost test3]# 实例九：文件被覆盖前做简单备份，前面加参数-b 命令： mv log1.txt -b log2.txt 输出：12345678910111213141516171819202122232425[root@localhost test5]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log1.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-25 17:56 test5-1[root@localhost test5]# mv log1.txt -b log2.txtmv：是否覆盖“log2.txt”? y[root@localhost test5]# ll-rw-r--r-- 1 root root 25 10-28 07:02 log2.txt-rw-r--r-- 1 root root 13 10-28 06:16 log2.txt~-rw-r--r-- 1 root root 29 10-28 06:05 test1.txtdrwxr-xr-x 2 root root 4096 10-25 17:56 test5-1[root@localhost test5]# 说明： -b 不接受参数，mv会去读取环境变量VERSION_CONTROL来作为备份策略。 --backup该选项指定如果目标文件存在时的动作，共有四种备份策略： 1.CONTROL=none或off : 不备份。 2.CONTROL=numbered或t：数字编号的备份 3.CONTROL=existing或nil：如果存在以数字编号的备份，则继续编号备份m+1...n： 执行mv操作前已存在以数字编号的文件log2.txt.~1~，那么再次执行将产生log2.txt~2~， 以次类推。如果之前没有以数字编号的文件，则使用下面讲到的简单备份。 4.CONTROL=simple或never：使用简单备份：在被覆盖前进行了简单备份，简单备份只能 有一份，再次被覆盖时，简单备份也会被覆盖。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--rmdir]]></title>
      <url>%2F2017%2F04%2F13%2Fevery-day-linux-command6-rmdir%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–rmdir文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 今天学习一下linux中命令： rmdir命令。rmdir是常用的命令，该命令的功能是删除空目录，一个目录被删除之前必须是空的。（注意，rm - r dir命令可代替rmdir，但是有很大危险性。）删除某目录时也必须具有对父目录的写权限。 1．命令格式：rmdir [选项]... 目录... 2．命令功能：该命令从一个目录中删除一个或多个子目录项，删除某目录时也必须具有对父目录的写权限。 3．命令参数：-p 递归删除目录dirname，当子目录删除后其父目录为空时，也一同被删除。 如果整个路径被删除或者由于某种原因保留部分路径，则系统在标准输出上显示相应的信息。 -v, --verbose 显示指令执行过程 4．命令实例：实例一：rmdir 不能删除非空目录 命令： rmdir doc 输出：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667[root@localhost scf]# tree.|-- bin|-- doc| |-- info| `-- product|-- lib|-- logs| |-- info| `-- product`-- service `-- deploy |-- info `-- product 12 directories, 0 files[root@localhost scf]# rmdir docrmdir: doc: 目录非空[root@localhost scf]# rmdir doc/info[root@localhost scf]# rmdir doc/product[root@localhost scf]# tree.|-- bin|-- doc|-- lib|-- logs| |-- info| `-- product`-- service `-- deploy |-- info `-- product 10 directories, 0 files 说明： rmdir 目录名 命令不能直接删除非空目录 实例2：rmdir -p 当子目录被删除后使它也成为空目录的话，则顺便一并删除 命令： rmdir -p logs 输出：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879[root@localhost scf]# tree.|-- bin|-- doc|-- lib|-- logs| `-- product`-- service `-- deploy |-- info `-- product 10 directories, 0 files[root@localhost scf]# rmdir -p logsrmdir: logs: 目录非空[root@localhost scf]# tree.|-- bin|-- doc|-- lib|-- logs| `-- product`-- service `-- deploy |-- info `-- product 9 directories, 0 files[root@localhost scf]# rmdir -p logs/product[root@localhost scf]# tree.|-- bin|-- doc|-- lib`-- service`-- deploy |-- info `-- product 7 directories, 0 files]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--rm]]></title>
      <url>%2F2017%2F04%2F12%2Fevery-day-linux-command5-rm%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–rm文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 昨天学习了创建文件和目录的命令mkdir ，今天学习一下linux中删除文件和目录的命令： rm命令。rm是常用的命令，该命令的功能为删除一个目录中的一个或多个文件或目录，它也可以将某个目录及其下的所有文件及子目录均删除。对于链接文件，只是删除了链接，原有文件均保持不变。 rm是一个危险的命令，使用的时候要特别当心，尤其对于新手，否则整个系统就会毁在这个命令（比如在/（根目录）下执行rm * -rf）。所以，我们在执行rm之前最好先确认一下在哪个目录，到底要删除什么东西，操作时保持高度清醒的头脑。 1．命令格式：rm [选项] 文件… 2．命令功能：删除一个目录中的一个或多个文件或目录，如果没有使用- r选项，则rm不会删除目录。 如果使用 rm 来删除文件，通常仍可以将该文件恢复原状。 3．命令参数：-f, --force 忽略不存在的文件，从不给出提示。 -i, --interactive 进行交互式删除 -r, -R, --recursive 指示rm将参数中列出的全部目录和子目录均递归地删除。 -v, --verbose 详细显示进行的步骤 --help 显示此帮助信息并退出 --version 输出版本信息并退出 4．命令实例：实例一：删除文件file，系统会先询问是否删除。 命令： rm 文件名 输出：12345678910111213[root@localhost test1]# ll总计 4-rw-r--r-- 1 root root 56 10-26 14:31 log.logroot@localhost test1]# rm log.log rm：是否删除 一般文件 “log.log”? yroot@localhost test1]# ll总计 0[root@localhost test1]# 说明： 输入rm log.log命令后，系统会询问是否删除，输入y后就会删除文件，不想删除则数据n。 实例二：强行删除file，系统不再提示。 命令： rm -f log1.log 输出：1234567891011[root@localhost test1]# ll总计 4-rw-r--r-- 1 root root 23 10-26 14:40 log1.log[root@localhost test1]# rm -f log1.log [root@localhost test1]# ll总计 0[root@localhost test1]# 实例三：删除任何.log文件；删除前逐一询问确认 命令： rm -i *.log 输出：1234567891011121314151617[root@localhost test1]# ll总计 8-rw-r--r-- 1 root root 11 10-26 14:45 log1.log-rw-r--r-- 1 root root 24 10-26 14:45 log2.log[root@localhost test1]# rm -i *.logrm：是否删除 一般文件 “log1.log”? yrm：是否删除 一般文件 “log2.log”? y[root@localhost test1]# ll总计 0[root@localhost test1]# 实例四：将 test1子目录及子目录中所有档案删除 命令： rm -r test1 输出：1234567891011121314151617181920212223242526272829303132333435[root@localhost test]# ll总计 24drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxr-xr-x 2 root root 4096 10-26 14:51 test1drwxr-xr-x 3 root root 4096 10-25 17:44 test2drwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# rm -r test1rm：是否进入目录 “test1”? yrm：是否删除 一般文件 “test1/log3.log”? yrm：是否删除 目录 “test1”? y[root@localhost test]# ll总计 20drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxr-xr-x 3 root root 4096 10-25 17:44 test2drwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# 实例五：rm -rf test2命令会将 test2 子目录及子目录中所有档案删除,并且不用一一确认 命令： rm -rf test2 输出：12345678910111213[root@localhost test]# rm -rf test2[root@localhost test]# ll总计 16drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# 实例六：删除以 -f 开头的文件 命令： rm -- -f 输出：12345678910111213141516171819202122232425[root@localhost test]# touch -- -f[root@localhost test]# ls -- -f-f[root@localhost test]# rm -- -frm：是否删除 一般空文件 “-f”? y[root@localhost test]# ls -- -fls: -f: 没有那个文件或目录[root@localhost test]#也可以使用下面的操作步骤:[root@localhost test]# touch ./-f[root@localhost test]# ls ./-f./-f[root@localhost test]# rm ./-frm：是否删除 一般空文件 “./-f”? y[root@localhost test]# 实例七：自定义回收站功能 命令： myrm(){ D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D; mv &quot;$@&quot; $D &amp;&amp; echo &quot;moved to $D ok&quot;; } 输出：12345678910111213141516171819202122232425262728293031323334353637383940414243[root@localhost test]# myrm()&#123; D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p $D; mv &quot;$@&quot; $D &amp;&amp; echo &quot;moved to $D ok&quot;; &#125;[root@localhost test]# alias rm=&apos;myrm&apos;[root@localhost test]# touch 1.log 2.log 3.log[root@localhost test]# ll总计 16-rw-r--r-- 1 root root 0 10-26 15:08 1.log-rw-r--r-- 1 root root 0 10-26 15:08 2.log-rw-r--r-- 1 root root 0 10-26 15:08 3.logdrwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# rm [123].logmoved to /tmp/20121026150901 ok[root@localhost test]# ll总计 16drwxr-xr-x 7 root root 4096 10-25 18:07 scfdrwxrwxrwx 2 root root 4096 10-25 17:46 test3drwxr-xr-x 2 root root 4096 10-25 17:56 test4drwxr-xr-x 3 root root 4096 10-25 17:56 test5[root@localhost test]# ls /tmp/20121026150901/1.log 2.log 3.log[root@localhost test]# 说明： 上面的操作过程模拟了回收站的效果，即删除文件的时候只是把文件放到一个临时目录中， 这样在需要的时候还可以恢复过来。 参考资料： http://codingstandards.iteye.com/blog/983531]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--mkdir]]></title>
      <url>%2F2017%2F04%2F11%2Fevery-day-linux-command4-mkdir%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–mkdir文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 linux mkdir 命令用来创建指定的名称的目录，要求创建目录的用户在当前目录中具有写权限，并且指定的目录名不能是当前目录中已有的目录。 1．命令格式：mkdir [选项] 目录... 2．命令功能：通过 mkdir 命令可以实现在指定位置创建以 DirName(指定的文件名)命名的文件夹或目录。要创建文件夹或目录的用户必须对所创建的文件夹的父文件夹具有写权限。并且，所创建的文件夹(目录)不能与其父目录(即父文件夹)中的文件名重名，即同一个目录下不能有同名的(区分大小写)。 3．命令参数：-m, --mode=模式，设定权限&lt;模式&gt; (类似 chmod)，而不是 rwxrwxrwx 减 umask -p, --parents 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后, 系统将自动建立好那些尚不存在的目录,即一次可以建立多个目录; -v, --verbose 每次创建新目录都显示信息 --help 显示此帮助信息并退出 --version 输出版本信息并退出 4．命令实例：实例1：创建一个空目录 命令： mkdir test1 输出：123456789[root@localhost soft]# cd test[root@localhost test]# mkdir test1[root@localhost test]# ll总计 4drwxr-xr-x 2 root root 4096 10-25 17:42 test1[root@localhost test]# 实例2：递归创建多个目录 命令： mkdir -p test2/test22 输出：123456789101112131415[root@localhost test]# mkdir -p test2/test22[root@localhost test]# ll总计 8drwxr-xr-x 2 root root 4096 10-25 17:42 test1drwxr-xr-x 3 root root 4096 10-25 17:44 test2[root@localhost test]# cd test2/[root@localhost test2]# ll总计 4drwxr-xr-x 2 root root 4096 10-25 17:44 test22[root@localhost test2]# 实例3：创建权限为777的目录 命令： mkdir -m 777 test3 输出：1234567891011[root@localhost test]# mkdir -m 777 test3[root@localhost test]# ll总计 12drwxr-xr-x 2 root root 4096 10-25 17:42 test1drwxr-xr-x 3 root root 4096 10-25 17:44 test2drwxrwxrwx 2 root root 4096 10-25 17:46 test3[root@localhost test]# 说明： test3 的权限为rwxrwxrwx 实例4：创建新目录都显示信息 命令： mkdir -v test4 输出：1234567891011[root@localhost test]# mkdir -v test4mkdir: 已创建目录 “test4”[root@localhost test]# mkdir -vp test5/test5-1mkdir: 已创建目录 “test5”mkdir: 已创建目录 “test5/test5-1”[root@localhost test]# 实例五：一个命令创建项目的目录结构 参考：http://www.ibm.com/developerworks/cn/aix/library/au-badunixhabits.html 命令： mkdir -vp scf/{lib/,bin/,doc/{info,product},logs/{info,product},service/deploy/{info,product}} 输出：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@localhost test]# mkdir -vp scf/&#123;lib/,bin/,doc/&#123;info,product&#125;,logs/&#123;info,product&#125;,service/deploy/&#123;info,product&#125;&#125;mkdir: 已创建目录 “scf”mkdir: 已创建目录 “scf/lib”mkdir: 已创建目录 “scf/bin”mkdir: 已创建目录 “scf/doc”mkdir: 已创建目录 “scf/doc/info”mkdir: 已创建目录 “scf/doc/product”mkdir: 已创建目录 “scf/logs”mkdir: 已创建目录 “scf/logs/info”mkdir: 已创建目录 “scf/logs/product”mkdir: 已创建目录 “scf/service”mkdir: 已创建目录 “scf/service/deploy”mkdir: 已创建目录 “scf/service/deploy/info”mkdir: 已创建目录 “scf/service/deploy/product”[root@localhost test]# tree scf/scf/|-- bin|-- doc| |-- info| `-- product|-- lib|-- logs| |-- info| `-- product`-- service `-- deploy |-- info `-- product12 directories, 0 files[root@localhost test]#]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--pwd]]></title>
      <url>%2F2017%2F04%2F10%2Fevery-day-linux-command3-pwd%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–pwd文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 Linux中用pwd命令来查看”当前工作目录“的完整路径。 简单得说，每当你在终端进行操作时，你都会有一个当前工作目录。 在不太确定当前位置时，就会使用pwd来判定当前目录在文件系统内的确切位置。 1. 命令格式：pwd [选项] 2．命令功能：查看”当前工作目录“的完整路径 3．常用参数：一般情况下不带任何参数 如果目录是链接时： 格式：pwd -P 显示出实际路径，而非使用连接（link）路径。 4．常用实例：实例1：用 pwd 命令查看默认工作目录的完整路径 命令： pwd 输出：12345[root@localhost ~]# pwd/root[root@localhost ~]# 实例2：使用 pwd 命令查看指定文件夹 命令： pwd 输出：1234567[root@localhost ~]# cd /opt/soft/[root@localhost soft]# pwd /opt/soft[root@localhost soft]# 实例三：目录连接链接时，pwd -P 显示出实际路径，而非使用连接（link）路径；pwd显示的是连接路径 命令： pwd -P 输出：1234567891011[root@localhost soft]# cd /etc/init.d [root@localhost init.d]# pwd/etc/init.d[root@localhost init.d]# pwd -P/etc/rc.d/init.d[root@localhost init.d]# 实例4：/bin/pwd 命令： /bin/pwd [选项] 选项： -L 目录连接链接时，输出连接路径 -P 输出物理路径 输出：123456789101112131415[root@localhost init.d]# /bin/pwd /etc/rc.d/init.d[root@localhost init.d]# /bin/pwd --help[root@localhost init.d]# /bin/pwd -P/etc/rc.d/init.d[root@localhost init.d]# /bin/pwd -L/etc/init.d[root@localhost init.d]# 实例五：当前目录被删除了，而pwd命令仍然显示那个目录 输出：123456789101112131415161718192021222324252627[root@localhost init.d]# cd /opt/soft[root@localhost soft]# mkdir removed[root@localhost soft]# cd removed/[root@localhost removed]# pwd/opt/soft/removed[root@localhost removed]# rm ../removed -rf[root@localhost removed]# pwd/opt/soft/removed[root@localhost removed]# /bin/pwd/bin/pwd: couldn&apos;t find directory entry in “..” with matching i-node[root@localhost removed]# cd [root@localhost ~]# pwd/root[root@localhost ~]#]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[vim编辑器一]]></title>
      <url>%2F2017%2F04%2F09%2Fvim-1%2F</url>
      <content type="text"><![CDATA[vim文本编辑器vi与vim vi编辑器是所有Unix及Linux系统下标准的编辑器，他就相当于windows系统中的记事本一样，它的强大不逊色于任何最新的文本编辑器。他是我们使用Linux系统不能缺少的工具。由于对Unix及Linux系统的任何版本，vi编辑器是完全相同的，学会它后，您将在Linux的世界里畅行无阻。vim 具有程序编辑的能力，可以以字体颜色辨别语法的正确性，方便程序设计；因为程序简单，编辑速度相当快速。vim可以当作vi的升级版本，他可以用多种颜色的方式来显示一些特殊的信息。vim会依据文件扩展名或者是文件内的开头信息， 判断该文件的内容而自动的执行该程序的语法判断式，再以颜色来显示程序代码与一般信息。vim里面加入了很多额外的功能，例如支持正则表达式的搜索、多文件编辑、块复制等等。 这对于我们在Linux上进行一些配置文件的修改工作时是很棒的功能。 为何要学 vi所有的Unix Like系统都会内建vi文本编辑器，其他的文本编辑器则不一定会存在；一些软件的编辑接口会主动调用vi (例如 crontab, visudo, edquota 等命令)； vi的使用基本上vi可以分为三种状态，分别是一般模式、编辑模式和命令行模式， 各模式的功能区分如下： 一般模式： 以vi打开一个文件就直接进入一般模式了(这是默认的模式)。在这个模式中， 你可以使用上下左右按键来 移动光标，你可以使用删除字符或删除整行来处理文件内容， 也可以使用复制、粘贴来处理你的文件数据。 编辑模式： 在一般模式中可以进行删除、复制、粘贴等的操作，但是却无法编辑文件的内容，只有当到你按下 【i, I, o, O, a, A, r, R】等任何一个字母之后才会进入编辑模式。这时候屏幕的左下方会出现 【INSERT或 REPLACE】的字样，此时才可以进行编辑。而如果要回到一般模式时， 则必须要按下【Esc】 即可退出编辑模式。 命令行模式： 输入【 : / ? 】三个中的任何一个，就可以将光标移动到最底下那一行。在这个模式中， 可以提供查找、读取、存盘、替换字符、离开vi、显示行号等的动作则是在此模式中完成的！ 一般模式可用的按钮说明移动光标 【h、j、k、l】，分别控制光标左、下、上、右移一格 按【ctrl+b】屏幕往&quot;后&quot;移动一页 按【ctrl+f】屏幕往&quot;前&quot;移动一页 【n&lt;space&gt;】光标向右移动n个字符 【Home】移动到这一行的最前面字符处:0数字，但不能用数字小键盘上的数字 【End】 移动到这一行的最后面字符处:$，我测试好像不行 【w】光标跳到下个字的开头 【e】光标跳到下个字的字尾 【H】 光标移动到这个屏幕的最上方那一行的第一个字符 【M】 光标移动到这个屏幕的中间那一行的第一个字符 【L】光标移动到这个屏幕的最下方那一行的第一个字符 【G】 移动到这个文件的最后一行 【nG】移动到这个文件的第n行(可配合:set nu) 【gg】 移动到这个文件的第一行，相当于1G 【n&lt;Enter&gt;】光标向下移动n行 查找与替换 【/word】 向光标向下寻找一个名称为word的字符串 【?word】 向光标向上寻找一个名称为word的字符串 【n】 代表重复前一个查找的动作 【N】 与n刚好相反，为【反向】进行行前一个查找动作 【:n1,n2s/word1/word2/g】 n1与n2为数字，在第n1与n2行之间查找 word1 这个字符串，并将该字符串替换为word2 【:1,$s/word1/word2/g】 从第一行到最后一行查找word1字符串，并将该字符串替换为word2 【:1,$s/word1/word2/gc】 从第一行到最后一行查找word1字符串，并将该字符串替换为word2 ， 且在替换前提示用户确认是否进行替换删除、复制与粘贴 【x】 为向后删除一个字符 (相当于【del】键) 【X】 为向前删除一个字符(相当于【backspace】键) 【nx】 连续向后删除n个字符 【dd】 删除光标所在行 【ndd】 删除光标所在的向下n行 【d1G】 删除光标所在行到第一行的所有数据 【dG】 删除光标所在到最后一行的所有数据 【d$】 删除光标所在处，到该行的最后一个字符 【d0】 删除光标所在处，到该行的最前一个字符 【yy】 复制光标所在的那一行 【nyy】 复制光标所在的向下n列 【y1G】 复制光标所在行到第一行的所有数据 【yG】 复制光标所在行到最后一行的所有数据 【y0】 复制光标所在的那个字符到该行行首的所有数据 【y$】 复制光标所在的那个字符到该行行尾的所有数据 【p】将已复制的数据在光标下一行粘贴上 【P】 则为贴在光标的上一行 【u】 恢复前一个操作 【Ctrl+r】重做上一个操作 【.】 是重复前一个操作 一般模式切换到编辑模式的可用的按钮说明 【i, I】 进入编辑模式： i 为【从目前光标所在处插入】 I 为【在目前所在行的第一个非空格符处开始插入】 【a, A】 进入编辑模式(Insert mode)： a 为【从目前光标所在的下一个字符处开始插入】 A 为【从光标所在行的最后一个字符处开始插入】 【o, O】 进入编辑模式： o 为【在目前光标所在的下一行处插入新的一行】 O 为在目前光标所在处的上一行插入新的一行 【r, R】 进入取代模式： r 只会取代光标所在的那一个字符一次 R会一直取代光标所在的文字，直到按下 ESC 为止； 【Esc】 退出编辑模式，回到一般模式 一般模式切换到命令行模式可用的按钮说明 【:w】 保存编辑的内容 【:w!】强制写入该文件，但跟你对该文件的权限有关 【:q】 离开vi 【:q!】 不想保存修改强制离开 【:wq】 保存后离开 【:x】 保存后离开 【ZZ】 若文件没有更动，则不保存离开，若文件已经被更改过，则保存后离开 【:w filename】 将编辑的数据保存成另一个文件（类似另存） 【:r filename】 在编辑的数据中，读入另一个文件的数据。即将【filename】 这个文件的内容加到光标所在 行后面。 【:n1,n2 w filename】 将n1到n2的内容保存成filename这个文件。 【:! command】暂时离开vi 到命令行模式下执行command的显示结果！ 例如 【:! ls /home】即可在 vi 当中察看/home底下以ls输出的文件信息！ 【:set nu】 显示行号 【:set nonu】 与 set nu 相反，为取消行 vim的功能 其实，目前大部分的Linux发行版本都以vim取代了vi。为什么要用vim呢？因为vim具有颜色显示的功能，并且还支持许多的程序语法(syntax)和相应的提示信息。查看自己的VI是不是被VIM代替，可以用alias这个命令来查看是不是有alias vi=’vim’这一行。 块选择 【v】字符选择，会将光标经过的地方反白选择 【V】 行选择，会将光标经过的行反白选择 【Ctrl+v】 块选择，可以用长方形的方式选择资料 （提制竖列） 【y】 将反白的地方复制 【d】 将反白的地方删除 多文件编辑 大家在使用vim的时候，可能会碰到你需要复制一个文件中的某段到另外一个文件中， 而vim不能够在关闭的时候，把这段保留住。或者是用其它的方法复制。 【vim file1 file2】 【:n】编辑下一个文件 【:N】编辑上一个文件 【:files】列出目前这个vim编辑的所有文件 多窗口功能 有两个需要对照着看的文件 【:sp filename】开启一个新窗口，如果有加 filename， 表示在新窗口开启一个新文件，否则表示两个窗口为 同一个文件内容(同步显示)。 【ctrl+w+j】 【ctrl+w+↓】按键的按法是：先按下 【ctrl】 不放， 再按下 w 后放开所有的按键，然后再按下 j (或向下箭头键)，则光标可移动到下方的窗口。 【ctrl+w+k】 【ctrl+w+↑】同上，不过光标移动到上面的窗口。 vim 环境设定与记录(~/.vimrc, ~/.viminfo) 如果我们以vim软件来查找一个文件内部的某个字符串时，这个字符串会被反白， 而下次我们再次以vim编辑这个文件时，该查找的字符串反白情况还是存在。另外，当我们重复编辑同一个文件时，当第二次进入该文件时， 光标竟然就在上次离开的那一行的开头。这个功能可能是方便，但也有不方便的时候。怎么会这样呢？这是因为我们的vim会主动的将你曾经做过的行为登录下来，那个记录动作的文件就是： ~/.viminfo，不想用这个功能，就直接删除~/.viminfo。只要你曾经使用过vim，那么你的家目录就会有这个文件。这个文件是自动产生的，你在vim里头所做过的动作，就可以在这个文件内部找到。有兴趣的朋友可以自己查看文件里面的内容。 不过，对于每个不同的发行版本对vim的预设环境都不太相同。举例来说，某些版本在查找到关键词时并不会高亮度反白， 有些版本则会主动的帮你进行缩排（所谓的缩排，就是当你按下 Enter 编辑新的一行时，光标不会在行首，而是在与上一行的第一个非空格符处对齐）的行为。其实这些都可以自行设定的，下面我们就来看看vim的环境设定。 vim的环境设定参数有很多，如果你想要知道目前的设定值，可以在一般模式时输入【 :set all】来查阅，由于设定项目实在太多了，我们在这里就仅列出一些平时比较常用的一些简单的设定值，给大家提供参考。 :set all &quot;显示目前所有的环境参数设定值 :set hlsearch &quot;高亮度反白(高亮度搜寻) :set nohlsearch &quot;取消高亮度反白(高亮度搜寻) :set backspace=2 &quot;在编辑的时候可随时用退格键删除 （０、１的时候，只针对刚输入的字符有效） :set autoindent &quot;自动缩排 :set noautoindent &quot;取消自动缩排 :set ruler &quot;可显示最后一行的状态 :set showmode &quot;左下角那一行的状态 :set nu &quot;显示行号 :set nonu &quot;取消行号 :set bg=dark &quot;显示不同的底色色调 :syntax on &quot;进行语法检验，颜色显示 :syntax off &quot;关闭语法检验 了解完上面的内容后，下面我们就能写一下自己的vim操作环境。整体vim的设定值一般是置在/etc/vimrc这个文件里面，不建议大家来修改他。我们在自己的家目录里面建立个.vimrc文件，在这里面写入自己的内容就能实现了。1234567891011[root@yufei ~]# vim ~/.vimrc内容如下set hlsearch &quot;高亮度反白set backspace=2 &quot;可随时用退格键删除set autoindent &quot;自动缩排set ruler &quot;可显示最后一行的状态set showmode &quot;左下角那一行的状态set nu &quot;可以在每一行的最前面显示行号set bg=dark &quot;显示不同的底色色调syntax on &quot;进行语法检验，颜色显示&quot;这个文件的双引号 (&quot;)表示的是注释 保存退出vim后，在下次使用vim的时候，就会有自己的vim操作环境了。提醒一点，这个文件中每一行前面加不加【:】效果都是一样的。 转自：http://blog.csdn.net/xiaolong2w/article/details/8224839]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[vim编辑器二]]></title>
      <url>%2F2017%2F04%2F09%2Fvim-2%2F</url>
      <content type="text"><![CDATA[vim 文本编辑器二linux vim编辑器必知必会一、我们为什么要学习vim编辑器？ Linux的命令行界面下面有非常多的文本编辑器。比如经常听说的就有Emacs、pico、nano、joe与vim等。vim可以看做是vi的高级版。我们为什么一定要学习vim呢？有以下几个原因： (1)所有的Unix like系统都会内置vi文本编辑器，其他的文本编辑器则不一定会存在。 (2)很多软件的编辑接口都会主动调用vi。 (3)vim具有程序编辑的能力，可以主动以字体颜色辨别语法的正确性，方便程序设计。 (4)程序简单，编辑速度快。 二、下面先介绍一下vi的基本使用方法及其相关命令。vim编辑器的三种模式：一般模式、编辑模式和命令行模式。 在一般模式中可以进行删除、复制和粘贴的功能，但是无法编辑文件内容。从一般模式切换到编辑模式可以按下i、I、o、O、a、A、r、R键。按下Esc键可以回到一般模式。在一般模式中输入：、/、？三个中的任意一个可以将光标移到最下面的一行。在这个模式中可以提供查找数据的操作，而读取、保存、大量替换字符、离开vii、显示行号等操作则是在此模式中完成的。需要注意的是，编辑模式与命令行模式之间是不能互相切换的。 下面列出平时用的最多的vi命令： 移动光标的方法： [Ctrl]+[f]：屏幕向下移动一页，相当于[PageDown]按键。 [Ctrl]+[b]：屏幕向上移动一页，相当于[PageUp]按键。 0或功能键[Home]：移动到这一行的最前面字符处。 $或功能键[End]：移动到这一行的最后面字符处。 G：移动到这个文件的最后一行。 gg：移动到这个文件的第一行，相当于1G. N[Enter]：N为数字，光标向下移动N行。 查找和替换： /word：向下寻找一个名称为word的字符串。 ?word：向上寻找一个名称为word的字符串。 :n1,n2s/word1/word2/g：在第n1行和n2行之间寻找word1这个字符串，并且将其替换为word2. :1,$s/word1/word2/g：从第一行到最后一行寻找word1这个字符串，并且将其替换为word2. :1,$s/word1/word2/gc：从第一行到最后一行寻找word1这个字符串，并且将其替换为word2. 且在替换前显示提示字符给用户确认是否需要替换。 删除、复制和粘贴： x,X：在一行字中，x为向后删除一个字符（相当于[Del]键），X为向前删除一个字符（相当于[Backspace]）。 dd：删除光标所在的一整行。 ndd：删除光标所在的向下n行。 yy：复制光标所在的一行。 nyy：复制光标所在的向下n行。 p,P：p为将已复制的内容在光标的下一行粘贴，P则为粘贴在光标的上一行。 u：复原前一个操作。 [Ctrl]+r：重做上一个操作。 .：小数点，重复前一个操作。 一般模式切换到编辑模式： i,I：进入插入模式，i为从目前光标所在处插入。I为在目前所在行的第一个非空格字符处开始插入。 a，A：进入插入模式。a为从目前光标所在处的下一个字符处开始插入。A为从所在行的最后一个字符处开始插入。 o，O：进入插入模式。o为在下一行插入。O为在上一行插入。 r，R：进入替换模式。r只替换光标所在那个字符一次。R会一直替换光标所在字符，直到按下Esc键。 一般模式切换到命令行： :w：将编辑的数据写入到硬盘中。 :q：离开vi.后面加！为强制离开。 :wq：保存后离开。:wq!为强制保存后离开。 目前主要的编辑器都有恢复功能，vim也不例外。vim是通过“保存”文件来挽回数据的。 每当我们在用vim编辑时，vim都会自动在被编辑的文件的目录下面再新建一个名为filename.swap的文件。这就是一个暂存文件，我们对文件filename所做的操作都会被记录到这个文件当中。如果系统意外崩溃，导致文件没有正常保存，那么这个暂存文件就会发挥作用。下面用一个例子来说明(Note：我用的是Ubuntu)。1234567打开终端，输入命令，将etc目录下面的manpath.config复制到tmp目录下面，并且更改当前工作目录为tmp：cp /etc/manpath.config /tmpcd /tmp用vim编辑manpath.config文件：vim manpath.config。 我们在vim的一般模式下按下Ctrl+z组合键，vim就会被丢到后台执行。回到命令提示符环境后，我们模拟将vim的工作不正常中断。 kill -9 %1;强制杀死制定的进程。 这样导致暂存盘无法通过正常的流程结束，所以暂存文件不会消失，而是继续保留下来。当再次编辑那个文件时(输入命令vim manpath.config)，出现(ubuntu 11.10)： 这时，有六个按钮可以使用： O(pen for Read-Only):打开成只读文件。 E(dit):用正常方式打开要编辑的文件，并不会载入暂存文件的内容。这很容易出现两个用户相互改变对方的文件 的问题。 R(ecover)：加载暂存文件的内容。 D(elete)：如果你确定这个暂存文件是没有用的，则可以删除。 Q(uit)：不进行任何操作，回到命令行。 A(bort)：忽略这个编辑行为，和Q类似。 需要注意的是：这个暂存文件不会应为你结束vim后自动删除，必须要手动删除。否则每次打开对应的文件时都会出现这样的提示。 转自：http://blog.csdn.net/xiaolong2w/article/details/8224839]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--cd]]></title>
      <url>%2F2017%2F04%2F09%2Fevery-day-linux-command2.cd%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–cd文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 cd命令可以说是Linux中最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。 所以，学习Linux 常用命令，首先就要学好 cd 命令的使用方法技巧。 1. 命令格式：cd [目录名] 2. 命令功能：切换当前目录至dirName 3. 常用范例：3.1 例一：进入系统根目录 命令： cd / 输出：1[root@localhost ~]# cd / 说明：进入系统根目录,上面命令执行完后拿ls命令看一下，当前目录已经到系统根目录了 命令： cd .. 或者 cd .. // 输出:123456[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd ..[root@localhost opt]# cd ..//[root@localhost /]# pwd/ 说明： 进入系统根目录可以使用“ cd .. ”一直退，就可以到达根目录 命令： cd ../.. // 输出：123456[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd ../.. //[root@localhost /]# pwd/[root@localhost /]# 说明：使用cd 命令实现进入当前目录的父目录的父目录。 例2：使用 cd 命令进入当前用户主目录 “当前用户主目录”和“系统根目录”是两个不同的概念。进入当前用户主目录有两个方法。 命令1： cd 输出：12345[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd[root@localhost ~]# pwd/root 命令2： cd ~ 输出：123456[root@localhost ~]# cd /opt/soft/[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd ~[root@localhost ~]# pwd/root 例3：跳转到指定目录 命令： cd /opt/soft 输出：1234567[root@localhost ~]# cd /opt/soft[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd jdk1.6.0_16/[root@localhost jdk1.6.0_16]# pwd/opt/soft/jdk1.6.0_16[root@localhost jdk1.6.0_16]# 说明： 跳转到指定目录，从根目录开始，目录名称前加 / ,当前目录内的子目录直接写名称即可 例四：返回进入此目录之前所在的目录 命令： cd - 输出： 123456789[root@localhost soft]# pwd/opt/soft[root@localhost soft]# cd -/root[root@localhost ~]# pwd/root[root@localhost ~]# cd -/opt/soft[root@localhost soft]# 例五：把上个命令的参数作为cd参数使用。 命令： cd !$ 输出： 1234567[root@localhost soft]# cd !$cd -/root[root@localhost ~]# cd !$cd -/opt/soft[root@localhost soft]#]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[每天一个linux命令--ls]]></title>
      <url>%2F2017%2F04%2F08%2Fevery-day-linux-command1.ls%2F</url>
      <content type="text"><![CDATA[每天一个linux命令–ls文章转载自博客园，作者peida。本文仅作为自用参考，请勿转载。 ls命令是linux下最常用的命令。ls命令就是list的缩写缺省下ls用来打印出当前目录的清单,如果ls指定其他目录,那么就会显示指定目录里的文件及文件夹清单。 通过ls 命令不仅可以查看linux文件夹包含的文件而且可以查看文件权限(包括目录、文件夹、文件权限),查看目录信息等等。ls 命令在日常的linux操作中用的很多! 1. 命令格式：ls [选项] [目录名] 2. 命令功能：列出目标目录中所有的子目录和文件。 3. 常用参数：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788-a –all 列出目录下的所有文件，包括以 . 开头的隐含文件 -A 同-a，但不列出“.”(表示当前目录)和“..”(表示当前目录的父目录)。 -c 配合 -lt：根据 ctime 排序及显示 ctime (文件状态最后更改的时间) 配合 -l：显示 ctime 但根据名称排序否则：根据 ctime 排序 -C 每栏由上至下列出项目 –color[=WHEN] 控制是否使用色彩分辨文件。WHEN 可以是&apos;never&apos;&apos;always&apos;或&apos;auto&apos;其中之一 -d –directory 将目录象文件一样显示，而不是显示其下的文件。 -D –dired 产生适合 Emacs 的 dired 模式使用的结果 -f 对输出的文件不进行排序，-aU 选项生效，-lst 选项失效 -g 类似 -l,但不列出所有者 -G –no-group 不列出任何有关组的信息 -h –human-readable 以容易理解的格式列出文件大小 (例如 1K 234M 2G) –si 类似 -h,但文件大小取 1000 的次方而不是 1024 -H –dereference-command-line 使用命令列中的符号链接指示的真正目的地 –indicator-style=方式 指定在每个项目名称后加上指示符号 &lt;方式&gt;：none (默认)，classify (-F)，file-type (-p) -i –inode 印出每个文件的 inode 号 -I –ignore=样式 不印出任何符合 shell 万用字符&lt;样式&gt;的项目 -k 即 –block-size=1K,以 k 字节的形式表示文件的大小。 -l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来。 -L –dereference 当显示符号链接的文件信息时，显示符号链接所指示的对象而并非符号 链接本身的信息 -m 所有项目以逗号分隔，并填满整行行宽 -o 类似 -l,显示文件的除组信息外的详细信息。 -r –reverse 依相反次序排列 -R –recursive 同时列出所有子目录层 -s –size 以块大小为单位列出所有文件的大小 -S 根据文件大小排序 –sort=WORD 以下是可选用的 WORD 和它们代表的相应选项： extension -X status -c none -U time -t size -S atime -u time -t access -u version -v use -u -t 以文件修改时间排序 -u 配合 -lt:显示访问时间而且依访问时间排序 配合 -l:显示访问时间但根据名称排序 否则：根据访问时间排序 -U 不进行排序;依文件系统原有的次序列出项目 -v 根据版本进行排序 -w –width=COLS 自行指定屏幕宽度而不使用目前的数值 -x 逐行列出项目而不是逐栏列出 -X 根据扩展名排序 -1 每行只列出一个文件 –help 显示此帮助信息并离开 –version 显示版本信息并离开 4. 常用范例：例一：列出/home/peidachang文件夹下的所有文件和目录的详细资料 命令：ls -l -R /home/peidachang 在使用 ls 命令时要注意命令的格式：在命令提示符后，首先是命令的关键字，接下来是命令参数，在命令参数之前要有一短横线“-”，所有的命令参数都有特定的作用，自己可以根据需要选用一个或者多个参数，在命令参数的后面是命令的操作对象。在以上这条命令“ ls -l -R /home/peidachang”中，“ls” 是命令关键字，“-l -R”是参数，“ /home/peidachang”是命令的操作对象。在这条命令中，使用到了两个参数，分别为“l”和“R”，当然，你也可以把他们放在一起使用，如下所示： 命令：ls -lR /home/peidachang 这种形式和上面的命令形式执行的结果是完全一样的。另外，如果命令的操作对象位于当前目录中，可以直接对操作对象进行操作;如果不在当前目录则需要给出操作对象的完整路径，例如上面的例子中，我的当前文件夹是peidachang文件夹，我想对home文件夹下的peidachang文件进行操作，我可以直接输入 ls -lR peidachang，也可以用 ls -lR /home/peidachang。 例二：列出当前目录中所有以“t”开头的目录的详细内容，可以使用如下命令： 命令：ls -l t* 可以查看当前目录下文件名以“t”开头的所有文件的信息。其实，在命令格式中，方括号内的内容都是可以省略的，对于命令ls而言，如果省略命令参数和操作对象，直接输入“ ls ”，则将会列出当前工作目录的内容清单。 例三：只列出文件下的子目录 命令：ls -F /opt/soft |grep /$ 列出 /opt/soft 文件下面的子目录 输出：1234567[root@localhost opt]# ls -F /opt/soft |grep /$jdk1.6.0_16/subversion-1.6.1/tomcat6.0.32/ 命令：ls -l /opt/soft | grep &quot;^d&quot; 列出 /opt/soft 文件下面的子目录详细情况 输出：1234567[root@localhost opt]# ls -l /opt/soft | grep &quot;^d&quot;drwxr-xr-x 10 root root 4096 09-17 18:17 jdk1.6.0_16drwxr-xr-x 16 1016 1016 4096 10-11 03:25 subversion-1.6.1drwxr-xr-x 9 root root 4096 2011-11-01 tomcat6.0.32 例四：列出目前工作目录下所有名称是s 开头的档案，愈新的排愈后面，可以使用如下命令： 命令：ls -ltr s* 输出：1234567891011121314151617181920212223242526272829[root@localhost opt]# ls -ltr s*src:总计 0script:总计 0soft:总计 350644drwxr-xr-x 9 root root 4096 2011-11-01 tomcat6.0.32-rwxr-xr-x 1 root root 81871260 09-17 18:15 jdk-6u16-linux-x64.bindrwxr-xr-x 10 root root 4096 09-17 18:17 jdk1.6.0_16-rw-r--r-- 1 root root 205831281 09-17 18:33 apache-tomcat-6.0.32.tar.gz-rw-r--r-- 1 root root 5457684 09-21 00:23 tomcat6.0.32.tar.gz-rw-r--r-- 1 root root 4726179 10-10 11:08 subversion-deps-1.6.1.tar.gz-rw-r--r-- 1 root root 7501026 10-10 11:08 subversion-1.6.1.tar.gzdrwxr-xr-x 16 1016 1016 4096 10-11 03:25 subversion-1.6.1 例五：列出目前工作目录下所有档案及目录;目录于名称后加”/“, 可执行档于名称后加”*” 命令：ls -AF 输出：123[root@localhost opt]# ls -AFlog/ script/ soft/ src/ svndata/ web/ 例六：计算当前目录下的文件数和目录数 命令： ls -l * |grep &quot;^-&quot;|wc -l ---文件个数 ls -l * |grep &quot;^d&quot;|wc -l ---目录个数 例七: 在ls中列出文件的绝对路径 命令：ls | sed &quot;s:^:`pwd`/:&quot; 输出：12345678910111213[root@localhost opt]# ls | sed &quot;s:^:`pwd`/:&quot; /opt/log/opt/script/opt/soft/opt/src/opt/svndata/opt/web 例九：列出当前目录下的所有文件（包括隐藏文件）的绝对路径， 对目录不做递归 命令：find $PWD -maxdepth 1 | xargs ls -ld 输出：123456789101112131415[root@localhost opt]# find $PWD -maxdepth 1 | xargs ls -lddrwxr-xr-x 8 root root 4096 10-11 03:43 /optdrwxr-xr-x 2 root root 4096 2012-03-08 /opt/logdrwxr-xr-x 2 root root 4096 2012-03-08 /opt/scriptdrwxr-xr-x 5 root root 4096 10-11 03:21 /opt/softdrwxr-xr-x 2 root root 4096 2012-03-08 /opt/srcdrwxr-xr-x 4 root root 4096 10-11 05:22 /opt/svndatadrwxr-xr-x 4 root root 4096 10-09 00:45 /opt/web 例十：递归列出当前目录下的所有文件（包括隐藏文件）的绝对路径 命令： find $PWD | xargs ls -ld 例十一：指定文件时间输出格式 命令： ls -tl --time-style=full-iso 输出：12345[root@localhost soft]# ls -tl --time-style=full-iso 总计 350644drwxr-xr-x 16 1016 1016 4096 2012-10-11 03:25:58.000000000 +0800 subversion-1.6.1 命令： ls -ctl --time-style=long-iso 输出：12345[root@localhost soft]# ls -ctl --time-style=long-iso总计 350644drwxr-xr-x 16 1016 1016 4096 2012-10-11 03:25 subversion-1.6.1 扩展： 显示彩色目录列表 打开/etc/bashrc, 加入如下一行: alias ls=&quot;ls --color&quot; 下次启动bash时就可以像在Slackware里那样显示彩色的目录列表了, 其中颜色的含义如下: 1. 蓝色--&gt;目录 2. 绿色--&gt;可执行文件 3. 红色--&gt;压缩文件 4. 浅蓝色--&gt;链接文件 5. 灰色--&gt;其他文件]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux COMMAND]]></title>
      <url>%2F2017%2F04%2F06%2Flinux-COMMAND%2F</url>
      <content type="text"><![CDATA[Linux常用命令1.线上帮助man help 2.目录操作ls tree pwd mkdir rmdir cd 3.文件操作touch cp mv rm ln find rename 4.文件查看处理cat more less head tail cut paste sort uniq wc iconv dos2unix file diff tree chattr lsattr rev vimdiff 5.文件打包压缩gzip tar unzip 6.信息显示uname hostname dmesg uptime file stat du df top free w date 7.搜索命令find which whereis locate 8.用户管理useradd userdel passwd chage usermod id. su sudo visudo groupadd 9.网络操作telent ssh scp wget ping route ifconfig ifup ifdown netstat curl lynx mail mutt nslookup dig 10.磁盘空间mount umount df du fsck dd 11.关机和查看系统命令shutdown reboot ps top kill date halt 12.系统管理top vmstat mpstat iostat sar kill chkconfig last 13.系统安全passwd su sudo umask charg chmod chattr lsattr ps whoami 14.系统登录信息w who users last lastlog fingers 15.硬件信息查看ethtool mii-tool dmidecode dmesg lspci 16.其他chkconfig echo yum watch alias unlias clear history eject time nohup nc xargs 17.关机shuatdown -h now init 0 halt -p 18.进程bg fg jobs kill，killall，pkill crontab ps pstree top nice nohup pgrep strace 19.危险命令mv rm fdisk dd parted 20.文本四剑客grep egrep sed awk]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[grep和正则表达式]]></title>
      <url>%2F2017%2F04%2F06%2Fgrep-and-zhengze%2F</url>
      <content type="text"><![CDATA[grep命令及正则表达式以下转自微信公众号：magedu-Linux grep基本概念 grep：global search regular expression and print out the line 作用：文本过滤器，用于文本搜索，用指定“模式”逐行匹配。 模式：由正则表达式字符及文本字符所编写的过滤条件 正则表达式：由一类特殊字符和文本字符所编写的模式，其有些字符不表示字符字面意义，而表示控制或通配的功能 比较记忆： 基本正则表达式：BRE 扩展正则表达式：ERE grep -E = egrep grep语法 grep [OPTIONS] PATTERN [FILE…] OPTIONS：1234567891011121314151617--color=auto：对匹配到的文本着色后高亮显示；-i：ignorecase，忽略字符的大小写；-o：仅显示匹配到的字符串本身；-v, --invert-match：显示不能被模式匹配到的行；-E：支持使用扩展的正则表达式元字符；-q, --quiet, --silent：静默模式，即不输出任何信息；-A #：after, 后#行-B #：before，前#行 -C #：context，前后各#行 基本正则表达式原字符字符匹配： . ：匹配任意单个字符； []：匹配指定范围内的任意单个字符； [^]：匹配指定范围外的任意单个字符； [:digit:]、[:lower:]、[:upper:]、[:alpha:]、[:alnum:]、[:punct:]、[:space:] 匹配次数： 用在要指定其出现的次数的字符的后面，用于限制其前面字符出现的次数；默认工作于贪婪模式； *：匹配其前面的字符任意次；0,1,多次； 例如：grep &quot;x\+y&quot; abxy aby xxxxxy yab .*：匹配任意长度的任意字符 \?：匹配其前面的字符0次或1次；即其前面的字符是可有可无的； \+：匹配其前面的字符1次或多次；即其面的字符要出现至少1次； \{m\}：匹配其前面的字符m次； \{m,n\}：匹配其前面的字符至少m次，至多n次； \{0,n\}：至多n次 \{m,\}：至少m次 位置锚定： ^：行首锚定；用于模式的最左侧； $：行尾锚定；用于模式的最右侧； ^PATTERN$：用于PATTERN来匹配整行； ^$：空白行； ^[[:space:]]*$：空行或包含空白字符的行； \&lt; 或 \b：词首锚定，用于单词模式的左侧； > 或 \b：词尾锚定，用于单词模式的右侧； \：匹配完整单词； 单词：非特殊字符组成的连续字符（字符串）都称为单词； 分组及引用 ()：将一个或多个字符捆绑在一起，当作一个整体进行处理； \(xy\)*ab Note：分组括号中的模式匹配 到的内容会被正则表达式引擎自动记录于内部的变量中，这些变量为： \1：模式从左侧起，第一个左括号以及与之匹配的右括号之间的模式所匹配到的字符； \2：模式从左侧起，第二个左括号以及与之匹配的右括号之间的模式所匹配到的字符； \3 … He loves his lover. He likes his lover. She likes her liker. She loves her liker. ~]# grep &quot;\(l..e\).*\1&quot; lovers.txt 后向引用：引用前面的分组括号中的模式所匹配到的字符； 扩展正则表达式的元字符字符匹配： .：任意单个字符 []：指定范围内的任意单个字符 [^]：指定范围外的任意单个字符 次数匹配： *：任意次，0,1或多次； ?：0次或1次，其前的字符是可有可无的； +：其前字符至少1次； {m}：其前的字符m次； {m,n}：至少m次，至多n次; {0,n} {m,} 位置锚定： ^：行首锚定； $：行尾锚定； \&lt;, \b：词首锚定； \&gt;, \b：词尾锚定； 分组及引用： ()：分组；括号内的模式匹配到的字符会被记录于正则表达式引擎的内部变量中； 后向引用：\1, \2, ... 或： a|b：a或者b；C|cat：C或cat(c|C)at：cat或Cat]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[常用正则表达式集合]]></title>
      <url>%2F2017%2F04%2F06%2Fzhengzebiaodashi%2F</url>
      <content type="text"><![CDATA[常用正则表达式集合以下转载自微信公众号：ChinaHadoop 校验数字的表达式 数字：^[0-9]*$ n位的数字：^\d{n}$ 至少n位的数字：^\d{n,}$ m-n位的数字：^\d{m,n}$ 零和非零开头的数字：^(0|[1-9][0-9]*)$ 非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(.[0-9]{1,2})?$ 带1-2位小数的正数或负数：^(-)?\d+(.\d{1,2})?$ 正数、负数、和小数：^(-|+)?\d+(.\d+)?$ 有两位小数的正实数：^[0-9]+(.[0-9]{2})?$ 有1~3位小数的正实数：^[0-9]+(.[0-9]{1,3})?$ 非零的正整数：^[1-9]\d$ 或 ^([1-9][0-9]){1,3}$ 或 ^+?[1-9][0-9]*$ 非零的负整数：^-[1-9][]0-9”$ 或 ^-[1-9]\d$ 非负整数：^\d+$ 或 ^[1-9]\d*|0$ 非正整数：^-[1-9]\d*|0$ 或 ^((-\d+)|(0+))$ 非负浮点数：^\d+(.\d+)?$ 或 ^[1-9]\d.\d|0.\d[1-9]\d|0?.0+|0$ 非正浮点数：^((-\d+(.\d+)?)|(0+(.0+)?))$ 或 ^(-([1-9]\d.\d|0.\d[1-9]\d))|0?.0+|0$ 正浮点数：^[1-9]\d.\d|0.\d[1-9]\d$ 或 ^(([0-9]+.[0-9][1-9][0-9])|([0-9][1-9][0-9].[0-9]+)|([0-9][1-9][0-9]))$ 负浮点数：^-([1-9]\d.\d|0.\d[1-9]\d)$ 或 ^(-(([0-9]+.[0-9][1-9][0-9])|([0-9][1-9][0-9].[0-9]+)|([0-9][1-9][0-9])))$ 浮点数：^(-?\d+)(.\d+)?$ 或 ^-?([1-9]\d.\d|0.\d[1-9]\d|0?.0+|0)$ 校验字符的表达式 汉字：^[\u4e00-\u9fa5]{0,}$ 英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]{4,40}$ 长度为3-20的所有字符：^.{3,20}$ 由26个英文字母组成的字符串：^[A-Za-z]+$ 由26个大写英文字母组成的字符串：^[A-Z]+$ 由26个小写英文字母组成的字符串：^[a-z]+$ 由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$ 由数字、26个英文字母或者下划线组成的字符串：^\w+$ 或 ^\w{3,20}$ 中文、英文、数字包括下划线：^[\u4E00-\u9FA5A-Za-z0-9_]+$ 中文、英文、数字但不包括下划线等符号：^[\u4E00-\u9FA5A-Za-z0-9]+$ 或 ^[\u4E00-\u9FA5A-Za-z0-9]{2,20}$ 可以输入含有^%&amp;’,;=?$\”等字符：[^%&amp;’,;=?$\x22]+ 12 禁止输入含有~的字符：[^~\x22]+ 特殊需求表达式 Email地址：^\w+([-+.]\w+)@\w+([-.]\w+).\w+([-.]\w+)*$ 域名：[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(/.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+/.? InternetURL：[a-zA-z]+://[^\s] 或 ^http://([\w-]+\.)+[\w-]+(/[\w-./?%&amp;=])?$ 手机号码：^(13[0-9]|14[5|7]|15[0|1|2|3|5|6|7|8|9]|18[0|1|2|3|5|6|7|8|9])\d{8}$ 电话号码(“XXX-XXXXXXX”、”XXXX-XXXXXXXX”、”XXX-XXXXXXX”、”XXX-XXXXXXXX”、”XXXXXXX”和”XXXXXXXX)：^((\d{3,4}-)|\d{3.4}-)?\d{7,8}$ 国内电话号码(0511-4405222、021-87888822)：\d{3}-\d{8}|\d{4}-\d{7} 身份证号(15位、18位数字)：^\d{15}|\d{18}$ 短身份证号码(数字、字母x结尾)：^([0-9]){7,18}(x|X)?$ 或 ^\d{8,18}|[0-9x]{8,18}|[0-9X]{8,18}?$ 帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]{4,15}$ 密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]\w{5,17}$ 强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间)：^(?=.\d)(?=.[a-z])(?=.*[A-Z]).{8,10}$ 日期格式：^\d{4}-\d{1,2}-\d{1,2} 一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$ 一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$ 钱的输入格式： 有四种钱的表示形式我们可以接受:”10000.00” 和 “10,000.00”, 和没有 “分” 的 “10000” 和 “10,000”：^[1-9][0-9]*$ 这表示任意一个不以0开头的数字,但是,这也意味着一个字符”0”不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$ 一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$ 这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧.下面我们要加的是说明可能的小数部分：^[0-9]+(.[0-9]+)?$ 必须说明的是,小数点后面至少应该有1位数,所以”10.”是不通过的,但是 “10” 和 “10.2” 是通过的：^[0-9]+(.[0-9]{2})?$ 这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：^[0-9]+(.[0-9]{1,2})?$ 这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：^[0-9]{1,3}(,[0-9]{3})*(.[0-9]{1,2})?$ 1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]{1,3}(,[0-9]{3})*)(.[0-9]{1,2})?$ 备注：这就是最终结果了,别忘了”+”可以用”*”替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里 xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\.[x|X][m|M][l|L]$ 中文字符的正则表达式：[\u4e00-\u9fa5] 双字节字符：[^\x00-\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1)) 空白行的正则表达式：\n\s*\r (可以用来删除空白行) HTML标记的正则表达式：&lt;(\S?)[^&gt;]&gt;.?&lt;/\1&gt;|&lt;.? /&gt; (网上流传的版本太糟糕，上面这个也仅仅能部分，对于复杂的嵌套标记依旧无能为力)S 首尾空白字符的正则表达式：^\s|\s$或(^\s)|(\s$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式) 腾讯QQ号：[1-9][0-9]{4,} (腾讯QQ号从10000开始) 中国邮政编码：[1-9]\d{5}(?!\d) (中国邮政编码为6位数字) IP地址：\d+.\d+.\d+.\d+ (提取IP地址时有用) IP地址：((?:(?:25[0-5]|2[0-4]\d|[01]?\d?\d)\.){3}(?:25[0-5]|2[0-4]\d|[01]?\d?\d))]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux Filesystem]]></title>
      <url>%2F2017%2F03%2F28%2Ffilesystem%2F</url>
      <content type="text"><![CDATA[什么是Filesystem？Filesystem就是分区或磁盘上的所有文件的逻辑集合。它不仅包含着文件中的数据而且还有文件系统的结构，所有Linux用户和程序看到的软连接及文件保护信息等都存储在其中。 文件系统有多种类型： ext2：早期linux中常用的文件系统。 ext3：ext2的升级版，带日志功能。 RAMFS：内存文件系统，速度快。 iso9660：光盘或光盘镜像。 NFS：网络文件系统，当初由SUN发明，除妖用于远程文件共享; MS-DOS：MS-DOS文件系统。 FAT：Windows XP 操作系统采用的文件系统。 NTFS：Windows NT/XP 操作系统采用的文件系统。 目录与分区文件系统位于磁盘分区中，一个硬盘又可以有多个分区，也可以只有一个分区，一个分区只能包含一个文件系统。 Linux的文件结构是单个的树状结构，根目录是”/“，其他目录都要位于根目录下。 以下是/目录下的结构： 1234567891011121314151617181920212223/├── bin├── boot├── dev├── etc├── home├── lib├── lib64├── lost+found├── media├── misc├── mnt├── net├── opt├── proc├── root├── sbin├── selinux├── srv├── sys├── tmp├── usr└── var 具体说明： 目录 说明 / 根目录，只能包含目录，不能包含具体文件 /bin 存放可执行文件，很多命令就对应/bin目录下的某个程序，如：ls、cp、mkdir，/bin目录下对所有用户有效 /boot 存放与内核有关的文件 /dev device 设备文件 /etc 存放各种系统包括应用的配置文件 /home 每个用户的家目录，而且是每个用户默认的工作目录 /lib 程序包括系统所以来的一些共享库文件及内核所依赖的模块文件 /lib64 系统程序所依赖的库文件通常以.so结尾 lost+found 垃圾回收站 /media 光盘或者U盘挂载点，媒体介质挂载点 /misc 杂项，存放不好归类的文件 /mnt 临时文件挂载点 /net 网络配置文件 /opt 第三方应用的安装位置如：nginx，tomcat，Apache /proc 伪文件系统，记录系统硬件的一些运行信息 /sbin 存放管理类命令 /selinux 存放与linux相关的文件或记录 /srv 系统运行产生的一些文件 /sys 伪文件系统，记录系统硬件的一些运行信息 /tmp 杂项，临时文件以及应用产生的临时文件 /usr 二级层级存储用户的只读数据； 包含(多)用户主要的公共文件以及应用程序 /var 日志存放以及应用产生的一些文件或者临时文件 /usr与/var目录下常用的目录： 目录 说明 /usr/bin 非必要的命令二进制文件(在单用户模式中不需要用到的)；用于所有用户 /usr/include 标准的包含文件 /usr/lib 备用格式库(可选的) /usr/local 三级层次 用于本地数据，具体到该主机上的。通常会有下一个子目录, 比如, bin/, lib/, share/. /usr/local/sbin 非必要系统的二进制文件，比如用于不同网络服务的守护进程 /usr/share 架构无关的 (共享) 数据 /usr/src 源代码，比如内核源文件以及与它相关的头文件 — — /var/cache 应用程序缓存数据， 这些数据是由耗时的I/O(输入/输出)的或者是运算本地生成的结果。这些应用程序是可以重新生成或者恢复数据的。当没有数据丢失的时候，可以删除缓存文件 /var/lib 状态信息。这些信息随着程序的运行而不停地改变，比如，数据库，软件包系统的元数据等等 /var/lock 锁文件。这些文件用于跟踪正在使用的资源 /var/log 日志文件。包含各种日志。 /var/mail 内含用户邮箱的相关文件 /var/opt 来自附加包的各种数据都会存储在其中 /var/spool 该spool主要用于存放将要被处理的任务，比如打印队列以及邮件外发队列 /var/mail 过时的位置，用于放置用户邮箱文件 /var/tmp 存放重启后保留的临时文件 tree命令：用来查看目录结构123tree -L 1 -d /-L 指定层数-d 只查看目录 常用文件管理命令： 命令 说明 cat filename 查看文件内容。 cd dirname 改变所在目录。 cp file1 file2 复制文件或目录。 file filename 查看文件类型(binary, text, etc)。 find filename dir 搜索文件或目录。 head filename 显示文件的开头，与tail命令相对。 less filename 查看文件的全部内容，可以分页显示，比more命令要强大。 ls dirname 遍历目录下的文件或目录。 mkdir dirname 创建目录。 more filename 查看文件的全部内容，可以分页显示。 mv file1 file2 移动文件或重命名。 pwd 显示用户当前所在目录。 rm filename 删除文件。 rmdir dirname 删除目录。 tail filename 显示文件的结尾，与head命令相对。 touch filename 文件不存在时创建一个空文件，存在时修改文件时间戳。 whereis filename 查看文件所在位置。 which filename 如果文件在环境变量PATH中有定义，那么显示文件位置。 Linux的文件类型： - 普通文件 d directory 目录文件 b 块设备 blockc 字符设备 character l 符号链接文件 p 管道文件pipe 进程间通信可能会管道 s 套接字文件 socket 或多或少有点像sockets(套接字)，提供一个进程间的通信机制，而不用网络套接字协议。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[获取帮助]]></title>
      <url>%2F2017%2F03%2F25%2Fget-help%2F</url>
      <content type="text"><![CDATA[概要whatis COMMAND --help man/info 本地帮助文档/usr/share/doc 官网在线文档 Google 在Linux中获取帮助有这么几方面 whatis COMMAND --help man/info 本地帮助文档/usr/share/doc 官网在线文档 Google whatis显示命令的简短描述 每晚使用一个数据库更新 刚安装后不可立即使用 makewhatis | mandb 制作数据库 123456[root@pxe57 ~]# whatis calcal (1) - displays a calendarcal (1p) - print a calendar[root@pxe57 ~]# man -f calcal (1) - displays a calendarcal (1p) - print a calendar 内部命令：help COMMAND man bash 外部命令：(1) # COMMAND --help # COMMAND -h (2) 使用手册(manual) # man COMMAND (3) 信息页 # info COMMAND (4) 程序自身的帮助文档 README INSTALL ChangeLog (5) 程序官方文档 官方站点： Documentation (6) 发行版的官方文档 (7) Googl help显示用法总结和参数列表 $ date --help 用法: date [OPTION]... [+FORMAT] date [-u|--utc|--universal] [MMDDhhmm[[CC]YY][.ss]] [] 表示可选项 ... 表示有多个选项 | 表示或 eg：a|b|c|=表示a或b或c {} 表示分组 infoman常用于命令参考 ， GNU工具info适合通用文档参考。 没有参数,列出所有的页面 info 页面的结构就像一个网站 每一页分为“ 节点” 链接节点之前 * info [ 命令 ] 导航info页：方向键， PgUp， PgDn 导航 Tab键 移动到下一个链接 d 显示主题目录 Home 显示主题首部 Enter进入 选定链接 n/p/u/l 进入下/前/上一层/最后一个链接 s 文字 文本搜索 q 退出 info 通过本地文档获取帮助：System-&gt;help（ centos6） Applications -&gt; documentation-&gt;help（ centos7）提供的官方使用指南和发行注记 /usr/share/doc目录 多数安装了的软件包的子目录,包括了这些软件的相关原理说明 常见文档： README INSTALL CHANGES 不适合其它地方的文档的位置 配置文件范例 HTML/PDF/PS 格式的文档 授权书详情 通过在线文档获取帮助：第三方程序官方文档 http://www.nginx.org http://tomcat.apache.org http://httpd.apache.org http://www.python.org 通过发行版官方的文档光盘或网站可以获得 安装指南、 部署指南、 虚拟化指南等 红帽知识库和官方在线文档 http://kbase.redhat.com http://www.redhat.com/docs http://access.redhat.com 网站搜索：http://tldp.org http://www.slideshare.net http://www.google.com Openstack filetype:pdf rhca site:redhat.com/docs]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[bash 快捷键]]></title>
      <url>%2F2017%2F03%2F25%2Fbash-kuaijie%2F</url>
      <content type="text"><![CDATA[bash快捷键Ctrl + l 清屏， 相当于clear命令 Ctrl + o 执行当前命令， 并重新显示本命令 Ctrl + s 阻止屏幕输出， 锁定 Ctrl + q 允许屏幕输出 Ctrl + c 终止命令 Ctrl + z 挂起命令 Ctrl + a 光标移到命令行首， 相当于Home Ctrl + e 光标移到命令行尾， 相当于End Ctrl + f 光标向右移动一个字符 Ctrl + b 光标向左移动一个字符 Alt + f 光标向右移动一个单词尾 Alt + b 光标向左移动一个单词首 Ctrl + xx 光标在命令行首和光标之间移动 Ctrl + u 从光标处删除至命令行首 Ctrl + k 从光标处删除至命令行尾 Ctrl + w 从光标处向左删除至单词首 Alt + d 从光标处向右删除至单词尾 Ctrl + d 删除光标处的一个字符 Ctrl + h 删除光标前的一个字符 Ctrl + y 将删除的字符粘贴至光标后 Alt + c 从光标处开始向右更改为首字母大写的单词 Alt + u 从光标处开始向右更改为全部大写的单词 Alt + l 从光标处更改为全部小写的单词 Ctrl + t 交换光标处和之前的字符位置 Alt + t 交换光标处和之前的单词位置 Alt + N 提示输入指定字符后， 重复显示该字符N次 注意： Alt组合快捷键经常和其它软件冲突]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[命令行扩展]]></title>
      <url>%2F2017%2F03%2F25%2Fcommand-kuozhan%2F</url>
      <content type="text"><![CDATA[命令行扩展$()或$ 把一个命令的输出打印给另一个命令的参数 $ echo &quot;This system&apos;s name is $(hostname) &quot; This system&apos;s name is server1.example.com $echo &quot;i am `whoami` &quot; i am root 括号扩展： { } 打印重复字符串的简化形式12[root@pxe57 ~]# echo file&#123;1,3,5&#125;file1 file3 file5 12[root@pxe57 ~]# echo &#123;1..10&#125;1 2 3 4 5 6 7 8 9 10 12[root@pxe57 ~]# echo &#123;a..z&#125;a b c d e f g h i j k l m n o p q r s t u v w x y z 12[root@pxe57 ~]# echo &#123;000..20..2&#125;000 002 004 006 008 010 012 014 016 018 020 命令补全 bash根据PATH环境变量定义的路径，自左而右在每个路径搜寻以给定命令 名命名的文件， 第一次找到的命令即为要执行的命令. 用户给定的字符串只有一条惟一对应的命令， 直接补全否则， 再次Tab会给出列表 路径补全 把用户给出的字符串当做路径开头，并在其指定上级目录下搜索以指定的字符串开头的文件名 如果惟一： 则直接补全 否则： 再次Tab给出列表 TAB快捷键 command 2Tab 所有命令行补全 string2Tab 以string开头命令 /2Tab 显示所有根目录下一级目录， 包括隐藏目录 ./2Tab 当前目录下子目录， 包括隐藏目录 *2Tab 当前目录下子目录， 不包括隐藏目录 ~2Tab 所有用户列表 $2Tab 所有变量 @2Tab /etc/hosts记录 （ centos7不支持） =2Tab 相当于ls –A]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[date 命令]]></title>
      <url>%2F2017%2F03%2F25%2Fdate%2F</url>
      <content type="text"><![CDATA[NAME 名称 date date - print or set the system date and time 显示系统的时间和日期。 也可以用来显示或设定系统的日期与时间。 SYNOPSIS 概要 用法 date [OPTION]... [+FORMAT] date [-u|--utc|--universal] [MMDDhhmm[[CC]YY][.ss]] 选项 %y : 年份的最后两位数字 (00.99) %Y : 完整年份 (0000-9999) %m : 月份 (01-12) %b : 月份 (Jan-Dec) %B : 月份 (January-December) %c : 直接显示日期与时间 %d : 日 (01-31) %H : 小时(00-23) %M : 分钟(00-59) %p : 显示本地 AM 或 PM %S : 秒(00-60) %T : 直接显示时间 (24 小时制) %X : 相当于 %H:%M:%S %x : 直接显示日期 (mm/dd/yy) %a : 星期几 (Sun-Sat) %D : 直接显示日期 (mm/dd/yy) %j : 一年中的第几天 (001-366) %U : 一年中的第几周 (00-53) (以 Sunday 为一周的第一天的情形) %w : 一周中的第几天 (0-6) %W : 一年中的第几周 (00-53) (以 Monday 为一周的第一天的情形) 示例 123date [root@localhost ~]# dateSat Mar 25 12:34:40 CST 2017 123456789date -s 修改系统日期[root@localhost ~]# date -s &quot;20170630&quot;Fri Jun 30 00:00:00 CST 2017修改系统时间[root@pxe57 ~]# date -s &quot;20170325 1430&quot;Sat Mar 25 14:30:00 CST 2017 12345date +%Y/%m/%d改变日期显示格式[root@pxe57 ~]# date +%Y/%m/%d2017/03/25 显示日历：如果要列出目前这个月份可以直接执行cal。 [root@pxe57 ~]# cal March 2017 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 显示全年日历[root@pxe57 ~]# cal -y 2017 January February March Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 1 2 3 4 1 2 3 4 8 9 10 11 12 13 14 5 6 7 8 9 10 11 5 6 7 8 9 10 11 15 16 17 18 19 20 21 12 13 14 15 16 17 18 12 13 14 15 16 17 18 22 23 24 25 26 27 28 19 20 21 22 23 24 25 19 20 21 22 23 24 25 29 30 31 26 27 28 26 27 28 29 30 31 April May June Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 1 2 3 4 5 6 1 2 3 2 3 4 5 6 7 8 7 8 9 10 11 12 13 4 5 6 7 8 9 10 9 10 11 12 13 14 15 14 15 16 17 18 19 20 11 12 13 14 15 16 17 16 17 18 19 20 21 22 21 22 23 24 25 26 27 18 19 20 21 22 23 24 23 24 25 26 27 28 29 28 29 30 31 25 26 27 28 29 30 30 July August September Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 1 2 3 4 5 1 2 2 3 4 5 6 7 8 6 7 8 9 10 11 12 3 4 5 6 7 8 9 9 10 11 12 13 14 15 13 14 15 16 17 18 19 10 11 12 13 14 15 16 16 17 18 19 20 21 22 20 21 22 23 24 25 26 17 18 19 20 21 22 23 23 24 25 26 27 28 29 27 28 29 30 31 24 25 26 27 28 29 30 30 31 October November December Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 1 2 3 4 1 2 8 9 10 11 12 13 14 5 6 7 8 9 10 11 3 4 5 6 7 8 9 15 16 17 18 19 20 21 12 13 14 15 16 17 18 10 11 12 13 14 15 16 22 23 24 25 26 27 28 19 20 21 22 23 24 25 17 18 19 20 21 22 23 29 30 31 26 27 28 29 30 24 25 26 27 28 29 30 31 显示指定月份日历 [root@pxe57 ~]# cal 03 2017 March 2017 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[echo 命令]]></title>
      <url>%2F2017%2F03%2F25%2Fecho%2F</url>
      <content type="text"><![CDATA[ECHONAME 名称 echo - display a line of text echo - 在屏幕上显示一段文字 SYNOPSIS 概要 echo [SHORT-OPTION]... [STRING]... echo [短选项]... [字符串] echo LONG-OPTION echo 长选项 DESCRIPTION 描述 Echo the STRING(s) to standard output. Echo是字符的标准输出 -n do not output the trailing newline 输出时不自动换行 -e enable interpretation of backslash escapes 启用\字符功能 -E disable interpretation of backslash escapes （默认）不支持\解释功能 (default) If -e is in effect, the following sequences are rec-ognized: 启用命令选项-e，若字符串中出现以下字符， 则特别加以处理， 而不会将它当成一般文字输出 \\ backslash 插入\字符 \a alert (BEL) 发出警告声 \b backspace 向前删除一个字符 \c produce no further output 最后不加换行符号 \f form feed 换行但光标仍旧停留在原来的位置 \n new line 换行且光标移至行首 \r carriage return 回车，即光标移至行首 \t horizontal tab 插入tab \v vertical tab 垂直插入tab，与\f显示相同 \0NNN byte with octal value NNN (1 to 3 digits) 插入（nnn）八进制所代表的ASCII字符； /bin/echo --help 查看help帮助 /bin/echo --version 查看当前版本echo版本 示例 123echo abcdefghijklmnopqrstuvwxyz[root@localhost ~]# echo abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz 123echo -n [root@localhost ~]# echo -n abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz[root@localhost ~]# 123echo -e \\[root@localhost ~]# echo -e &quot;\\ abcdefghijklmnopqrstuvwxyz&quot;\ abcdefghijklmnopqrstuvwxyz 123echo -e \b[root@localhost ~]# echo -e &quot;abcdefghijklmnopqrstuvwxy\bz&quot;abcdefghijklmnopqrstuvwxz 123echo -e \c[root@localhost ~]# echo -e &quot;abcdefghijklmnopqrstuvwxyz\c&quot;abcdefghijklmnopqrstuvwxyz[root@localhost ~]# 1234echo -e \f[root@localhost ~]# echo -e &quot;abcd\fefghijklmnopqrstuvwxyz&quot;abcd efghijklmnopqrstuvwxyz 1234echo -e \n[root@localhost ~]# echo -e &quot;\nabcdefghijklmnopqrstuvwxyz&quot;abcdefghijklmnopqrstuvwxyz]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux 基础]]></title>
      <url>%2F2017%2F03%2F24%2FLinux%2F</url>
      <content type="text"><![CDATA[Linux中的用户 在Linux中一般分为两个用户： root用户：一个特殊的管理账户，也被称为超级用户，在Windows中相当于administrato管理&gt;员。root已接近完整的系统控制，对系统损害几乎有无限的能力，在平时的生产环境中，除非需要做特定的操作，否则一般情况下不在root用户下对系统进行操作。 普通用户： 普通用户也叫非特权用户，它对系统操作的权限有限，所以普通用户的操作对操作系统造成的损害的能力也比较有限。 用户登录信息查看命令：123whoami: 显示当前登录有效用户who: 系统当前所有的登录会话w: 系统当前所有的登录会话及所做的操作 终端 终端： 终端分为设备终端，物理终端，虚拟终端，图形终端，串行终端，伪终端。 设备终端： 键盘鼠标显示器。 物理终端： 在(/dev/console) 下，控制台console。 虚拟终端：（tty：tele type writers，/dev/tty# #为[1-6] ） 在(/dev/tty）下，tty可以有多个，可以使用Ctrl+Alt+F[1-6] 来进行切换。 图形终端：(/dec/tty7) startx，xwindows 在(/dec/tty7)下， 在CentOS6中：启动图形终端为Ctrl+Alt+F7。 在CentOS7中：启动图形终端为：在哪个终端启动就为于哪个终端。 串行终端： 在(/dev/ttyS#)下，使用串行接口输出的终端设备。 伪终端：（pty：pseudo-tty ，/dev/pts/#） 在(/dev/pts/#)下,pts,SSH远程连接；使用Xshell或CRT进行远程连接的都称为伪终端。 查看当前的终端设备： [root@localhost ~]# tty /dev/pts/0 交互式接口 交互式接口： 在启动终端后，在终端设备附加一个交互式应用程序，其实就是选择桌面或者是黑屏代码模式。 交互式程序： 交互式程序分为两类：GUI和CLI； GUI：Graphic User Interface图形用户界面，又称图形用户接口。 Xprotocol，window manager，desktop Desktop： GNOME（c语言编写，图形库gtk） KDE（c++编写，图形库qt） XFCE（c语言编写，图形库gtk+） CLI：Command Line Interface命令行界面，又称命令行接口。 shell程序：sh，csh，tcsh，ksh，bash，zsh SHELL Shell是一种高级程序设计语言，它是Linux系统的用户界面，为提供用户与内核进行交互操作的一种接口，他接受用户输入的命令并把它送入内核去执行，shell也被称为Linux的命令解释器（Command interpreter）。 BASH SHELL GNU Bourne-Again Shell（bash）是GNU计划中重要的工具软件之一，目前也是Linux标准的shell，与sh兼容。 CentOS中默认使用的是bash。 显示当前使用的shell：12[root@localhost ~]# echo $SHELL/bin/bash 显示当前系统使用的所有shell：12345678910 [root@localhost ~]# cat /etc/shells /bin/sh /bin/bash /sbin/nologin /usr/bin/sh /usr/bin/bash /usr/sbin/nologin /bin/tcsh /bin/csh` 命令提示符 [root@localhost ~]# #：当前用户为管理员 [lee@localhost root]$ $：当前用户为普通用户 显示提示符格式： [lee@localhost root]$ echo $PS1 [\u@\h \W]\$ PS1=”[\e[31m][\u@\h \W]\$[\e[0m]“12345678910\e\033 修改命令符颜色\u 当前用户\h 主机名简称 \H 主机名\w 当前工作目录 \W 当前工作目录基名\t 24小时时间格式 \T 12小时时间格式\! 命令历史数 \# 开机后命令历史数 执行命令 输入命令后回车： 提请shell程序找到键入命令所对应的可执行程序或代码，并由其分析后提交给内核分配资源将其运行起来。 在shell中可执行的命令有两类： 内部命令，外部命令 内部命令： 由shell自带的，而且通过某命令形式提供。 help：内部命令列表。 enable cmd：可以启用。 enable -n cmd：禁用内部命令。 enable -n：查看所有禁用的内部命令。 外部命令： 在文件系统路径下有对应的可执行程序文件。 查看路径： which -a，which --skip-alias，whereis 区别指定的命令是内部的还是外部的： [lee@localhost root]$ type cd cd is a shell builtin 内部命令 [lee@localhost root]$ type ll ll is aliased to `ls -l --color=auto&apos; 外部命令 在文件系统路径下有对应的可执行程序文件。 查看路径： which -a，which --skip-alias，whereis 区别指定的命令是内部的还是外部的： [lee@localhost root]$ type cd cd is a shell builtin 内部命令 [lee@localhost root]$ type ll ll is aliased to `ls -l --color=auto&apos; 外部命令 Hash缓存表 系统初始hash表为空，当外部命令执行时，默认会从PATH路径下寻找该命令，找到后会将这条命令路径记录到hash表中，当再次使用该命令时，shell解释器首先会查看hash表，存在将执行，如果不存在，将会去PATH路径下寻找。利用hash缓存表可大大提高命令的调用速率。 Hash常见用法： hash：显示hash缓存。 hash -l：显示hash缓存，可作为输入使用。 hash -p path name：将命令全路径path起别名为name。 hash -t name：打印缓存中的name的路径。 hash -d name ：清除name的缓存。 hash -r ：清除缓存。 别名 命令别名：123456789101112显示当前shell进程所有可用的命令别名： [root@localhost ~]# alias alias cp=&apos;cp -i&apos; alias egrep=&apos;egrep --color=auto&apos; alias fgrep=&apos;fgrep --color=auto&apos; alias grep=&apos;grep --color=auto&apos; alias l.=&apos;ls -d .* --color=auto&apos; alias ll=&apos;ls -l --color=auto&apos; alias ls=&apos;ls --color=auto&apos; alias mv=&apos;mv -i&apos; alias rm=&apos;rm -i&apos; alias which=&apos;alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde&apos; 定义别名：12345定义别名name，其相当于执行命令VALUE：[root@localhost ~]# alias lqb=&apos;ls -a&apos;[root@localhost ~]# lqb. anaconda-ks.cfg .bash_logout .bashrc .config .ssh .Xauthority.. .bash_history .bash_profile .cache .cshrc .tcshrc 在命令行中定义的别名，仅对当前shell进程有效，如果想永久保存要定义在配置文件中：12仅对当前用户有效：~/.bashrc 对所有用户有效：. /etc/bashrc 编辑配置给出的新配置不会立即生效 bash进程重新读取配置文件12source /path/to/config_file./path/to/config_file 撤销别名：unalias12345 unalias [-a] name [name ...] -a 取消所有别名[root@localhost ~]# unalias lqb[root@localhost ~]# lqbbash: lqb: command not found 如果别名同原命令同名， 如果要执行原命令， 可使用:123“\COMMAND”’COMMAND’/PATH/COMMAND： 外部命令 命令行格式 12345 COMMAND [OPTIONS...] [ARGUMENTS...]选项： 用于启用或关闭命令的某个或某些功能；短选项： -c, 例如： -l, -h长选项： --word， 例如： --all, --human-readable参数： 命令的作用对象， 比如文件名， 用户名等 注意： 1.多选项，以及多参数和命令之间使用空白字符分隔 2.取消和结束命令执行： Ctrl+c，Ctrl+d 3.多个命令可以用；符号分开 4.一个命令可以用\分成多行 date：显示日期和时间 Linux的两种时钟： 系统时钟： 由Linux内核通过CPU的工作频率进行的 硬件时钟： 主板 hwclock， clock: 显示硬件时钟 -s, --hctosys 以硬件时钟为准， 校正系统时钟 -w, --systohc 以系统时钟为准， 校正硬件时钟 时区： /etc/localtime cal： 显示日历 cal –y：显示全年日历 开机关机 关机：1halt, poweroff 重启：123reboot-f: 强制， 不调用shutdown-p: 切断电源 关机或重启:shutdown1234567shutdown [OPTION]... TIME [MESSAGE]-r: reboot-h: halt-c： cancelTIME:now: 立刻+m: 相对时间表示法， 多久之后； 例如 +3hh:mm: 绝对时间表示， 指明具体时间 screen命令 1234567891011121314创建新screen会话： screen –S [SESSION]加入screen会话： screen –x [SESSION]离线某个会话： screen –d [SESSION]恢复某screen会话： screen -r [SESSION]退出并关闭screen会话 ： exit剥离当前screen会话： Ctrl+a,d显示所有已经打开的screen会话： screen -l echo命令 123功能： 显示字符语法： echo [-neE][字符串]说明： echo会将输入的字符串送往标准输出。 输出的字符串间以空白字符隔开, 并在最后加上换行号 选项：1234567891011121314151617&gt;-E （ 默认） 不支持 \ 解释功能-n 不自动换行-e 启用 \ 字符的解释功能 显示变量： echo &quot;$VAR_NAME“ 变量会替换， 弱引用 echo &apos;$VAR_NAME‘ 变量不会替换， 强引用 启用命令选项-e， 若字符串中出现以下字符， 则特别加以处理， 而不会将它当成一般文字输出\a 发出警告声\b 退格键\c 最后不加上换行符号\n 换行且光标移至行首\r 回车， 即光标移至行首， 但不换行\t 插入tab\\ 插入\字符\0nnn 插入nnn（ 八进制） 所代表的ASCII字符echo -e &apos;\033[43;31;5mmagedu\033[0m&apos;\xHH插入HH（ 十六进制） 所代表的ASCII字]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>%2F2017%2F03%2F14%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
    </entry>

    
  
  
</search>
